{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_feature.ipynb","provenance":[],"collapsed_sections":["_oYbBENpFSf6","2bdFCKVEFSf7","BIEMLO9kFSf7","nhiZsjPcI3nY","t4MPPclYDYWa","xg9MlhCvOPxy","Fz5X_QitOPxz","vuuCgEmTVbd6","xjmMT6jBOPx0","hJKEjBoVOPx0","mSqDVvKvFSf-","2DpawyUl3cIz","4B3sGPgEOjk-","S_YZL3IxcwwY","VVM2N9jw0g-w","vHGqh7C_FSgB","tPooryCm3xzP","rARysuQbOn6K","geySr50uczVY","RVXQKK0p0lkc","q11wWX3xFSgE","sFJoIRa54KXm","FIPk2M3BOrUe","kNSrIeTic2DO","93FL8LTbFSgH","5Sep1dY74dan","w6R1seiiOza0","d6I9gyzVc4rn","MrZ2p9UEFSgM","9MZ_NNshFSgN","_wL_rpI5OxbG","zk3zSiS2c7bl"],"authorship_tag":"ABX9TyOXEWx3Bas5fHjAX99A2diN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HViEAgpmvY40"},"source":["# AACT features with target variable + Adverse Events information + Dropout Reason"]},{"cell_type":"markdown","metadata":{"id":"_oYbBENpFSf6"},"source":["## Prep Data for Modeling "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6173,"status":"ok","timestamp":1659895522504,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"},"user_tz":240},"id":"PWovP-87Iq8t","outputId":"69abc852-afee-4818-a914-2c503f02c874"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: collinearity in /usr/local/lib/python3.7/dist-packages (0.6.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from collinearity) (1.21.6)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from collinearity) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->collinearity) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->collinearity) (1.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->collinearity) (1.7.3)\n"]}],"source":["!pip install collinearity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pkpv5iv36_LX"},"outputs":[],"source":["# Import necessary packages:\n","\n","import pandas as pd\n","import numpy as np\n","from numpy import mean\n","from numpy import absolute\n","from numpy import sqrt\n","from numpy import std\n","from collections import Counter\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import r2_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import make_regression\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import KFold\n","from sklearn.linear_model import Lasso\n","from sklearn.feature_selection import SelectFromModel\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.preprocessing import scale\n","from sklearn.feature_selection import RFE\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.pipeline import make_pipeline\n","from sklearn.feature_selection import f_regression\n","\n","import statsmodels.api as sm\n","from statsmodels.stats.outliers_influence import variance_inflation_factor\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","\n","from sklearn import svm\n","from scipy.stats import loguniform\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.svm import SVR\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.ensemble import GradientBoostingRegressor\n","\n","import seaborn as sns\n","\n","import scipy.stats as spstats\n","%matplotlib inline\n","\n","from collinearity import SelectNonCollinear"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nuzOYmc2V_ca"},"outputs":[],"source":["#importing libraries\n","from sklearn.datasets import load_boston\n","import pandas as pd\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import statsmodels.api as sm\n","%matplotlib inline\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_selection import RFE\n","from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-cbzDYqnV7qi"},"outputs":[],"source":["# Import necessary packages:\n","import pandas as pd\n","import numpy as np\n","from collections import Counter\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","\n","from sklearn import svm\n","from sklearn.metrics import mean_squared_error, r2_score\n","from xgboost import XGBClassifier \n","from sklearn import svm\n","# evaluate a logistic regression model using k-fold cross-validation\n","from numpy import mean\n","from numpy import std\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4c0dAYCKt5P7","executionInfo":{"status":"ok","timestamp":1659895524010,"user_tz":240,"elapsed":1327,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"21c86a41-c63b-41c4-b1b0-7aae5248930a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m2BsNuTKFSf6"},"outputs":[],"source":["#import AACT files - all diseases\n","master_disease_df = pd.read_csv(\"/content/drive/MyDrive/HIDS510/Collab Notebooks/Master Notebooks/master_clean_df.csv\", index_col=0)\n","master_ae_df = pd.read_csv(\"/content/drive/MyDrive/HIDS510/Collab Notebooks/Master Notebooks/master_ae.csv\")\n","master_dropout_df = pd.read_csv(\"/content/drive/MyDrive/HIDS510/Collab Notebooks/NLP Dropout Reason/Dropout Output Files/master_clean_dropout.csv\", index_col=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VZXCX6cfZ0OE"},"outputs":[],"source":["master_dropout_df = master_dropout_df.iloc[:, 0:9]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1659895524509,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"},"user_tz":240},"id":"yRtw8xCIFSf7","outputId":"0185d229-bd85-4bfe-ebe9-c8b7619fa4cc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0     0.660714\n","1     0.931818\n","2     0.960000\n","3     0.700000\n","4     0.360710\n","        ...   \n","44    0.750000\n","45    0.483660\n","46    0.795580\n","47    0.851528\n","48    0.500000\n","Name: percent_attrition, Length: 1359, dtype: float64"]},"metadata":{},"execution_count":113}],"source":["MIN = 100\n","MAX = 0\n","master_disease_df['percent_attrition'].sub(MIN).div(MAX-MIN).clip(0, 1)"]},{"cell_type":"markdown","metadata":{"id":"VMttpX0kFSf7"},"source":["Splittarget variable into 4 classifications based on distribution of clinical trial attrition with all neuropsychiatric trials"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hhGvHyUBFSf7"},"outputs":[],"source":["V4 = pd.merge(master_ae_df, master_disease_df, on='nct_id', how='inner')\n","V4_df = pd.merge(master_dropout_df, V4, on=['nct_id'], how='inner')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1659895524673,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"},"user_tz":240},"id":"GzXiALd0Y9cd","outputId":"05aaaf9a-34f3-4d0d-ec22-a21e32ccf44c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({\"Alzheimer's Disease\": 193,\n","         'Amyotrophic lateral sclerosis': 2,\n","         'Anxiety': 37,\n","         'Bipolar': 37,\n","         'Depression': 339,\n","         \"Parkinson's Disease\": 192})"]},"metadata":{},"execution_count":115}],"source":["Counter(V4_df['disease_type'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_1xW3ZkhFSf7"},"outputs":[],"source":["#drop nct_id, enrollment_total, drop_count_total, has_expanded_access column \n","V4_master_df = V4_df.drop(['nct_id', 'quantile_attrition_range', 'enrollment_total', 'drop_count_total', 'has_expanded_access'], axis = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kLGEUpQcFSf7"},"outputs":[],"source":["#convert booleon to binary : has_dmc\n","V4_master_df.has_dmc = V4_master_df.has_dmc.replace({True: 1, False: 0})\n","V4_master_df.health_status_eligibility = V4_master_df.health_status_eligibility.replace({'10.0': 0, 'No': 0, 'Accepts Healthy Volunteers' : 1})\n","#0-does not accept helathy volunteers 1-does accept healthy volunteers\n","V4_master_df.rename(columns = {'health_status_eligibility':'Accepts_Healthy_volunteers'}, inplace = True)\n","\n","#one-hot encode categorical colemsn : study_type, study_phase, minimum_age_num, intervention_model_type, allocation_type, masking_type, study_gender_eligibility\n","prefix_cols = ['study_type',  'study_phase', 'minimum_age_num', 'intervention_model_type', 'allocation_type', 'masking_type', 'study_gender_eligibility']\n","dummy_cols = ['study_type', 'study_phase', 'minimum_age_num', 'intervention_model_type', 'allocation_type', 'masking_type', 'study_gender_eligibility']\n","\n","V4_master_df = pd.get_dummies(V4_master_df, prefix=prefix_cols, columns=dummy_cols)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":139,"status":"ok","timestamp":1659895524810,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"},"user_tz":240},"id":"M_bhSSXQFSf7","outputId":"22019dd7-f14e-4f9f-828b-354258c663e5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  dropout_reason_consent withdrawn  \\\n","0                            22.0                               0.0   \n","1                            22.0                               0.0   \n","2                            22.0                               0.0   \n","3                            22.0                               0.0   \n","4                             0.0                               0.0   \n","..                            ...                               ...   \n","795                           0.0                               0.0   \n","796                           3.0                               0.0   \n","797                           1.0                               0.0   \n","798                           1.0                               1.0   \n","799                           0.0                               0.0   \n","\n","     dropout_reason_death  dropout_reason_inclusion/exclusion criteria issue  \\\n","0                     0.0                                                0.0   \n","1                     0.0                                                0.0   \n","2                     0.0                                                0.0   \n","3                     0.0                                                0.0   \n","4                     0.0                                                0.0   \n","..                    ...                                                ...   \n","795                   0.0                                                3.0   \n","796                   0.0                                                0.0   \n","797                   0.0                                                0.0   \n","798                   0.0                                                0.0   \n","799                   0.0                                                0.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","0                                0.0                               0.0   \n","1                                0.0                               0.0   \n","2                                0.0                               0.0   \n","3                                0.0                               0.0   \n","4                                0.0                               0.0   \n","..                               ...                               ...   \n","795                              0.0                               0.0   \n","796                              5.0                               0.0   \n","797                              1.0                               0.0   \n","798                              0.0                               0.0   \n","799                              0.0                               0.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","0                                  0.0                                0.0   \n","1                                  0.0                                0.0   \n","2                                  0.0                                0.0   \n","3                                  0.0                                0.0   \n","4                                  0.0                                4.0   \n","..                                 ...                                ...   \n","795                                0.0                                0.0   \n","796                                0.0                                0.0   \n","797                                0.0                                0.0   \n","798                                0.0                                0.0   \n","799                                1.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Influenza  ...  \\\n","0                                  0.0        0.0  ...   \n","1                                  0.0        0.0  ...   \n","2                                  0.0        0.0  ...   \n","3                                  0.0        0.0  ...   \n","4                                  0.0        0.0  ...   \n","..                                 ...        ...  ...   \n","795                                0.0        0.0  ...   \n","796                                1.0        0.0  ...   \n","797                                1.0        0.0  ...   \n","798                                0.0        0.0  ...   \n","799                                0.0        0.0  ...   \n","\n","     allocation_type_Randomized  masking_type_Double  \\\n","0                             1                    0   \n","1                             1                    0   \n","2                             1                    0   \n","3                             1                    0   \n","4                             1                    0   \n","..                          ...                  ...   \n","795                           0                    0   \n","796                           1                    0   \n","797                           0                    0   \n","798                           1                    0   \n","799                           1                    0   \n","\n","     masking_type_None (Open Label)  masking_type_Not Reported  \\\n","0                                 0                          0   \n","1                                 0                          0   \n","2                                 0                          0   \n","3                                 0                          0   \n","4                                 0                          0   \n","..                              ...                        ...   \n","795                               1                          0   \n","796                               0                          0   \n","797                               1                          0   \n","798                               0                          0   \n","799                               0                          0   \n","\n","     masking_type_Quadruple  masking_type_Single  masking_type_Triple  \\\n","0                         0                    0                    1   \n","1                         0                    0                    1   \n","2                         0                    0                    1   \n","3                         0                    0                    1   \n","4                         0                    1                    0   \n","..                      ...                  ...                  ...   \n","795                       0                    0                    0   \n","796                       1                    0                    0   \n","797                       0                    0                    0   \n","798                       1                    0                    0   \n","799                       0                    0                    1   \n","\n","     study_gender_eligibility_All  study_gender_eligibility_Female  \\\n","0                               1                                0   \n","1                               1                                0   \n","2                               1                                0   \n","3                               1                                0   \n","4                               1                                0   \n","..                            ...                              ...   \n","795                             1                                0   \n","796                             1                                0   \n","797                             1                                0   \n","798                             1                                0   \n","799                             1                                0   \n","\n","     study_gender_eligibility_Male  \n","0                                0  \n","1                                0  \n","2                                0  \n","3                                0  \n","4                                0  \n","..                             ...  \n","795                              0  \n","796                              0  \n","797                              0  \n","798                              0  \n","799                              0  \n","\n","[800 rows x 2013 columns]"],"text/html":["\n","  <div id=\"df-d4432705-af38-4b2e-a8d7-12aa5d637281\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>...</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Not Reported</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Female</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>795</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>796</th>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>797</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>798</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>799</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>800 rows × 2013 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4432705-af38-4b2e-a8d7-12aa5d637281')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d4432705-af38-4b2e-a8d7-12aa5d637281 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d4432705-af38-4b2e-a8d7-12aa5d637281');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":118}],"source":["V4_master_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1659895524810,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"},"user_tz":240},"id":"DCWtdaFyXKsq","outputId":"d41a19b2-fc5b-49df-9c99-ba22658a07e5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":119}],"source":["V4_master_df.isnull().sum().sum()"]},{"cell_type":"markdown","metadata":{"id":"2bdFCKVEFSf7"},"source":["## Depression"]},{"cell_type":"markdown","metadata":{"id":"BIEMLO9kFSf7"},"source":["### Subset Depression Studies / Split into test and train sets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qjFj3g8WFSf8"},"outputs":[],"source":["V4_depression_df = V4_master_df[V4_master_df['disease_type'] == \"Depression\"]\n","V4_depression_df = V4_depression_df.drop(columns=['disease_type', 'intervention_model_type_Sequential Assignment'])\n","\n","#split into features and outcome dataframes\n","X_df = V4_depression_df.drop(columns=['percent_attrition'])\n","y_df = V4_depression_df.percent_attrition"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1659896497184,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"},"user_tz":240},"id":"xkdOtgOKQMBB","outputId":"36e5d154-3e3a-43c1-91a8-ff2fec41dd5a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  dropout_reason_consent withdrawn  \\\n","0                            22.0                               0.0   \n","2                            22.0                               0.0   \n","4                             0.0                               0.0   \n","5                            10.0                               0.0   \n","7                            10.0                               0.0   \n","..                            ...                               ...   \n","403                           2.0                               0.0   \n","405                           9.0                               0.0   \n","406                           8.0                               0.0   \n","407                          13.0                               0.0   \n","408                           0.0                               0.0   \n","\n","     dropout_reason_death  dropout_reason_inclusion/exclusion criteria issue  \\\n","0                     0.0                                                0.0   \n","2                     0.0                                                0.0   \n","4                     0.0                                                0.0   \n","5                     0.0                                                3.0   \n","7                     0.0                                                3.0   \n","..                    ...                                                ...   \n","403                   0.0                                                0.0   \n","405                   0.0                                                0.0   \n","406                   0.0                                                3.0   \n","407                   0.0                                              114.0   \n","408                   0.0                                                0.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","0                                0.0                               0.0   \n","2                                0.0                               0.0   \n","4                                0.0                               0.0   \n","5                                0.0                               0.0   \n","7                                0.0                               0.0   \n","..                               ...                               ...   \n","403                              0.0                              10.0   \n","405                              0.0                               0.0   \n","406                              1.0                               2.0   \n","407                              7.0                               8.0   \n","408                              0.0                               6.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","0                                  0.0                                0.0   \n","2                                  0.0                                0.0   \n","4                                  0.0                                4.0   \n","5                                  0.0                                1.0   \n","7                                  0.0                                1.0   \n","..                                 ...                                ...   \n","403                                0.0                                0.0   \n","405                                0.0                                0.0   \n","406                                0.0                                4.0   \n","407                                1.0                                0.0   \n","408                                0.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Influenza  ...  \\\n","0                                  0.0        0.0  ...   \n","2                                  0.0        0.0  ...   \n","4                                  0.0        0.0  ...   \n","5                                  4.0        0.0  ...   \n","7                                  4.0        0.0  ...   \n","..                                 ...        ...  ...   \n","403                                4.0        0.0  ...   \n","405                                0.0        0.0  ...   \n","406                               10.0        0.0  ...   \n","407                               22.0        0.0  ...   \n","408                                4.0        0.0  ...   \n","\n","     allocation_type_Randomized  masking_type_Double  \\\n","0                             1                    0   \n","2                             1                    0   \n","4                             1                    0   \n","5                             1                    0   \n","7                             1                    0   \n","..                          ...                  ...   \n","403                           1                    0   \n","405                           0                    0   \n","406                           1                    0   \n","407                           0                    0   \n","408                           1                    1   \n","\n","     masking_type_None (Open Label)  masking_type_Not Reported  \\\n","0                                 0                          0   \n","2                                 0                          0   \n","4                                 0                          0   \n","5                                 0                          0   \n","7                                 0                          0   \n","..                              ...                        ...   \n","403                               1                          0   \n","405                               1                          0   \n","406                               0                          0   \n","407                               1                          0   \n","408                               0                          0   \n","\n","     masking_type_Quadruple  masking_type_Single  masking_type_Triple  \\\n","0                         0                    0                    1   \n","2                         0                    0                    1   \n","4                         0                    1                    0   \n","5                         1                    0                    0   \n","7                         1                    0                    0   \n","..                      ...                  ...                  ...   \n","403                       0                    0                    0   \n","405                       0                    0                    0   \n","406                       1                    0                    0   \n","407                       0                    0                    0   \n","408                       0                    0                    0   \n","\n","     study_gender_eligibility_All  study_gender_eligibility_Female  \\\n","0                               1                                0   \n","2                               1                                0   \n","4                               1                                0   \n","5                               1                                0   \n","7                               1                                0   \n","..                            ...                              ...   \n","403                             1                                0   \n","405                             1                                0   \n","406                             1                                0   \n","407                             1                                0   \n","408                             1                                0   \n","\n","     study_gender_eligibility_Male  \n","0                                0  \n","2                                0  \n","4                                0  \n","5                                0  \n","7                                0  \n","..                             ...  \n","403                              0  \n","405                              0  \n","406                              0  \n","407                              0  \n","408                              0  \n","\n","[339 rows x 2010 columns]"],"text/html":["\n","  <div id=\"df-e8c949b3-9830-476d-99cb-6c47c1e35055\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>...</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Not Reported</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Female</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>403</th>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>405</th>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>406</th>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>407</th>\n","      <td>13.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>114.0</td>\n","      <td>7.0</td>\n","      <td>8.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>408</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>339 rows × 2010 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8c949b3-9830-476d-99cb-6c47c1e35055')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e8c949b3-9830-476d-99cb-6c47c1e35055 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e8c949b3-9830-476d-99cb-6c47c1e35055');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":144}],"source":["X_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ilON4ZOQJ7z"},"outputs":[],"source":["#select all ae columns\n","ae_df = X_df.iloc[:,9:1962]\n","\n","#replace all non zero cells with 1\n","ae_df[ae_df != 0] = 1\n","\n","#add all columns and select the top ten most prevelant\n","s = ae_df.sum()\n","top_ae_table = ae_df[s.sort_values(ascending=False).index[:10]]\n","\n","#generated list of most prevelant ae\n","top_ae_table_list = list(top_ae_table.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1659896497352,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"},"user_tz":240},"id":"ljyZpgufUhxU","outputId":"7408d50b-1144-4b10-f14f-22f2df24b09d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(339, 2010)"]},"metadata":{},"execution_count":146}],"source":["X_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1659896497352,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"},"user_tz":240},"id":"N8OxFgIJq2Cy","outputId":"e8a74984-53eb-4555-9791-10c0a719dccc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  dropout_reason_consent withdrawn  \\\n","0                            22.0                               0.0   \n","2                            22.0                               0.0   \n","4                             0.0                               0.0   \n","5                            10.0                               0.0   \n","7                            10.0                               0.0   \n","..                            ...                               ...   \n","403                           2.0                               0.0   \n","405                           9.0                               0.0   \n","406                           8.0                               0.0   \n","407                          13.0                               0.0   \n","408                           0.0                               0.0   \n","\n","     dropout_reason_death  dropout_reason_inclusion/exclusion criteria issue  \\\n","0                     0.0                                                0.0   \n","2                     0.0                                                0.0   \n","4                     0.0                                                0.0   \n","5                     0.0                                                3.0   \n","7                     0.0                                                3.0   \n","..                    ...                                                ...   \n","403                   0.0                                                0.0   \n","405                   0.0                                                0.0   \n","406                   0.0                                                3.0   \n","407                   0.0                                              114.0   \n","408                   0.0                                                0.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","0                                0.0                               0.0   \n","2                                0.0                               0.0   \n","4                                0.0                               0.0   \n","5                                0.0                               0.0   \n","7                                0.0                               0.0   \n","..                               ...                               ...   \n","403                              0.0                              10.0   \n","405                              0.0                               0.0   \n","406                              1.0                               2.0   \n","407                              7.0                               8.0   \n","408                              0.0                               6.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","0                                  0.0                                0.0   \n","2                                  0.0                                0.0   \n","4                                  0.0                                4.0   \n","5                                  0.0                                1.0   \n","7                                  0.0                                1.0   \n","..                                 ...                                ...   \n","403                                0.0                                0.0   \n","405                                0.0                                0.0   \n","406                                0.0                                4.0   \n","407                                1.0                                0.0   \n","408                                0.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Influenza  ...  \\\n","0                                  0.0        0.0  ...   \n","2                                  0.0        0.0  ...   \n","4                                  0.0        0.0  ...   \n","5                                  4.0        0.0  ...   \n","7                                  4.0        0.0  ...   \n","..                                 ...        ...  ...   \n","403                                4.0        0.0  ...   \n","405                                0.0        0.0  ...   \n","406                               10.0        0.0  ...   \n","407                               22.0        0.0  ...   \n","408                                4.0        0.0  ...   \n","\n","     allocation_type_Randomized  masking_type_Double  \\\n","0                             1                    0   \n","2                             1                    0   \n","4                             1                    0   \n","5                             1                    0   \n","7                             1                    0   \n","..                          ...                  ...   \n","403                           1                    0   \n","405                           0                    0   \n","406                           1                    0   \n","407                           0                    0   \n","408                           1                    1   \n","\n","     masking_type_None (Open Label)  masking_type_Not Reported  \\\n","0                                 0                          0   \n","2                                 0                          0   \n","4                                 0                          0   \n","5                                 0                          0   \n","7                                 0                          0   \n","..                              ...                        ...   \n","403                               1                          0   \n","405                               1                          0   \n","406                               0                          0   \n","407                               1                          0   \n","408                               0                          0   \n","\n","     masking_type_Quadruple  masking_type_Single  masking_type_Triple  \\\n","0                         0                    0                    1   \n","2                         0                    0                    1   \n","4                         0                    1                    0   \n","5                         1                    0                    0   \n","7                         1                    0                    0   \n","..                      ...                  ...                  ...   \n","403                       0                    0                    0   \n","405                       0                    0                    0   \n","406                       1                    0                    0   \n","407                       0                    0                    0   \n","408                       0                    0                    0   \n","\n","     study_gender_eligibility_All  study_gender_eligibility_Female  \\\n","0                               1                                0   \n","2                               1                                0   \n","4                               1                                0   \n","5                               1                                0   \n","7                               1                                0   \n","..                            ...                              ...   \n","403                             1                                0   \n","405                             1                                0   \n","406                             1                                0   \n","407                             1                                0   \n","408                             1                                0   \n","\n","     study_gender_eligibility_Male  \n","0                                0  \n","2                                0  \n","4                                0  \n","5                                0  \n","7                                0  \n","..                             ...  \n","403                              0  \n","405                              0  \n","406                              0  \n","407                              0  \n","408                              0  \n","\n","[339 rows x 554 columns]"],"text/html":["\n","  <div id=\"df-669986e1-bdd3-479e-896c-6469fbecf029\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>...</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Not Reported</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Female</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>403</th>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>405</th>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>406</th>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>407</th>\n","      <td>13.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>114.0</td>\n","      <td>7.0</td>\n","      <td>8.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>408</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>339 rows × 554 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-669986e1-bdd3-479e-896c-6469fbecf029')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-669986e1-bdd3-479e-896c-6469fbecf029 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-669986e1-bdd3-479e-896c-6469fbecf029');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":147}],"source":["X_df = X_df.loc[:, (X_df != 0).any(axis=0)]\n","X_df"]},{"cell_type":"markdown","metadata":{"id":"nhiZsjPcI3nY"},"source":["### Colinearity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PVHikwT8H-W5"},"outputs":[],"source":["from statsmodels.stats.outliers_influence import variance_inflation_factor    \n","\n","def calculate_vif_(X_df, thresh=4.0):\n","    variables = list(range(X_df.shape[1]))\n","    dropped = True\n","    while dropped:\n","        dropped = False\n","        vif = [variance_inflation_factor(X_df.iloc[:, variables].values, ix)\n","               for ix in range(X_df.iloc[:, variables].shape[1])]\n","\n","        maxloc = vif.index(max(vif))\n","        if max(vif) > thresh:\n","            print('dropping \\'' + X_df.iloc[:, variables].columns[maxloc] +\n","                  '\\' at index: ' + str(maxloc))\n","            del variables[maxloc]\n","            dropped = True\n","\n","    print('Remaining variables:')\n","    print(X_df.columns[variables])\n","    return X_df.iloc[:, variables]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1659896497699,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"},"user_tz":240},"id":"F-Hd6Je5ILWt","outputId":"5e7e5acb-c233-43f5-b7a8-7b2207935ecd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  dropout_reason_consent withdrawn  \\\n","0                            22.0                               0.0   \n","2                            22.0                               0.0   \n","4                             0.0                               0.0   \n","5                            10.0                               0.0   \n","7                            10.0                               0.0   \n","..                            ...                               ...   \n","403                           2.0                               0.0   \n","405                           9.0                               0.0   \n","406                           8.0                               0.0   \n","407                          13.0                               0.0   \n","408                           0.0                               0.0   \n","\n","     dropout_reason_death  dropout_reason_inclusion/exclusion criteria issue  \\\n","0                     0.0                                                0.0   \n","2                     0.0                                                0.0   \n","4                     0.0                                                0.0   \n","5                     0.0                                                3.0   \n","7                     0.0                                                3.0   \n","..                    ...                                                ...   \n","403                   0.0                                                0.0   \n","405                   0.0                                                0.0   \n","406                   0.0                                                3.0   \n","407                   0.0                                              114.0   \n","408                   0.0                                                0.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","0                                0.0                               0.0   \n","2                                0.0                               0.0   \n","4                                0.0                               0.0   \n","5                                0.0                               0.0   \n","7                                0.0                               0.0   \n","..                               ...                               ...   \n","403                              0.0                              10.0   \n","405                              0.0                               0.0   \n","406                              1.0                               2.0   \n","407                              7.0                               8.0   \n","408                              0.0                               6.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","0                                  0.0                                0.0   \n","2                                  0.0                                0.0   \n","4                                  0.0                                4.0   \n","5                                  0.0                                1.0   \n","7                                  0.0                                1.0   \n","..                                 ...                                ...   \n","403                                0.0                                0.0   \n","405                                0.0                                0.0   \n","406                                0.0                                4.0   \n","407                                1.0                                0.0   \n","408                                0.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Influenza  ...  \\\n","0                                  0.0        0.0  ...   \n","2                                  0.0        0.0  ...   \n","4                                  0.0        0.0  ...   \n","5                                  4.0        0.0  ...   \n","7                                  4.0        0.0  ...   \n","..                                 ...        ...  ...   \n","403                                4.0        0.0  ...   \n","405                                0.0        0.0  ...   \n","406                               10.0        0.0  ...   \n","407                               22.0        0.0  ...   \n","408                                4.0        0.0  ...   \n","\n","     allocation_type_Randomized  masking_type_Double  \\\n","0                             1                    0   \n","2                             1                    0   \n","4                             1                    0   \n","5                             1                    0   \n","7                             1                    0   \n","..                          ...                  ...   \n","403                           1                    0   \n","405                           0                    0   \n","406                           1                    0   \n","407                           0                    0   \n","408                           1                    1   \n","\n","     masking_type_None (Open Label)  masking_type_Not Reported  \\\n","0                                 0                          0   \n","2                                 0                          0   \n","4                                 0                          0   \n","5                                 0                          0   \n","7                                 0                          0   \n","..                              ...                        ...   \n","403                               1                          0   \n","405                               1                          0   \n","406                               0                          0   \n","407                               1                          0   \n","408                               0                          0   \n","\n","     masking_type_Quadruple  masking_type_Single  masking_type_Triple  \\\n","0                         0                    0                    1   \n","2                         0                    0                    1   \n","4                         0                    1                    0   \n","5                         1                    0                    0   \n","7                         1                    0                    0   \n","..                      ...                  ...                  ...   \n","403                       0                    0                    0   \n","405                       0                    0                    0   \n","406                       1                    0                    0   \n","407                       0                    0                    0   \n","408                       0                    0                    0   \n","\n","     study_gender_eligibility_All  study_gender_eligibility_Female  \\\n","0                               1                                0   \n","2                               1                                0   \n","4                               1                                0   \n","5                               1                                0   \n","7                               1                                0   \n","..                            ...                              ...   \n","403                             1                                0   \n","405                             1                                0   \n","406                             1                                0   \n","407                             1                                0   \n","408                             1                                0   \n","\n","     study_gender_eligibility_Male  \n","0                                0  \n","2                                0  \n","4                                0  \n","5                                0  \n","7                                0  \n","..                             ...  \n","403                              0  \n","405                              0  \n","406                              0  \n","407                              0  \n","408                              0  \n","\n","[339 rows x 554 columns]"],"text/html":["\n","  <div id=\"df-dc13b85a-6b8a-4424-b045-3665ced8e000\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>...</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Not Reported</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Female</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>403</th>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>405</th>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>406</th>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>407</th>\n","      <td>13.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>114.0</td>\n","      <td>7.0</td>\n","      <td>8.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>408</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>339 rows × 554 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc13b85a-6b8a-4424-b045-3665ced8e000')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-dc13b85a-6b8a-4424-b045-3665ced8e000 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-dc13b85a-6b8a-4424-b045-3665ced8e000');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":149}],"source":["X_df"]},{"cell_type":"markdown","metadata":{"id":"t4MPPclYDYWa"},"source":["### Corelated Feature Drop"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":334},"executionInfo":{"elapsed":371,"status":"ok","timestamp":1659896498424,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"},"user_tz":240},"id":"nlq2tsrDPtHu","outputId":"b952217b-ae31-49bf-9aaf-39bebdd4e1fa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   dropout_reason_adverse event  \\\n","dropout_reason_adverse event                                           1.000000   \n","dropout_reason_consent withdrawn                                       0.236928   \n","dropout_reason_death                                                   0.050688   \n","dropout_reason_inclusion/exclusion criteria issue                      0.592236   \n","dropout_reason_lack of efficacy                                        0.569987   \n","\n","                                                   dropout_reason_consent withdrawn  \\\n","dropout_reason_adverse event                                               0.236928   \n","dropout_reason_consent withdrawn                                           1.000000   \n","dropout_reason_death                                                      -0.033768   \n","dropout_reason_inclusion/exclusion criteria issue                          0.030314   \n","dropout_reason_lack of efficacy                                            0.045809   \n","\n","                                                   dropout_reason_death  \\\n","dropout_reason_adverse event                                   0.050688   \n","dropout_reason_consent withdrawn                              -0.033768   \n","dropout_reason_death                                           1.000000   \n","dropout_reason_inclusion/exclusion criteria issue              0.056496   \n","dropout_reason_lack of efficacy                                0.104402   \n","\n","                                                   dropout_reason_inclusion/exclusion criteria issue  \\\n","dropout_reason_adverse event                                                                0.592236   \n","dropout_reason_consent withdrawn                                                            0.030314   \n","dropout_reason_death                                                                        0.056496   \n","dropout_reason_inclusion/exclusion criteria issue                                           1.000000   \n","dropout_reason_lack of efficacy                                                             0.418130   \n","\n","                                                   dropout_reason_lack of efficacy  \\\n","dropout_reason_adverse event                                              0.569987   \n","dropout_reason_consent withdrawn                                          0.045809   \n","dropout_reason_death                                                      0.104402   \n","dropout_reason_inclusion/exclusion criteria issue                         0.418130   \n","dropout_reason_lack of efficacy                                           1.000000   \n","\n","                                                   dropout_reason_lost to follow-up  \\\n","dropout_reason_adverse event                                               0.663702   \n","dropout_reason_consent withdrawn                                           0.216796   \n","dropout_reason_death                                                       0.166846   \n","dropout_reason_inclusion/exclusion criteria issue                          0.429081   \n","dropout_reason_lack of efficacy                                            0.365045   \n","\n","                                                   dropout_reason_physician decision  \\\n","dropout_reason_adverse event                                                0.227710   \n","dropout_reason_consent withdrawn                                           -0.057828   \n","dropout_reason_death                                                        0.000384   \n","dropout_reason_inclusion/exclusion criteria issue                           0.081411   \n","dropout_reason_lack of efficacy                                             0.087598   \n","\n","                                                   dropout_reason_protocol violation  \\\n","dropout_reason_adverse event                                                0.681694   \n","dropout_reason_consent withdrawn                                            0.290410   \n","dropout_reason_death                                                       -0.035764   \n","dropout_reason_inclusion/exclusion criteria issue                           0.355182   \n","dropout_reason_lack of efficacy                                             0.243812   \n","\n","                                                   dropout_reason_subject withdrawal  \\\n","dropout_reason_adverse event                                                0.673219   \n","dropout_reason_consent withdrawn                                           -0.108052   \n","dropout_reason_death                                                        0.165816   \n","dropout_reason_inclusion/exclusion criteria issue                           0.402866   \n","dropout_reason_lack of efficacy                                             0.386981   \n","\n","                                                   Influenza  ...  \\\n","dropout_reason_adverse event                       -0.057171  ...   \n","dropout_reason_consent withdrawn                   -0.024285  ...   \n","dropout_reason_death                               -0.016003  ...   \n","dropout_reason_inclusion/exclusion criteria issue  -0.032966  ...   \n","dropout_reason_lack of efficacy                    -0.027997  ...   \n","\n","                                                   allocation_type_Randomized  \\\n","dropout_reason_adverse event                                        -0.003499   \n","dropout_reason_consent withdrawn                                    -0.038401   \n","dropout_reason_death                                                 0.035980   \n","dropout_reason_inclusion/exclusion criteria issue                   -0.094862   \n","dropout_reason_lack of efficacy                                      0.017603   \n","\n","                                                   masking_type_Double  \\\n","dropout_reason_adverse event                                 -0.044567   \n","dropout_reason_consent withdrawn                              0.046037   \n","dropout_reason_death                                         -0.058782   \n","dropout_reason_inclusion/exclusion criteria issue            -0.012105   \n","dropout_reason_lack of efficacy                               0.013323   \n","\n","                                                   masking_type_None (Open Label)  \\\n","dropout_reason_adverse event                                             0.003703   \n","dropout_reason_consent withdrawn                                         0.001759   \n","dropout_reason_death                                                     0.089205   \n","dropout_reason_inclusion/exclusion criteria issue                        0.073121   \n","dropout_reason_lack of efficacy                                          0.047799   \n","\n","                                                   masking_type_Not Reported  \\\n","dropout_reason_adverse event                                       -0.056593   \n","dropout_reason_consent withdrawn                                   -0.024735   \n","dropout_reason_death                                               -0.016300   \n","dropout_reason_inclusion/exclusion criteria issue                  -0.033578   \n","dropout_reason_lack of efficacy                                    -0.029400   \n","\n","                                                   masking_type_Quadruple  \\\n","dropout_reason_adverse event                                     0.040543   \n","dropout_reason_consent withdrawn                                -0.046656   \n","dropout_reason_death                                            -0.031071   \n","dropout_reason_inclusion/exclusion criteria issue                0.001313   \n","dropout_reason_lack of efficacy                                  0.015803   \n","\n","                                                   masking_type_Single  \\\n","dropout_reason_adverse event                                 -0.117357   \n","dropout_reason_consent withdrawn                             -0.050382   \n","dropout_reason_death                                          0.057242   \n","dropout_reason_inclusion/exclusion criteria issue            -0.053890   \n","dropout_reason_lack of efficacy                              -0.059881   \n","\n","                                                   masking_type_Triple  \\\n","dropout_reason_adverse event                                  0.074695   \n","dropout_reason_consent withdrawn                              0.043163   \n","dropout_reason_death                                         -0.038576   \n","dropout_reason_inclusion/exclusion criteria issue            -0.038335   \n","dropout_reason_lack of efficacy                              -0.048964   \n","\n","                                                   study_gender_eligibility_All  \\\n","dropout_reason_adverse event                                           0.093445   \n","dropout_reason_consent withdrawn                                       0.061071   \n","dropout_reason_death                                                   0.031771   \n","dropout_reason_inclusion/exclusion criteria issue                      0.064637   \n","dropout_reason_lack of efficacy                                        0.052537   \n","\n","                                                   study_gender_eligibility_Female  \\\n","dropout_reason_adverse event                                             -0.074829   \n","dropout_reason_consent withdrawn                                         -0.055159   \n","dropout_reason_death                                                     -0.027084   \n","dropout_reason_inclusion/exclusion criteria issue                        -0.054907   \n","dropout_reason_lack of efficacy                                          -0.043639   \n","\n","                                                   study_gender_eligibility_Male  \n","dropout_reason_adverse event                                           -0.058233  \n","dropout_reason_consent withdrawn                                       -0.024735  \n","dropout_reason_death                                                   -0.016300  \n","dropout_reason_inclusion/exclusion criteria issue                      -0.033578  \n","dropout_reason_lack of efficacy                                        -0.029400  \n","\n","[5 rows x 554 columns]"],"text/html":["\n","  <div id=\"df-ee3bc826-2d01-4e1b-a039-9195bfb85bf0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>...</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Not Reported</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Female</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>dropout_reason_adverse event</th>\n","      <td>1.000000</td>\n","      <td>0.236928</td>\n","      <td>0.050688</td>\n","      <td>0.592236</td>\n","      <td>0.569987</td>\n","      <td>0.663702</td>\n","      <td>0.227710</td>\n","      <td>0.681694</td>\n","      <td>0.673219</td>\n","      <td>-0.057171</td>\n","      <td>...</td>\n","      <td>-0.003499</td>\n","      <td>-0.044567</td>\n","      <td>0.003703</td>\n","      <td>-0.056593</td>\n","      <td>0.040543</td>\n","      <td>-0.117357</td>\n","      <td>0.074695</td>\n","      <td>0.093445</td>\n","      <td>-0.074829</td>\n","      <td>-0.058233</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <td>0.236928</td>\n","      <td>1.000000</td>\n","      <td>-0.033768</td>\n","      <td>0.030314</td>\n","      <td>0.045809</td>\n","      <td>0.216796</td>\n","      <td>-0.057828</td>\n","      <td>0.290410</td>\n","      <td>-0.108052</td>\n","      <td>-0.024285</td>\n","      <td>...</td>\n","      <td>-0.038401</td>\n","      <td>0.046037</td>\n","      <td>0.001759</td>\n","      <td>-0.024735</td>\n","      <td>-0.046656</td>\n","      <td>-0.050382</td>\n","      <td>0.043163</td>\n","      <td>0.061071</td>\n","      <td>-0.055159</td>\n","      <td>-0.024735</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_death</th>\n","      <td>0.050688</td>\n","      <td>-0.033768</td>\n","      <td>1.000000</td>\n","      <td>0.056496</td>\n","      <td>0.104402</td>\n","      <td>0.166846</td>\n","      <td>0.000384</td>\n","      <td>-0.035764</td>\n","      <td>0.165816</td>\n","      <td>-0.016003</td>\n","      <td>...</td>\n","      <td>0.035980</td>\n","      <td>-0.058782</td>\n","      <td>0.089205</td>\n","      <td>-0.016300</td>\n","      <td>-0.031071</td>\n","      <td>0.057242</td>\n","      <td>-0.038576</td>\n","      <td>0.031771</td>\n","      <td>-0.027084</td>\n","      <td>-0.016300</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <td>0.592236</td>\n","      <td>0.030314</td>\n","      <td>0.056496</td>\n","      <td>1.000000</td>\n","      <td>0.418130</td>\n","      <td>0.429081</td>\n","      <td>0.081411</td>\n","      <td>0.355182</td>\n","      <td>0.402866</td>\n","      <td>-0.032966</td>\n","      <td>...</td>\n","      <td>-0.094862</td>\n","      <td>-0.012105</td>\n","      <td>0.073121</td>\n","      <td>-0.033578</td>\n","      <td>0.001313</td>\n","      <td>-0.053890</td>\n","      <td>-0.038335</td>\n","      <td>0.064637</td>\n","      <td>-0.054907</td>\n","      <td>-0.033578</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <td>0.569987</td>\n","      <td>0.045809</td>\n","      <td>0.104402</td>\n","      <td>0.418130</td>\n","      <td>1.000000</td>\n","      <td>0.365045</td>\n","      <td>0.087598</td>\n","      <td>0.243812</td>\n","      <td>0.386981</td>\n","      <td>-0.027997</td>\n","      <td>...</td>\n","      <td>0.017603</td>\n","      <td>0.013323</td>\n","      <td>0.047799</td>\n","      <td>-0.029400</td>\n","      <td>0.015803</td>\n","      <td>-0.059881</td>\n","      <td>-0.048964</td>\n","      <td>0.052537</td>\n","      <td>-0.043639</td>\n","      <td>-0.029400</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 554 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee3bc826-2d01-4e1b-a039-9195bfb85bf0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ee3bc826-2d01-4e1b-a039-9195bfb85bf0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ee3bc826-2d01-4e1b-a039-9195bfb85bf0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":150}],"source":["df_corr = X_df.corr()\n","df_corr.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iHnLEyoePxu-"},"outputs":[],"source":["threshold = 0.9\n","\n","\n","columns = np.full((df_corr.shape[0],), True, dtype=bool)\n","for i in range(df_corr.shape[0]):\n","    for j in range(i+1, df_corr.shape[0]):\n","        if df_corr.iloc[i,j] >= threshold:\n","            if columns[j]:\n","                columns[j] = False\n","selected_columns = X_df.columns[columns]\n","selected_columns\n","X_df = X_df[selected_columns]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1659896504063,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"},"user_tz":240},"id":"8RfsGIpIP7_1","outputId":"5bea112d-4815-40ad-a6f7-bf52bd066974"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  dropout_reason_consent withdrawn  \\\n","0                            22.0                               0.0   \n","2                            22.0                               0.0   \n","4                             0.0                               0.0   \n","5                            10.0                               0.0   \n","7                            10.0                               0.0   \n","..                            ...                               ...   \n","403                           2.0                               0.0   \n","405                           9.0                               0.0   \n","406                           8.0                               0.0   \n","407                          13.0                               0.0   \n","408                           0.0                               0.0   \n","\n","     dropout_reason_death  dropout_reason_inclusion/exclusion criteria issue  \\\n","0                     0.0                                                0.0   \n","2                     0.0                                                0.0   \n","4                     0.0                                                0.0   \n","5                     0.0                                                3.0   \n","7                     0.0                                                3.0   \n","..                    ...                                                ...   \n","403                   0.0                                                0.0   \n","405                   0.0                                                0.0   \n","406                   0.0                                                3.0   \n","407                   0.0                                              114.0   \n","408                   0.0                                                0.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","0                                0.0                               0.0   \n","2                                0.0                               0.0   \n","4                                0.0                               0.0   \n","5                                0.0                               0.0   \n","7                                0.0                               0.0   \n","..                               ...                               ...   \n","403                              0.0                              10.0   \n","405                              0.0                               0.0   \n","406                              1.0                               2.0   \n","407                              7.0                               8.0   \n","408                              0.0                               6.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","0                                  0.0                                0.0   \n","2                                  0.0                                0.0   \n","4                                  0.0                                4.0   \n","5                                  0.0                                1.0   \n","7                                  0.0                                1.0   \n","..                                 ...                                ...   \n","403                                0.0                                0.0   \n","405                                0.0                                0.0   \n","406                                0.0                                4.0   \n","407                                1.0                                0.0   \n","408                                0.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Influenza  ...  \\\n","0                                  0.0        0.0  ...   \n","2                                  0.0        0.0  ...   \n","4                                  0.0        0.0  ...   \n","5                                  4.0        0.0  ...   \n","7                                  4.0        0.0  ...   \n","..                                 ...        ...  ...   \n","403                                4.0        0.0  ...   \n","405                                0.0        0.0  ...   \n","406                               10.0        0.0  ...   \n","407                               22.0        0.0  ...   \n","408                                4.0        0.0  ...   \n","\n","     allocation_type_Not Reported  allocation_type_Randomized  \\\n","0                               0                           1   \n","2                               0                           1   \n","4                               0                           1   \n","5                               0                           1   \n","7                               0                           1   \n","..                            ...                         ...   \n","403                             0                           1   \n","405                             1                           0   \n","406                             0                           1   \n","407                             1                           0   \n","408                             0                           1   \n","\n","     masking_type_Double  masking_type_None (Open Label)  \\\n","0                      0                               0   \n","2                      0                               0   \n","4                      0                               0   \n","5                      0                               0   \n","7                      0                               0   \n","..                   ...                             ...   \n","403                    0                               1   \n","405                    0                               1   \n","406                    0                               0   \n","407                    0                               1   \n","408                    1                               0   \n","\n","     masking_type_Quadruple  masking_type_Single  masking_type_Triple  \\\n","0                         0                    0                    1   \n","2                         0                    0                    1   \n","4                         0                    1                    0   \n","5                         1                    0                    0   \n","7                         1                    0                    0   \n","..                      ...                  ...                  ...   \n","403                       0                    0                    0   \n","405                       0                    0                    0   \n","406                       1                    0                    0   \n","407                       0                    0                    0   \n","408                       0                    0                    0   \n","\n","     study_gender_eligibility_All  study_gender_eligibility_Female  \\\n","0                               1                                0   \n","2                               1                                0   \n","4                               1                                0   \n","5                               1                                0   \n","7                               1                                0   \n","..                            ...                              ...   \n","403                             1                                0   \n","405                             1                                0   \n","406                             1                                0   \n","407                             1                                0   \n","408                             1                                0   \n","\n","     study_gender_eligibility_Male  \n","0                                0  \n","2                                0  \n","4                                0  \n","5                                0  \n","7                                0  \n","..                             ...  \n","403                              0  \n","405                              0  \n","406                              0  \n","407                              0  \n","408                              0  \n","\n","[339 rows x 334 columns]"],"text/html":["\n","  <div id=\"df-8ae2e610-8278-4c67-b787-d03025a74853\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>...</th>\n","      <th>allocation_type_Not Reported</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Female</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>403</th>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>405</th>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>406</th>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>407</th>\n","      <td>13.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>114.0</td>\n","      <td>7.0</td>\n","      <td>8.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>408</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>339 rows × 334 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ae2e610-8278-4c67-b787-d03025a74853')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8ae2e610-8278-4c67-b787-d03025a74853 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8ae2e610-8278-4c67-b787-d03025a74853');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":152}],"source":["X_df"]},{"cell_type":"markdown","metadata":{"id":"v7c-zHX6QO9z"},"source":["Standardize and split data "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"27K1EqbuT-Pb"},"outputs":[],"source":["X_df_norm = (X_df-X_df.min())/(X_df.max()-X_df.min())"]},{"cell_type":"code","source":["mean(y_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DFxP67vjiqtF","executionInfo":{"status":"ok","timestamp":1659896520266,"user_tz":240,"elapsed":140,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"4a8b1137-40d7-461f-bc26-d24b69e77583"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["25.157495598463377"]},"metadata":{},"execution_count":155}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1659896504229,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"},"user_tz":240},"id":"yhPRxF5rL4v0","outputId":"cd11dfb5-e08c-4efd-cffe-24d95e4df318"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((271, 334), (68, 334))"]},"metadata":{},"execution_count":154}],"source":["# Train/test split:\n","X_train, X_test, y_train, y_test = train_test_split(X_df_norm, y_df, test_size = 0.2, random_state = 2)\n","\n","X_train.shape, X_test.shape"]},{"cell_type":"markdown","metadata":{"id":"xg9MlhCvOPxy"},"source":["### Feature Selection"]},{"cell_type":"markdown","metadata":{"id":"Fz5X_QitOPxz"},"source":["#### Feature Importance with Gradient Boosting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sKzmCz9FOPxz","executionInfo":{"status":"ok","timestamp":1659890131292,"user_tz":240,"elapsed":178,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4661acf5-1779-49c7-f5d4-3335c78e0fb7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4288759363250807"]},"metadata":{},"execution_count":28}],"source":["# GradientBoostingRegressor will be used for feature importance\n","reg_model = GradientBoostingRegressor(random_state=0)   \n","reg_model.fit(X_train, y_train)\n","y_preds = reg_model.predict(X_test)\n","r2_score(y_test, y_preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fLxEvCpwOPxz","executionInfo":{"status":"ok","timestamp":1659890131293,"user_tz":240,"elapsed":4,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"colab":{"base_uri":"https://localhost:8080/","height":676},"outputId":"a0c48973-a909-4f20-dca5-cf341bbe25e2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   importance\n","dropout_reason_inclusion/exclusion criteria issue    0.318439\n","dropout_reason_lost to follow-up                     0.058545\n","event_type_other                                     0.045327\n","Headache                                             0.040401\n","study_duration_months                                0.038388\n","Abdominal pain                                       0.037683\n","intervention_model_type_Factorial Assignment         0.037326\n","Genetic                                              0.034936\n","Nausea                                               0.028028\n","dropout_reason_adverse event                         0.025854\n","Dissociation                                         0.024618\n","Overdose                                             0.022068\n","dropout_reason_subject withdrawal                    0.017419\n","Glossitis                                            0.017076\n","Major depression                                     0.013135\n","masking_type_Quadruple                               0.012135\n","Lethargy                                             0.011323\n","Tremor                                               0.010559\n","intervention_model_type_Single Group Assignment      0.010132\n","dropout_reason_lack of efficacy                      0.009232"],"text/html":["\n","  <div id=\"df-94066c3e-bb63-41de-87b5-f6560594c6e0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>importance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <td>0.318439</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <td>0.058545</td>\n","    </tr>\n","    <tr>\n","      <th>event_type_other</th>\n","      <td>0.045327</td>\n","    </tr>\n","    <tr>\n","      <th>Headache</th>\n","      <td>0.040401</td>\n","    </tr>\n","    <tr>\n","      <th>study_duration_months</th>\n","      <td>0.038388</td>\n","    </tr>\n","    <tr>\n","      <th>Abdominal pain</th>\n","      <td>0.037683</td>\n","    </tr>\n","    <tr>\n","      <th>intervention_model_type_Factorial Assignment</th>\n","      <td>0.037326</td>\n","    </tr>\n","    <tr>\n","      <th>Genetic</th>\n","      <td>0.034936</td>\n","    </tr>\n","    <tr>\n","      <th>Nausea</th>\n","      <td>0.028028</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_adverse event</th>\n","      <td>0.025854</td>\n","    </tr>\n","    <tr>\n","      <th>Dissociation</th>\n","      <td>0.024618</td>\n","    </tr>\n","    <tr>\n","      <th>Overdose</th>\n","      <td>0.022068</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <td>0.017419</td>\n","    </tr>\n","    <tr>\n","      <th>Glossitis</th>\n","      <td>0.017076</td>\n","    </tr>\n","    <tr>\n","      <th>Major depression</th>\n","      <td>0.013135</td>\n","    </tr>\n","    <tr>\n","      <th>masking_type_Quadruple</th>\n","      <td>0.012135</td>\n","    </tr>\n","    <tr>\n","      <th>Lethargy</th>\n","      <td>0.011323</td>\n","    </tr>\n","    <tr>\n","      <th>Tremor</th>\n","      <td>0.010559</td>\n","    </tr>\n","    <tr>\n","      <th>intervention_model_type_Single Group Assignment</th>\n","      <td>0.010132</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <td>0.009232</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94066c3e-bb63-41de-87b5-f6560594c6e0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-94066c3e-bb63-41de-87b5-f6560594c6e0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-94066c3e-bb63-41de-87b5-f6560594c6e0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":29}],"source":["feature_imp = pd.DataFrame(reg_model.feature_importances_,\n","                                   index = X_train.columns,\n","                                   columns=['importance']).sort_values('importance', ascending=False)\n","\n","feature_imp.head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rRKJQsdSOPxz"},"outputs":[],"source":["#create list of top 30 features\n","boost_top_10 = feature_imp.head(10).index.values\n","boost_top_10_list = list(boost_top_10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xgNPkQU_OPxz"},"outputs":[],"source":["X_boost_df = X_df[X_df.columns.intersection(boost_top_10_list)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5XDdvGmUOPxz","executionInfo":{"status":"ok","timestamp":1659890131482,"user_tz":240,"elapsed":3,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9298c539-76d9-4551-f6a0-512d56403e0f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((271, 10), (68, 10))"]},"metadata":{},"execution_count":32}],"source":["# Train/test split:\n","X_boost_train, X_boost_test, y_train, y_test = train_test_split(X_boost_df, y_df, test_size = 0.2, random_state = 2)\n","\n","X_boost_train.shape, X_boost_test.shape"]},{"cell_type":"markdown","source":["##### Model Set-up"],"metadata":{"id":"vuuCgEmTVbd6"}},{"cell_type":"code","source":["# Continous outcome prediction:\n","\n","def train_and_test(reg_model, X_train, y_train, X_test, y_test):\n","  reg_model.fit(X_train, y_train)\n","  # Make predictions with model\n","  y_pred = reg_model.predict(X_test)\n","  #Metrics\n","  mse_score_val = mean_squared_error(y_test, y_pred)\n","  r2_score_val = r2_score(y_test, y_pred)\n","  return {\"MSE_Score\": mse_score_val, \"R2_Score\": r2_score_val}"],"metadata":{"id":"1nDMw4qQKH-L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Linear Regression"],"metadata":{"id":"XorPdyGZVgZm"}},{"cell_type":"code","source":["# Linear Regression:\n","\n","lr_model = LinearRegression()\n","\n","scores = cross_val_score(lr_model, X_boost_train, y_train, scoring='r2', cv=5)\n","scores   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8HNJLXQNPKN","executionInfo":{"status":"ok","timestamp":1659893244224,"user_tz":240,"elapsed":149,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"7e15afcf-dc7e-4be4-9ead-b02e6c00e426"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.52372859,  0.22300902,  0.40490087,  0.28289511,  0.22152235])"]},"metadata":{},"execution_count":104}]},{"cell_type":"code","source":["# k-fold CV (using all the boost variables)\n","train_and_test(lr_model, X_boost_train, y_train, X_boost_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u3LEeDg-TAy-","executionInfo":{"status":"ok","timestamp":1659893245438,"user_tz":240,"elapsed":2,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"1580e64d-dfae-49fb-ad3d-97cc49d9cbbc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'MSE_Score': 320.12078109174996, 'R2_Score': 0.27008943892479653}"]},"metadata":{},"execution_count":105}]},{"cell_type":"markdown","source":["Random Forest"],"metadata":{"id":"hsN9aH9PVi0n"}},{"cell_type":"code","source":["# Random Forest Regression:\n","\n","rfr_model = RandomForestRegressor()\n","\n","scores = cross_val_score(rfr_model, X_boost_train, y_train, scoring='r2', cv=5)\n","scores   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D4fKow76KMOQ","executionInfo":{"status":"ok","timestamp":1659893012236,"user_tz":240,"elapsed":2255,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"3379fa3e-f132-4e1a-dfba-ae15c9339c25"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.21087431, 0.4829302 , 0.49542987, 0.26260168, 0.45673906])"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["\n","train_and_test(rfr_model, X_boost_train, y_train, X_boost_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EeOycXgMVUeZ","executionInfo":{"status":"ok","timestamp":1659893013554,"user_tz":240,"elapsed":607,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"44be92a3-36fd-42ca-98b1-f2321d638b9f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'MSE_Score': 239.01657569297282, 'R2_Score': 0.455015940310575}"]},"metadata":{},"execution_count":97}]},{"cell_type":"markdown","source":["Gradient Boosting"],"metadata":{"id":"fK2oXMiYVkIq"}},{"cell_type":"code","source":["# Gradient Boost for feature importance:\n","\n","boost_model = GradientBoostingRegressor(random_state=0)   \n","\n","scores = cross_val_score(boost_model, X_boost_train, y_train, scoring='r2', cv=5)\n","scores   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RtVch7M3KPN4","executionInfo":{"status":"ok","timestamp":1659893141201,"user_tz":240,"elapsed":860,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"cd9eebc5-824a-4f51-d233-07aaff560c52"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.11861583, 0.52141256, 0.46201785, 0.23063168, 0.37609487])"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":["boost_model.fit(X_boost_train, y_train)\n","y_preds = boost_model.predict(X_boost_test)\n","r2_score(y_test, y_preds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qwcJE61QV1hH","executionInfo":{"status":"ok","timestamp":1659893147475,"user_tz":240,"elapsed":316,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"f4bcf021-b3e3-4597-a9f4-494dc6deff67"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4156543656927092"]},"metadata":{},"execution_count":100}]},{"cell_type":"code","source":["#chose five models to train the data with to see which performs the best : Linear Regression and Support Vector Regression\n","pipe_lr = Pipeline([('LR', LinearRegression())])\n","pipe_svm = Pipeline([('SVM', SVR())])\n","pipe_rfr = Pipeline([('RFR', RandomForestRegressor())])\n","pipe_dtr = Pipeline([('DTR', DecisionTreeRegressor())])\n","pipe_gbr = Pipeline([('DTR', GradientBoostingRegressor())])\n","\n","#create GridSearch parameters\n","\n","#creates lists to pass into the grid below\n","C = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n","epsilon = [0, 0.01, 0.1, 0.5, 1, 2, 4, 5]\n","n_estimators = [50,100,150, 200, 300, 500,1000, 1500]\n","n_jobs = np.array([1, 10, 100, 290, 500])\n","bootstrap = [True, False]\n","max_depth = [3,4,6,8,10]\n","min_samples_split = [10,20,40]\n","max_depth = [2, 6, 8]\n","min_samples_leaf = [20, 40, 100]\n","max_leaf_nodes = [5, 20, 100]\n","learning_rate = [0.01,0.02,0.03,0.04]\n","subsample = [0.9, 0.5, 0.2, 0.1]\n","\n","#these will be passed to the GridSearchCV function below -> which will take a pipeline model and test out each paramter value passed through in the following parameter list\n","lr_space = [{'fit_intercept':[True, False]}]\n","\n","svr_space = [{'kernel': ['linear'], 'C' : C, 'epsilon' : epsilon},\n","         {'kernel': ['rbf'], 'C' : C, 'gamma' : C, 'epsilon' : epsilon}]\n","\n","rfr_space = [{'max_features' : [\"auto\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"sqrt\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"log2\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","dtr_space = [{'criterion': ['squared_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes},\n","            {'criterion': ['absolute_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes}]\n","\n","gbr_space = [{'learning_rate': learning_rate, 'subsample' : subsample, 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","\n","\n","##use the GridSearchCV function and pass in both the pipeline created above and the grid parameters \n","\n","#pass in cv=5 for the gridsearch to perform cross-validation on our training set\n","#pass score = accuracy for get the accrucay score when the test is performed \n","lr_gs = GridSearchCV(LinearRegression(), param_grid = lr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","svm_gs = GridSearchCV(SVR(), param_grid = svr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","rfr_gs = GridSearchCV(RandomForestRegressor(), param_grid = rfr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","dtr_gs = GridSearchCV(DecisionTreeRegressor(), param_grid = dtr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","gbr_gs = GridSearchCV(GradientBoostingRegressor(), param_grid = gbr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","\n","lr_grids = [lr_gs]\n","\n","for lr_pipe in lr_grids:\n","    lr_pipe.fit(X_boost_train,y_train)\n","\n","svm_grids = [svm_gs]\n","\n","for svm_pipe in svm_grids:\n","    svm_pipe.fit(X_boost_train,y_train)\n","\n","rfr_grids = [rfr_gs]\n","\n","for rfr_pipe in rfr_grids:\n","    rfr_pipe.fit(X_boost_train,y_train)\n","\n","dtr_grids = [dtr_gs]\n","\n","for dtr_pipe in dtr_grids:\n","    dtr_pipe.fit(X_boost_train,y_train)\n","\n","gbr_grids = [gbr_gs]\n","\n","for gbr_pipe in gbr_grids:\n","    gbr_pipe.fit(X_boost_train,y_train)"],"metadata":{"id":"GyLu4LZJzyM-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#first create a dictionary that contains the classifier types to used int eh for loop. \n","lr_grid_dict = {0: 'Linear Regression'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(lr_grids):\n","    print('{} Train R_Square: {}'.format(lr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","lr_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,lr_y_pred)*100\n","\n","for i, model in enumerate(lr_grids):\n","    print('{} Test R_Square: {}'.format(lr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","svm_grid_dict = {0: 'Support Vector Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(svm_grids):\n","    print('{} Train R_Square: {}'.format(svm_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","svm_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,svm_y_pred)*100\n","\n","for i, model in enumerate(svm_grids):\n","    print('{} Test R_Square: {}'.format(svm_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          results.best_params_))\n","    \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","rfr_grid_dict = {0: 'Random Forest Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(rfr_grids):\n","    print('{} Train R_Square: {}'.format(rfr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","rf_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,rf_y_pred)*100\n","\n","for i, model in enumerate(rfr_grids):\n","    print('{} Test R_Square: {}'.format(rfr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","dtr_grid_dict = {0: 'Decision Tree Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(dtr_grids):\n","    print('{} Train R_Square: {}'.format(dtr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","dtr_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,dtr_y_pred)*100\n","\n","for i, model in enumerate(dtr_grids):\n","    print('{} Test R_Square: {}'.format(dtr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","gbr_grid_dict = {0: 'Gradient Boosting Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(gbr_grids):\n","    print('{} Train R_Square: {}'.format(gbr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","gbr_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,gbr_y_pred)*100\n","\n","for i, model in enumerate(gbr_grids):\n","    print('{} Test R_Square: {}'.format(gbr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          results.best_params_))"],"metadata":{"id":"OCP4mAx-z3cs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xjmMT6jBOPx0"},"source":["#### Mutual Information Feature Selection "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lEahLSlqOPx0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659724797561,"user_tz":240,"elapsed":2931,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"7f430427-d146-4f57-c8f0-ac55c5f102fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1.93329965e-01 2.79787357e-02 0.00000000e+00 2.85353136e-01\n"," 1.12896336e-01 2.04555356e-01 6.47709408e-02 1.89068091e-02\n"," 2.36317673e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.14886389e-02 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 9.31302684e-04 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 2.32252200e-03 1.40305033e-01\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.39487101e-02\n"," 7.96625655e-03 0.00000000e+00 9.11215201e-02 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 2.24477243e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 5.80357087e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.13094503e-01 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.45845098e-03 7.19362761e-03\n"," 0.00000000e+00 0.00000000e+00 2.40973048e-03 7.97151068e-03\n"," 1.65255318e-02 2.68652715e-02 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 4.78600247e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 9.50697768e-04 2.04791150e-03 0.00000000e+00 0.00000000e+00\n"," 1.41220624e-03 0.00000000e+00 5.01277239e-03 0.00000000e+00\n"," 0.00000000e+00 7.38843507e-03 0.00000000e+00 0.00000000e+00\n"," 1.29290297e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 6.44048285e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 5.02576173e-03 0.00000000e+00 0.00000000e+00 1.99348901e-03\n"," 7.05102041e-03 8.03350383e-03 9.70502791e-04 1.17793054e-03\n"," 5.30411535e-03 0.00000000e+00 5.33382372e-03 3.65177267e-04\n"," 8.64074784e-03 0.00000000e+00 1.19599897e-02 0.00000000e+00\n"," 2.84805174e-03 1.38729789e-03 0.00000000e+00 1.02384043e-02\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 1.09570251e-02 1.19276081e-02 0.00000000e+00 2.53345761e-04\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.42389858e-02\n"," 0.00000000e+00 1.85970340e-02 1.75240411e-03 3.44523841e-03\n"," 9.75414247e-03 2.92779979e-03 0.00000000e+00 0.00000000e+00\n"," 1.77997772e-03 0.00000000e+00 8.69478688e-04 2.96583868e-03\n"," 0.00000000e+00 8.08535841e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 1.97063305e-02 3.67974827e-05 1.96065812e-05\n"," 0.00000000e+00 0.00000000e+00 3.69781965e-04 0.00000000e+00\n"," 0.00000000e+00 1.26305402e-03 0.00000000e+00 0.00000000e+00\n"," 4.49748302e-03 8.72724855e-03 4.24913952e-03 4.28808130e-03\n"," 0.00000000e+00 0.00000000e+00 1.04173726e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 2.68405974e-03 9.93819846e-04\n"," 0.00000000e+00 2.74253287e-02 5.91776086e-03 0.00000000e+00\n"," 3.12987092e-03 0.00000000e+00 0.00000000e+00 1.84500421e-02\n"," 0.00000000e+00 7.46316487e-04 0.00000000e+00 2.83490536e-03\n"," 6.22400733e-03 9.66883491e-03 1.97294403e-02 0.00000000e+00\n"," 4.05093784e-03 0.00000000e+00 4.27624185e-05 9.47262668e-06\n"," 0.00000000e+00 2.39920972e-03 0.00000000e+00 0.00000000e+00\n"," 2.83998190e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 6.63027663e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 2.69679475e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 3.30421947e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 9.72412049e-04\n"," 0.00000000e+00 0.00000000e+00 1.51862016e-03 1.57903235e-02\n"," 0.00000000e+00 0.00000000e+00 5.30980431e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 6.48832115e-04 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.46576918e-04\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.60120945e-02\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.08799955e-02 5.67464207e-03\n"," 0.00000000e+00 0.00000000e+00 2.99233670e-03 3.60552397e-03\n"," 2.10738798e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 1.36375133e-02 0.00000000e+00 0.00000000e+00\n"," 1.38784031e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 2.36206964e-03 0.00000000e+00 0.00000000e+00\n"," 4.14751754e-04 4.63904996e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 3.81096621e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 1.43343054e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 9.67265880e-04 4.12500329e-04\n"," 1.32235983e-02 7.88329410e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 3.73740846e-04 0.00000000e+00 5.22484888e-03\n"," 6.29731809e-02 0.00000000e+00 6.21929279e-02 1.49949132e-01\n"," 8.69707919e-03 1.86974960e-02 3.31688153e-03 6.98487316e-02\n"," 5.58862446e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 1.70697662e-01 1.35633449e-01 0.00000000e+00\n"," 0.00000000e+00 8.44687426e-03 0.00000000e+00 3.92890583e-04\n"," 3.05852092e-02 0.00000000e+00 1.77488514e-02 3.18491126e-02\n"," 4.92078625e-02 5.25771761e-02 3.57412169e-02 0.00000000e+00\n"," 0.00000000e+00 6.05903110e-02 2.00073829e-02 2.41637927e-02\n"," 2.98299349e-02 6.85765039e-04 0.00000000e+00 3.66658126e-02\n"," 8.50858185e-02 8.20275432e-03 0.00000000e+00 1.04039135e-02\n"," 2.37977376e-02 7.00182719e-03]\n"]}],"source":["from sklearn.feature_selection import mutual_info_regression  \n","from sklearn.feature_selection import SelectKBest\n","selector = SelectKBest(mutual_info_regression, k=10)\n","X_train_new = selector.fit_transform(X_train, y_train)  #Applying transformation to the training set\n","#to get names of the selected features\n","mask = selector.get_support()  \n","\n","print(selector.scores_)   \n","\n","new_features = X_train.columns[mask]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vstk_RRrOPx0"},"outputs":[],"source":["X_MI_df = V4_master_df[new_features]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BBGARp1bOPx0","colab":{"base_uri":"https://localhost:8080/","height":375},"executionInfo":{"status":"error","timestamp":1659724798118,"user_tz":240,"elapsed":289,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"b261267e-2132-4ed7-fe08-e4c25bcaeb52"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-82-a1d14a8e7824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train/test split:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_MI_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_MI_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_MI_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_MI_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_MI_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2417\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [800, 339]"]}],"source":["# Train/test split:\n","X_MI_train, X_MI_test, y_train, y_test = train_test_split(X_MI_df, y_df, test_size = 0.2, random_state = 2)\n","\n","X_MI_train.shape, X_MI_test.shape"]},{"cell_type":"code","source":["logreg=LogisticRegression()\n","kf=KFold(n_splits=5)\n","score=cross_val_score(logreg,X_MI_train,y_train,cv=kf)\n","print(\"Cross Validation Scores are {}\".format(score))\n","print(\"Average Cross Validation score :{}\".format(score.mean()))\n","\n","# Train classifiers\n","reg1 = GradientBoostingRegressor(random_state=1)\n","reg2 = RandomForestRegressor(random_state=1)\n","reg3 = LinearRegression()\n","\n","reg1.fit(X_MI_train, y_train)\n","reg2.fit(X_MI_train, y_train)\n","reg3.fit(X_MI_train, y_train)\n","\n","ereg = VotingRegressor([(\"gb\", reg1), (\"rf\", reg2), (\"lr\", reg3)])\n","ereg.fit(X_MI_train, y_train)\n","\n","#predict \n","pred1 = reg1.predict(X_boost_test)\n","pred2 = reg2.predict(X_boost_test)\n","pred3 = reg3.predict(X_boost_test)\n","pred4 = ereg.predict(X_boost_test)\n","\n","#plot\n","plt.figure()\n","plt.plot(pred1, \"gd\", label=\"GradientBoostingRegressor\")\n","plt.plot(pred2, \"b^\", label=\"RandomForestRegressor\")\n","plt.plot(pred3, \"ys\", label=\"LinearRegression\")\n","plt.plot(pred4, \"r*\", ms=10, label=\"VotingRegressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"training samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions and their average - Depression\")\n","plt.setp(plt.gca(),ylim=(0,100))\n","\n","plt.show()"],"metadata":{"id":"s9Xf-FFgTZg-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#chose five models to train the data with to see which performs the best : Linear Regression and Support Vector Regression\n","pipe_lr = Pipeline([('LR', LinearRegression())])\n","pipe_svm = Pipeline([('SVM', SVR())])\n","pipe_rfr = Pipeline([('RFR', RandomForestRegressor())])\n","pipe_dtr = Pipeline([('DTR', DecisionTreeRegressor())])\n","pipe_gbr = Pipeline([('DTR', GradientBoostingRegressor())])\n","\n","#create GridSearch parameters\n","\n","#creates lists to pass into the grid below\n","C = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n","epsilon = [0, 0.01, 0.1, 0.5, 1, 2, 4, 5]\n","n_estimators = [50,100,150, 200, 300, 500,1000, 1500]\n","n_jobs = np.array([1, 10, 100, 290, 500])\n","bootstrap = [True, False]\n","max_depth = [3,4,6,8,10]\n","min_samples_split = [10,20,40]\n","max_depth = [2, 6, 8]\n","min_samples_leaf = [20, 40, 100]\n","max_leaf_nodes = [5, 20, 100]\n","learning_rate = [0.01,0.02,0.03,0.04]\n","subsample = [0.9, 0.5, 0.2, 0.1]\n","\n","#these will be passed to the GridSearchCV function below -> which will take a pipeline model and test out each paramter value passed through in the following parameter list\n","lr_space = [{'fit_intercept': ['svd'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['cholesky'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['lsqr'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sparse_cg'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sag'],  'n_jobs' : n_jobs},\n","         {'fit_intercept': ['saga'], 'n_jobs' : n_jobs}]\n","\n","svr_space = [{'kernel': ['linear'], 'C' : C, 'epsilon' : epsilon},\n","         {'kernel': ['rbf'], 'C' : C, 'gamma' : C, 'epsilon' : epsilon}]\n","\n","rfr_space = [{'max_features' : [\"auto\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"sqrt\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"log2\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","dtr_space = [{'criterion': ['mse'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes},\n","         {'criterion': ['absolute_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes}]\n","\n","gbr_space = [{'learning_rate': learning_rate, 'subsample' : subsample, 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","\n","\n","##use the GridSearchCV function and pass in both the pipeline created above and the frid parameters \n","\n","#pass in cv=3 for the fridsearch to perform cross-validation on our training set\n","#pass score = accuracy for get the accrucay score when the test is performed \n","lr_gs = GridSearchCV(LinearRegression(), param_grid = lr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","svm_gs = GridSearchCV(SVR(), param_grid = svr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","rfr_gs = GridSearchCV(RandomForestRegressor(), param_grid = rfr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","dtr_gs = GridSearchCV(DecisionTreeRegressor(), param_grid = dtr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","gbr_gs = GridSearchCV(GradientBoostingRegressor(), param_grid = gbr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","\n","lr_grids = [lr_gs]\n","\n","for lr_pipe in lr_grids:\n","    lr_pipe.fit(X_MI_train,y_train)\n","\n","svm_grids = [svm_gs]\n","\n","for svm_pipe in svm_grids:\n","    svm_pipe.fit(X_MI_train,y_train)\n","\n","rfr_grids = [rfr_gs]\n","\n","for rfr_pipe in rfr_grids:\n","    rfr_pipe.fit(X_MI_train,y_train)\n","\n","dtr_grids = [dtr_gs]\n","\n","for dtr_pipe in dtr_grids:\n","    dtr_pipe.fit(X_MI_train,y_train)\n","\n","gbr_grids = [gbr_gs]\n","\n","for gbr_pipe in gbr_grids:\n","    gbr_pipe.fit(X_MI_train,y_train)"],"metadata":{"id":"CMZPWjvQOPx0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#first create a dictionary that contains the classifier types to used int eh for loop. \n","lr_grid_dict = {0: 'Linear Regression'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(lr_grids):\n","    print('{} Train R_Square: {}'.format(lr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(lr_grids):\n","    print('{} Test R_Square: {}'.format(lr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","svm_grid_dict = {0: 'Support Vector Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(svm_grids):\n","    print('{} Train R_Square: {}'.format(svm_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(svm_grids):\n","    print('{} Test R_Square: {}'.format(svm_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","rfr_grid_dict = {0: 'Random Forest Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(rfr_grids):\n","    print('{} Train R_Square: {}'.format(rfr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(rfr_grids):\n","    print('{} Test R_Square: {}'.format(rfr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","dtr_grid_dict = {0: 'Decision Tree Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(dtr_grids):\n","    print('{} Train R_Square: {}'.format(dtr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(dtr_grids):\n","    print('{} Test R_Square: {}'.format(dtr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","gbr_grid_dict = {0: 'Gradient Boosting Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(gbr_grids):\n","    print('{} Train R_Square: {}'.format(gbr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(gbr_grids):\n","    print('{} Test R_Square: {}'.format(gbr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))"],"metadata":{"id":"D_u61NpqOPx0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hJKEjBoVOPx0"},"source":["#### Knowledge Feature Selection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3YIsZwqsOPx0"},"outputs":[],"source":["df_list = list(X_df[['number_of_arms', 'has_dmc', 'number_of_facilities', 'study_duration_months', 'event_type_deaths', 'event_type_other', 'event_type_serious']])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kzai72hjOPx0"},"outputs":[],"source":["dropout_list = list(X_df[['dropout_reason_adverse event', 'dropout_reason_inclusion/exclusion criteria issue', 'dropout_reason_lost to follow-up']])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k-qBqV32OPx0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659724854258,"user_tz":240,"elapsed":139,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"6e474a56-8e67-44c6-ba63-94dc82d8b857"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Headache',\n"," 'Nausea',\n"," 'Fatigue',\n"," 'Vomiting',\n"," 'Decreased appetite',\n"," 'Diarrhoea',\n"," 'Sedation',\n"," 'Rash',\n"," 'Increased appetite',\n"," 'Palpitations']"]},"metadata":{},"execution_count":85}],"source":["top_ae_table_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7EX2LmWsOPx0"},"outputs":[],"source":["X_knowledge_df = X_df[X_df.columns.intersection(top_ae_table_list+dropout_list+df_list)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IDbScRs1OPx0"},"outputs":[],"source":["X_knowledge_norm = (X_knowledge_df-X_knowledge_df.min())/(X_knowledge_df.max()-X_knowledge_df.min())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4QkSH4POPx0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659724857924,"user_tz":240,"elapsed":117,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"1f81e75a-1e24-4ea5-fc14-1c0e06343aca"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((271, 20), (68, 20))"]},"metadata":{},"execution_count":88}],"source":["# Train/test split:\n","X_knowledge_train, X_knowledge_test, y_train, y_test = train_test_split(X_knowledge_norm, y_df, test_size = 0.2, random_state = 2)\n","\n","X_knowledge_train.shape, X_knowledge_test.shape"]},{"cell_type":"code","source":["logreg=LogisticRegression()\n","kf=KFold(n_splits=5)\n","score=cross_val_score(logreg,X_knowledge_train,y_train,cv=kf)\n","print(\"Cross Validation Scores are {}\".format(score))\n","print(\"Average Cross Validation score :{}\".format(score.mean()))\n","\n","# Train classifiers\n","reg1 = GradientBoostingRegressor(random_state=1)\n","reg2 = RandomForestRegressor(random_state=1)\n","reg3 = LinearRegression()\n","\n","reg1.fit(X_knowledge_train, y_train)\n","reg2.fit(X_knowledge_train, y_train)\n","reg3.fit(X_knowledge_train, y_train)\n","\n","ereg = VotingRegressor([(\"gb\", reg1), (\"rf\", reg2), (\"lr\", reg3)])\n","ereg.fit(X_knowledge_train, y_train)\n","\n","#predict \n","pred1 = reg1.predict(X_knowledge_test)\n","pred2 = reg2.predict(X_knowledge_test)\n","pred3 = reg3.predict(X_knowledge_test)\n","pred4 = ereg.predict(X_knowledge_test)\n","\n","#plot\n","plt.figure()\n","plt.plot(pred1, \"gd\", label=\"GradientBoostingRegressor\")\n","plt.plot(pred2, \"b^\", label=\"RandomForestRegressor\")\n","plt.plot(pred3, \"ys\", label=\"LinearRegression\")\n","plt.plot(pred4, \"r*\", ms=10, label=\"VotingRegressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"training samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions and their average - Depression\")\n","plt.setp(plt.gca(),ylim=(0,100))\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":640},"id":"cYSOu6LTT4gB","executionInfo":{"status":"ok","timestamp":1659724939828,"user_tz":240,"elapsed":2577,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"4fa6ee0a-25ae-442b-80ff-50a084b78f97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","5 fits failed out of a total of 5.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","5 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1516, in fit\n","    check_classification_targets(y)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 197, in check_classification_targets\n","    raise ValueError(\"Unknown label type: %r\" % y_type)\n","ValueError: Unknown label type: 'continuous'\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Cross Validation Scores are [nan nan nan nan nan]\n","Average Cross Validation score :nan\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["#chose five models to train the data with to see which performs the best : Linear Regression and Support Vector Regression\n","pipe_lr = Pipeline([('LR', LinearRegression())])\n","pipe_svm = Pipeline([('SVM', SVR())])\n","pipe_rfr = Pipeline([('RFR', RandomForestRegressor())])\n","pipe_dtr = Pipeline([('DTR', DecisionTreeRegressor())])\n","pipe_gbr = Pipeline([('DTR', GradientBoostingRegressor())])\n","\n","#create GridSearch parameters\n","\n","#creates lists to pass into the grid below\n","C = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n","epsilon = [0, 0.01, 0.1, 0.5, 1, 2, 4, 5]\n","n_estimators = [50,100,150, 200, 300, 500,1000, 1500]\n","n_jobs = np.array([1, 10, 100, 290, 500])\n","bootstrap = [True, False]\n","max_depth = [3,4,6,8,10]\n","min_samples_split = [10,20,40]\n","max_depth = [2, 6, 8]\n","min_samples_leaf = [20, 40, 100]\n","max_leaf_nodes = [5, 20, 100]\n","learning_rate = [0.01,0.02,0.03,0.04]\n","subsample = [0.9, 0.5, 0.2, 0.1]\n","\n","#these will be passed to the GridSearchCV function below -> which will take a pipeline model and test out each paramter value passed through in the following parameter list\n","lr_space = [{'fit_intercept': ['svd'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['cholesky'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['lsqr'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sparse_cg'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sag'],  'n_jobs' : n_jobs},\n","         {'fit_intercept': ['saga'], 'n_jobs' : n_jobs}]\n","\n","svr_space = [{'kernel': ['linear'], 'C' : C, 'epsilon' : epsilon},\n","         {'kernel': ['rbf'], 'C' : C, 'gamma' : C, 'epsilon' : epsilon}]\n","\n","rfr_space = [{'max_features' : [\"auto\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"sqrt\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"log2\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","dtr_space = [{'criterion': ['mse'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes},\n","         {'criterion': ['absolute_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes}]\n","\n","gbr_space = [{'learning_rate': learning_rate, 'subsample' : subsample, 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","\n","\n","##use the GridSearchCV function and pass in both the pipeline created above and the frid parameters \n","\n","#pass in cv=3 for the fridsearch to perform cross-validation on our training set\n","#pass score = accuracy for get the accrucay score when the test is performed \n","lr_gs = GridSearchCV(LinearRegression(), param_grid = lr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","svm_gs = GridSearchCV(SVR(), param_grid = svr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","rfr_gs = GridSearchCV(RandomForestRegressor(), param_grid = rfr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","dtr_gs = GridSearchCV(DecisionTreeRegressor(), param_grid = dtr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","gbr_gs = GridSearchCV(GradientBoostingRegressor(), param_grid = gbr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","\n","lr_grids = [lr_gs]\n","\n","for lr_pipe in lr_grids:\n","    lr_pipe.fit(X_knowledge_train,y_train)\n","\n","svm_grids = [svm_gs]\n","\n","for svm_pipe in svm_grids:\n","    svm_pipe.fit(X_knowledge_train,y_train)\n","\n","rfr_grids = [rfr_gs]\n","\n","for rfr_pipe in rfr_grids:\n","    rfr_pipe.fit(X_knowledge_train,y_train)\n","\n","dtr_grids = [dtr_gs]\n","\n","for dtr_pipe in dtr_grids:\n","    dtr_pipe.fit(X_knowledge_train,y_train)\n","\n","gbr_grids = [gbr_gs]\n","\n","for gbr_pipe in gbr_grids:\n","    gbr_pipe.fit(X_knowledge_train,y_train)"],"metadata":{"id":"wDkCndY5OPx1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#first create a dictionary that contains the classifier types to used int eh for loop. \n","lr_grid_dict = {0: 'Linear Regression'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(lr_grids):\n","    print('{} Train R_Square: {}'.format(lr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","lr_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,lr_y_pred)*100\n","\n","for i, model in enumerate(lr_grids):\n","    print('{} Test R_Square: {}'.format(lr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","svm_grid_dict = {0: 'Support Vector Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(svm_grids):\n","    print('{} Train R_Square: {}'.format(svm_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","svm_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,svm_y_pred)*100\n","\n","for i, model in enumerate(svm_grids):\n","    print('{} Test R_Square: {}'.format(svm_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          results.best_params_))\n","    \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","rfr_grid_dict = {0: 'Random Forest Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(rfr_grids):\n","    print('{} Train R_Square: {}'.format(rfr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","rf_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,rf_y_pred)*100\n","\n","for i, model in enumerate(rfr_grids):\n","    print('{} Test R_Square: {}'.format(rfr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","dtr_grid_dict = {0: 'Decision Tree Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(dtr_grids):\n","    print('{} Train R_Square: {}'.format(dtr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","dtr_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,dtr_y_pred)*100\n","\n","for i, model in enumerate(dtr_grids):\n","    print('{} Test R_Square: {}'.format(dtr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","gbr_grid_dict = {0: 'Gradient Boosting Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(gbr_grids):\n","    print('{} Train R_Square: {}'.format(gbr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","gbr_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,gbr_y_pred)*100\n","\n","for i, model in enumerate(gbr_grids):\n","    print('{} Test R_Square: {}'.format(gbr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          results.best_params_))"],"metadata":{"id":"6xBgfmkHOPx1","colab":{"base_uri":"https://localhost:8080/","height":592},"executionInfo":{"status":"error","timestamp":1659726446747,"user_tz":240,"elapsed":329,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"ce5abbb0-34da-4c3e-c4d7-0a55fe99180e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n","Feature names unseen at fit time:\n","- Abdominal distension\n","- Abdominal hernia\n","- Abdominal pain\n","- Abortion spontaneous\n","- Accepts_Healthy_volunteers\n","- ...\n","Feature names must be in the same order as they were in fit.\n","\n","  warnings.warn(message, FutureWarning)\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-93-d716c58a4f93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#then create a for loop to train them all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_grids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Train R_Square: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_grid_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Best Params: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_grid_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;31m# callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimetric_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         )\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \"\"\"\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod_caller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return self._sign * self._score_func(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;34m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \"\"\"\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise ValueError(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: X has 334 features, but LinearRegression is expecting 20 features as input."]}]},{"cell_type":"code","source":["#plot predictions \n","plt.figure()\n","plt.plot(lr_y_pred, \"gd\", label=\"Linear Regression\")\n","plt.plot(svm_y_pred, \"b^\", label=\"Support Vector Regressor\")\n","plt.plot(rf_y_pred, \"ys\", label=\"Random Forest Regressor\")\n","plt.plot(dtr_y_pred, \"r*\", ms=10, label=\"Decision Tree Regressor\")\n","plt.plot(gbr_y_pred, \"bs\", label=\"Gradient Boosting Regressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"Training Samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions - Knowledge Based Feature Selection - Depression\")\n","plt.setp(plt.gca(),ylim=(0,100))"],"metadata":{"id":"m6hYULywWrKq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mSqDVvKvFSf-"},"source":["## Anxiety "]},{"cell_type":"markdown","metadata":{"id":"2DpawyUl3cIz"},"source":["### Subset Anxiety Studies / Split into test and train sets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OMUzbKYQ3cI0"},"outputs":[],"source":["V4_anxiety_df = V4_master_df[V4_master_df['disease_type'] == \"Anxiety\"]\n","V4_anxiety_df = V4_anxiety_df.drop(columns=['disease_type', 'intervention_model_type_Sequential Assignment'])\n","\n","#split into features and outcome dataframes\n","X_df = V4_anxiety_df.drop(columns=['percent_attrition'])\n","y_df = V4_anxiety_df.percent_attrition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xp3fiNhxgWlS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896569941,"user_tz":240,"elapsed":167,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"ee102e30-4fb1-457d-ee05-ea26dc6c2d1b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  dropout_reason_consent withdrawn  \\\n","27                            0.0                               0.0   \n","29                            0.0                               0.0   \n","92                            0.0                               0.0   \n","94                            0.0                               0.0   \n","111                           0.0                               0.0   \n","113                           0.0                               0.0   \n","125                           1.0                               0.0   \n","127                           1.0                               0.0   \n","132                           0.0                               0.0   \n","134                           0.0                               0.0   \n","190                           0.0                               0.0   \n","192                           0.0                               0.0   \n","235                           0.0                               0.0   \n","237                           0.0                               0.0   \n","245                           1.0                               0.0   \n","247                           1.0                               0.0   \n","287                           1.0                               0.0   \n","289                           1.0                               0.0   \n","292                           0.0                               0.0   \n","294                           0.0                               0.0   \n","330                           0.0                               0.0   \n","332                           0.0                               0.0   \n","344                           0.0                               0.0   \n","346                           0.0                               0.0   \n","348                           0.0                               0.0   \n","350                           0.0                               0.0   \n","379                           0.0                               0.0   \n","381                           0.0                               0.0   \n","384                           0.0                               0.0   \n","386                           0.0                               0.0   \n","388                           0.0                               0.0   \n","390                           0.0                               0.0   \n","395                           0.0                               0.0   \n","397                           0.0                               0.0   \n","402                           2.0                               0.0   \n","404                           2.0                               0.0   \n","410                           8.0                               0.0   \n","\n","     dropout_reason_death  dropout_reason_inclusion/exclusion criteria issue  \\\n","27                    0.0                                               22.0   \n","29                    0.0                                               22.0   \n","92                    0.0                                                3.0   \n","94                    0.0                                                3.0   \n","111                   0.0                                                0.0   \n","113                   0.0                                                0.0   \n","125                   0.0                                                8.0   \n","127                   0.0                                                8.0   \n","132                   0.0                                                0.0   \n","134                   0.0                                                0.0   \n","190                   0.0                                                0.0   \n","192                   0.0                                                0.0   \n","235                   0.0                                                8.0   \n","237                   0.0                                                8.0   \n","245                   0.0                                                0.0   \n","247                   0.0                                                0.0   \n","287                   0.0                                                0.0   \n","289                   0.0                                                0.0   \n","292                   0.0                                                1.0   \n","294                   0.0                                                1.0   \n","330                   0.0                                                4.0   \n","332                   0.0                                                4.0   \n","344                   0.0                                                0.0   \n","346                   0.0                                                0.0   \n","348                   0.0                                                0.0   \n","350                   0.0                                                0.0   \n","379                   0.0                                                8.0   \n","381                   0.0                                                8.0   \n","384                   0.0                                                0.0   \n","386                   0.0                                                0.0   \n","388                   0.0                                                0.0   \n","390                   0.0                                                0.0   \n","395                   0.0                                                0.0   \n","397                   0.0                                                0.0   \n","402                   0.0                                                0.0   \n","404                   0.0                                                0.0   \n","410                   0.0                                                5.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","27                               0.0                               5.0   \n","29                               0.0                               5.0   \n","92                               0.0                               1.0   \n","94                               0.0                               1.0   \n","111                              0.0                               1.0   \n","113                              0.0                               1.0   \n","125                              0.0                               0.0   \n","127                              0.0                               0.0   \n","132                              0.0                               0.0   \n","134                              0.0                               0.0   \n","190                              0.0                              67.0   \n","192                              0.0                              67.0   \n","235                              0.0                               4.0   \n","237                              0.0                               4.0   \n","245                              0.0                               0.0   \n","247                              0.0                               0.0   \n","287                              0.0                               0.0   \n","289                              0.0                               0.0   \n","292                              0.0                               3.0   \n","294                              0.0                               3.0   \n","330                              0.0                              12.0   \n","332                              0.0                              12.0   \n","344                              0.0                               3.0   \n","346                              0.0                               3.0   \n","348                              0.0                               0.0   \n","350                              0.0                               0.0   \n","379                              0.0                              22.0   \n","381                              0.0                              22.0   \n","384                              0.0                              17.0   \n","386                              0.0                              17.0   \n","388                              0.0                               0.0   \n","390                              0.0                               0.0   \n","395                              0.0                               1.0   \n","397                              0.0                               1.0   \n","402                              0.0                              10.0   \n","404                              0.0                              10.0   \n","410                             10.0                              16.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","27                                 0.0                                0.0   \n","29                                 0.0                                0.0   \n","92                                 0.0                                1.0   \n","94                                 0.0                                1.0   \n","111                                2.0                                1.0   \n","113                                2.0                                1.0   \n","125                                0.0                                0.0   \n","127                                0.0                                0.0   \n","132                                4.0                                0.0   \n","134                                4.0                                0.0   \n","190                                0.0                                0.0   \n","192                                0.0                                0.0   \n","235                                1.0                                0.0   \n","237                                1.0                                0.0   \n","245                                0.0                                0.0   \n","247                                0.0                                0.0   \n","287                                0.0                                5.0   \n","289                                0.0                                5.0   \n","292                                0.0                                0.0   \n","294                                0.0                                0.0   \n","330                                0.0                                0.0   \n","332                                0.0                                0.0   \n","344                                9.0                                0.0   \n","346                                9.0                                0.0   \n","348                                0.0                                0.0   \n","350                                0.0                                0.0   \n","379                                0.0                                0.0   \n","381                                0.0                                0.0   \n","384                                0.0                                0.0   \n","386                                0.0                                0.0   \n","388                                0.0                                0.0   \n","390                                0.0                                0.0   \n","395                                0.0                                0.0   \n","397                                0.0                                0.0   \n","402                                0.0                                0.0   \n","404                                0.0                                0.0   \n","410                                2.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Influenza  ...  \\\n","27                                14.0        0.0  ...   \n","29                                14.0        0.0  ...   \n","92                                 1.0        0.0  ...   \n","94                                 1.0        0.0  ...   \n","111                                5.0        0.0  ...   \n","113                                5.0        0.0  ...   \n","125                                0.0        0.0  ...   \n","127                                0.0        0.0  ...   \n","132                               15.0        0.0  ...   \n","134                               15.0        0.0  ...   \n","190                                0.0        0.0  ...   \n","192                                0.0        0.0  ...   \n","235                                5.0        0.0  ...   \n","237                                5.0        0.0  ...   \n","245                                1.0        0.0  ...   \n","247                                1.0        0.0  ...   \n","287                               11.0        0.0  ...   \n","289                               11.0        0.0  ...   \n","292                                1.0        0.0  ...   \n","294                                1.0        0.0  ...   \n","330                                3.0        0.0  ...   \n","332                                3.0        0.0  ...   \n","344                                1.0        0.0  ...   \n","346                                1.0        0.0  ...   \n","348                                1.0        0.0  ...   \n","350                                1.0        0.0  ...   \n","379                                6.0        0.0  ...   \n","381                                6.0        0.0  ...   \n","384                                2.0        2.0  ...   \n","386                                2.0        2.0  ...   \n","388                                6.0        0.0  ...   \n","390                                6.0        0.0  ...   \n","395                                1.0        0.0  ...   \n","397                                1.0        0.0  ...   \n","402                                4.0        0.0  ...   \n","404                                4.0        0.0  ...   \n","410                                6.0        0.0  ...   \n","\n","     allocation_type_Randomized  masking_type_Double  \\\n","27                            1                    1   \n","29                            1                    1   \n","92                            1                    0   \n","94                            1                    0   \n","111                           1                    0   \n","113                           1                    0   \n","125                           1                    0   \n","127                           1                    0   \n","132                           0                    0   \n","134                           0                    0   \n","190                           1                    0   \n","192                           1                    0   \n","235                           1                    0   \n","237                           1                    0   \n","245                           1                    0   \n","247                           1                    0   \n","287                           1                    0   \n","289                           1                    0   \n","292                           0                    0   \n","294                           0                    0   \n","330                           1                    0   \n","332                           1                    0   \n","344                           1                    1   \n","346                           1                    1   \n","348                           1                    0   \n","350                           1                    0   \n","379                           1                    0   \n","381                           1                    0   \n","384                           1                    0   \n","386                           1                    0   \n","388                           1                    1   \n","390                           1                    1   \n","395                           1                    0   \n","397                           1                    0   \n","402                           1                    0   \n","404                           1                    0   \n","410                           1                    0   \n","\n","     masking_type_None (Open Label)  masking_type_Not Reported  \\\n","27                                0                          0   \n","29                                0                          0   \n","92                                0                          0   \n","94                                0                          0   \n","111                               0                          0   \n","113                               0                          0   \n","125                               0                          0   \n","127                               0                          0   \n","132                               1                          0   \n","134                               1                          0   \n","190                               1                          0   \n","192                               1                          0   \n","235                               0                          0   \n","237                               0                          0   \n","245                               0                          0   \n","247                               0                          0   \n","287                               0                          0   \n","289                               0                          0   \n","292                               1                          0   \n","294                               1                          0   \n","330                               1                          0   \n","332                               1                          0   \n","344                               0                          0   \n","346                               0                          0   \n","348                               0                          0   \n","350                               0                          0   \n","379                               1                          0   \n","381                               1                          0   \n","384                               1                          0   \n","386                               1                          0   \n","388                               0                          0   \n","390                               0                          0   \n","395                               0                          0   \n","397                               0                          0   \n","402                               1                          0   \n","404                               1                          0   \n","410                               0                          0   \n","\n","     masking_type_Quadruple  masking_type_Single  masking_type_Triple  \\\n","27                        0                    0                    0   \n","29                        0                    0                    0   \n","92                        1                    0                    0   \n","94                        1                    0                    0   \n","111                       0                    0                    1   \n","113                       0                    0                    1   \n","125                       0                    0                    1   \n","127                       0                    0                    1   \n","132                       0                    0                    0   \n","134                       0                    0                    0   \n","190                       0                    0                    0   \n","192                       0                    0                    0   \n","235                       1                    0                    0   \n","237                       1                    0                    0   \n","245                       1                    0                    0   \n","247                       1                    0                    0   \n","287                       1                    0                    0   \n","289                       1                    0                    0   \n","292                       0                    0                    0   \n","294                       0                    0                    0   \n","330                       0                    0                    0   \n","332                       0                    0                    0   \n","344                       0                    0                    0   \n","346                       0                    0                    0   \n","348                       1                    0                    0   \n","350                       1                    0                    0   \n","379                       0                    0                    0   \n","381                       0                    0                    0   \n","384                       0                    0                    0   \n","386                       0                    0                    0   \n","388                       0                    0                    0   \n","390                       0                    0                    0   \n","395                       0                    1                    0   \n","397                       0                    1                    0   \n","402                       0                    0                    0   \n","404                       0                    0                    0   \n","410                       0                    0                    1   \n","\n","     study_gender_eligibility_All  study_gender_eligibility_Female  \\\n","27                              1                                0   \n","29                              1                                0   \n","92                              1                                0   \n","94                              1                                0   \n","111                             0                                1   \n","113                             0                                1   \n","125                             0                                1   \n","127                             0                                1   \n","132                             1                                0   \n","134                             1                                0   \n","190                             1                                0   \n","192                             1                                0   \n","235                             0                                1   \n","237                             0                                1   \n","245                             1                                0   \n","247                             1                                0   \n","287                             1                                0   \n","289                             1                                0   \n","292                             1                                0   \n","294                             1                                0   \n","330                             1                                0   \n","332                             1                                0   \n","344                             1                                0   \n","346                             1                                0   \n","348                             1                                0   \n","350                             1                                0   \n","379                             1                                0   \n","381                             1                                0   \n","384                             1                                0   \n","386                             1                                0   \n","388                             0                                0   \n","390                             0                                0   \n","395                             1                                0   \n","397                             1                                0   \n","402                             1                                0   \n","404                             1                                0   \n","410                             1                                0   \n","\n","     study_gender_eligibility_Male  \n","27                               0  \n","29                               0  \n","92                               0  \n","94                               0  \n","111                              0  \n","113                              0  \n","125                              0  \n","127                              0  \n","132                              0  \n","134                              0  \n","190                              0  \n","192                              0  \n","235                              0  \n","237                              0  \n","245                              0  \n","247                              0  \n","287                              0  \n","289                              0  \n","292                              0  \n","294                              0  \n","330                              0  \n","332                              0  \n","344                              0  \n","346                              0  \n","348                              0  \n","350                              0  \n","379                              0  \n","381                              0  \n","384                              0  \n","386                              0  \n","388                              1  \n","390                              1  \n","395                              0  \n","397                              0  \n","402                              0  \n","404                              0  \n","410                              0  \n","\n","[37 rows x 2010 columns]"],"text/html":["\n","  <div id=\"df-8806ce3c-3f2f-47e3-a33b-1b4090b01757\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>...</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Not Reported</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Female</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>27</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>94</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>111</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>113</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>125</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>127</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>134</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>190</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>67.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>67.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>235</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>237</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>245</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>247</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>287</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>289</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>292</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>294</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>330</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>332</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>344</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>346</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>348</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>350</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>379</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>381</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>384</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>17.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>386</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>17.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>388</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>390</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>395</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>397</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>402</th>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>404</th>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>410</th>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>10.0</td>\n","      <td>16.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>37 rows × 2010 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8806ce3c-3f2f-47e3-a33b-1b4090b01757')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8806ce3c-3f2f-47e3-a33b-1b4090b01757 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8806ce3c-3f2f-47e3-a33b-1b4090b01757');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":157}],"source":["X_df"]},{"cell_type":"code","source":["#select all ae columns\n","ae_df = X_df.iloc[:,9:1962]\n","\n","#replace all non zero cells with 1\n","ae_df[ae_df != 0] = 1\n","\n","#add all columns and select the top ten most prevelant\n","s = ae_df.sum()\n","top_ae_table = ae_df[s.sort_values(ascending=False).index[:10]]\n","\n","#generated list of most prevelant ae\n","top_ae_table_list = list(top_ae_table.columns)"],"metadata":{"id":"tn0wGaZ2oZNI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FS4hGWJqcFEU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896570100,"user_tz":240,"elapsed":161,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"e14f05f2-76e6-4be5-b0b4-60cff18293b6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  \\\n","27                            0.0   \n","29                            0.0   \n","92                            0.0   \n","94                            0.0   \n","111                           0.0   \n","113                           0.0   \n","125                           1.0   \n","127                           1.0   \n","132                           0.0   \n","134                           0.0   \n","190                           0.0   \n","192                           0.0   \n","235                           0.0   \n","237                           0.0   \n","245                           1.0   \n","247                           1.0   \n","287                           1.0   \n","289                           1.0   \n","292                           0.0   \n","294                           0.0   \n","330                           0.0   \n","332                           0.0   \n","344                           0.0   \n","346                           0.0   \n","348                           0.0   \n","350                           0.0   \n","379                           0.0   \n","381                           0.0   \n","384                           0.0   \n","386                           0.0   \n","388                           0.0   \n","390                           0.0   \n","395                           0.0   \n","397                           0.0   \n","402                           2.0   \n","404                           2.0   \n","410                           8.0   \n","\n","     dropout_reason_inclusion/exclusion criteria issue  \\\n","27                                                22.0   \n","29                                                22.0   \n","92                                                 3.0   \n","94                                                 3.0   \n","111                                                0.0   \n","113                                                0.0   \n","125                                                8.0   \n","127                                                8.0   \n","132                                                0.0   \n","134                                                0.0   \n","190                                                0.0   \n","192                                                0.0   \n","235                                                8.0   \n","237                                                8.0   \n","245                                                0.0   \n","247                                                0.0   \n","287                                                0.0   \n","289                                                0.0   \n","292                                                1.0   \n","294                                                1.0   \n","330                                                4.0   \n","332                                                4.0   \n","344                                                0.0   \n","346                                                0.0   \n","348                                                0.0   \n","350                                                0.0   \n","379                                                8.0   \n","381                                                8.0   \n","384                                                0.0   \n","386                                                0.0   \n","388                                                0.0   \n","390                                                0.0   \n","395                                                0.0   \n","397                                                0.0   \n","402                                                0.0   \n","404                                                0.0   \n","410                                                5.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","27                               0.0                               5.0   \n","29                               0.0                               5.0   \n","92                               0.0                               1.0   \n","94                               0.0                               1.0   \n","111                              0.0                               1.0   \n","113                              0.0                               1.0   \n","125                              0.0                               0.0   \n","127                              0.0                               0.0   \n","132                              0.0                               0.0   \n","134                              0.0                               0.0   \n","190                              0.0                              67.0   \n","192                              0.0                              67.0   \n","235                              0.0                               4.0   \n","237                              0.0                               4.0   \n","245                              0.0                               0.0   \n","247                              0.0                               0.0   \n","287                              0.0                               0.0   \n","289                              0.0                               0.0   \n","292                              0.0                               3.0   \n","294                              0.0                               3.0   \n","330                              0.0                              12.0   \n","332                              0.0                              12.0   \n","344                              0.0                               3.0   \n","346                              0.0                               3.0   \n","348                              0.0                               0.0   \n","350                              0.0                               0.0   \n","379                              0.0                              22.0   \n","381                              0.0                              22.0   \n","384                              0.0                              17.0   \n","386                              0.0                              17.0   \n","388                              0.0                               0.0   \n","390                              0.0                               0.0   \n","395                              0.0                               1.0   \n","397                              0.0                               1.0   \n","402                              0.0                              10.0   \n","404                              0.0                              10.0   \n","410                             10.0                              16.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","27                                 0.0                                0.0   \n","29                                 0.0                                0.0   \n","92                                 0.0                                1.0   \n","94                                 0.0                                1.0   \n","111                                2.0                                1.0   \n","113                                2.0                                1.0   \n","125                                0.0                                0.0   \n","127                                0.0                                0.0   \n","132                                4.0                                0.0   \n","134                                4.0                                0.0   \n","190                                0.0                                0.0   \n","192                                0.0                                0.0   \n","235                                1.0                                0.0   \n","237                                1.0                                0.0   \n","245                                0.0                                0.0   \n","247                                0.0                                0.0   \n","287                                0.0                                5.0   \n","289                                0.0                                5.0   \n","292                                0.0                                0.0   \n","294                                0.0                                0.0   \n","330                                0.0                                0.0   \n","332                                0.0                                0.0   \n","344                                9.0                                0.0   \n","346                                9.0                                0.0   \n","348                                0.0                                0.0   \n","350                                0.0                                0.0   \n","379                                0.0                                0.0   \n","381                                0.0                                0.0   \n","384                                0.0                                0.0   \n","386                                0.0                                0.0   \n","388                                0.0                                0.0   \n","390                                0.0                                0.0   \n","395                                0.0                                0.0   \n","397                                0.0                                0.0   \n","402                                0.0                                0.0   \n","404                                0.0                                0.0   \n","410                                2.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Influenza  Rash  Somnolence  ...  \\\n","27                                14.0        0.0   0.0         0.0  ...   \n","29                                14.0        0.0   0.0         0.0  ...   \n","92                                 1.0        0.0   4.0         0.0  ...   \n","94                                 1.0        0.0   4.0         0.0  ...   \n","111                                5.0        0.0   0.0         0.0  ...   \n","113                                5.0        0.0   0.0         0.0  ...   \n","125                                0.0        0.0   0.0         0.0  ...   \n","127                                0.0        0.0   0.0         0.0  ...   \n","132                               15.0        0.0   0.0        20.0  ...   \n","134                               15.0        0.0   0.0        20.0  ...   \n","190                                0.0        0.0   0.0         0.0  ...   \n","192                                0.0        0.0   0.0         0.0  ...   \n","235                                5.0        0.0   0.0         0.0  ...   \n","237                                5.0        0.0   0.0         0.0  ...   \n","245                                1.0        0.0   4.0         8.0  ...   \n","247                                1.0        0.0   4.0         8.0  ...   \n","287                               11.0        0.0   0.0         0.0  ...   \n","289                               11.0        0.0   0.0         0.0  ...   \n","292                                1.0        0.0   0.0         0.0  ...   \n","294                                1.0        0.0   0.0         0.0  ...   \n","330                                3.0        0.0   0.0         0.0  ...   \n","332                                3.0        0.0   0.0         0.0  ...   \n","344                                1.0        0.0   0.0         0.0  ...   \n","346                                1.0        0.0   0.0         0.0  ...   \n","348                                1.0        0.0   0.0         0.0  ...   \n","350                                1.0        0.0   0.0         0.0  ...   \n","379                                6.0        0.0   0.0         0.0  ...   \n","381                                6.0        0.0   0.0         0.0  ...   \n","384                                2.0        2.0   0.0         0.0  ...   \n","386                                2.0        2.0   0.0         0.0  ...   \n","388                                6.0        0.0   0.0         0.0  ...   \n","390                                6.0        0.0   0.0         0.0  ...   \n","395                                1.0        0.0   0.0         0.0  ...   \n","397                                1.0        0.0   0.0         0.0  ...   \n","402                                4.0        0.0   0.0         0.0  ...   \n","404                                4.0        0.0   0.0         0.0  ...   \n","410                                6.0        0.0   0.0         0.0  ...   \n","\n","     allocation_type_Not Reported  allocation_type_Randomized  \\\n","27                              0                           1   \n","29                              0                           1   \n","92                              0                           1   \n","94                              0                           1   \n","111                             0                           1   \n","113                             0                           1   \n","125                             0                           1   \n","127                             0                           1   \n","132                             0                           0   \n","134                             0                           0   \n","190                             0                           1   \n","192                             0                           1   \n","235                             0                           1   \n","237                             0                           1   \n","245                             0                           1   \n","247                             0                           1   \n","287                             0                           1   \n","289                             0                           1   \n","292                             1                           0   \n","294                             1                           0   \n","330                             0                           1   \n","332                             0                           1   \n","344                             0                           1   \n","346                             0                           1   \n","348                             0                           1   \n","350                             0                           1   \n","379                             0                           1   \n","381                             0                           1   \n","384                             0                           1   \n","386                             0                           1   \n","388                             0                           1   \n","390                             0                           1   \n","395                             0                           1   \n","397                             0                           1   \n","402                             0                           1   \n","404                             0                           1   \n","410                             0                           1   \n","\n","     masking_type_Double  masking_type_None (Open Label)  \\\n","27                     1                               0   \n","29                     1                               0   \n","92                     0                               0   \n","94                     0                               0   \n","111                    0                               0   \n","113                    0                               0   \n","125                    0                               0   \n","127                    0                               0   \n","132                    0                               1   \n","134                    0                               1   \n","190                    0                               1   \n","192                    0                               1   \n","235                    0                               0   \n","237                    0                               0   \n","245                    0                               0   \n","247                    0                               0   \n","287                    0                               0   \n","289                    0                               0   \n","292                    0                               1   \n","294                    0                               1   \n","330                    0                               1   \n","332                    0                               1   \n","344                    1                               0   \n","346                    1                               0   \n","348                    0                               0   \n","350                    0                               0   \n","379                    0                               1   \n","381                    0                               1   \n","384                    0                               1   \n","386                    0                               1   \n","388                    1                               0   \n","390                    1                               0   \n","395                    0                               0   \n","397                    0                               0   \n","402                    0                               1   \n","404                    0                               1   \n","410                    0                               0   \n","\n","     masking_type_Quadruple  masking_type_Single  masking_type_Triple  \\\n","27                        0                    0                    0   \n","29                        0                    0                    0   \n","92                        1                    0                    0   \n","94                        1                    0                    0   \n","111                       0                    0                    1   \n","113                       0                    0                    1   \n","125                       0                    0                    1   \n","127                       0                    0                    1   \n","132                       0                    0                    0   \n","134                       0                    0                    0   \n","190                       0                    0                    0   \n","192                       0                    0                    0   \n","235                       1                    0                    0   \n","237                       1                    0                    0   \n","245                       1                    0                    0   \n","247                       1                    0                    0   \n","287                       1                    0                    0   \n","289                       1                    0                    0   \n","292                       0                    0                    0   \n","294                       0                    0                    0   \n","330                       0                    0                    0   \n","332                       0                    0                    0   \n","344                       0                    0                    0   \n","346                       0                    0                    0   \n","348                       1                    0                    0   \n","350                       1                    0                    0   \n","379                       0                    0                    0   \n","381                       0                    0                    0   \n","384                       0                    0                    0   \n","386                       0                    0                    0   \n","388                       0                    0                    0   \n","390                       0                    0                    0   \n","395                       0                    1                    0   \n","397                       0                    1                    0   \n","402                       0                    0                    0   \n","404                       0                    0                    0   \n","410                       0                    0                    1   \n","\n","     study_gender_eligibility_All  study_gender_eligibility_Female  \\\n","27                              1                                0   \n","29                              1                                0   \n","92                              1                                0   \n","94                              1                                0   \n","111                             0                                1   \n","113                             0                                1   \n","125                             0                                1   \n","127                             0                                1   \n","132                             1                                0   \n","134                             1                                0   \n","190                             1                                0   \n","192                             1                                0   \n","235                             0                                1   \n","237                             0                                1   \n","245                             1                                0   \n","247                             1                                0   \n","287                             1                                0   \n","289                             1                                0   \n","292                             1                                0   \n","294                             1                                0   \n","330                             1                                0   \n","332                             1                                0   \n","344                             1                                0   \n","346                             1                                0   \n","348                             1                                0   \n","350                             1                                0   \n","379                             1                                0   \n","381                             1                                0   \n","384                             1                                0   \n","386                             1                                0   \n","388                             0                                0   \n","390                             0                                0   \n","395                             1                                0   \n","397                             1                                0   \n","402                             1                                0   \n","404                             1                                0   \n","410                             1                                0   \n","\n","     study_gender_eligibility_Male  \n","27                               0  \n","29                               0  \n","92                               0  \n","94                               0  \n","111                              0  \n","113                              0  \n","125                              0  \n","127                              0  \n","132                              0  \n","134                              0  \n","190                              0  \n","192                              0  \n","235                              0  \n","237                              0  \n","245                              0  \n","247                              0  \n","287                              0  \n","289                              0  \n","292                              0  \n","294                              0  \n","330                              0  \n","332                              0  \n","344                              0  \n","346                              0  \n","348                              0  \n","350                              0  \n","379                              0  \n","381                              0  \n","384                              0  \n","386                              0  \n","388                              1  \n","390                              1  \n","395                              0  \n","397                              0  \n","402                              0  \n","404                              0  \n","410                              0  \n","\n","[37 rows x 80 columns]"],"text/html":["\n","  <div id=\"df-c295d5ae-e302-4d6a-9cbf-87858b5c611f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>Rash</th>\n","      <th>Somnolence</th>\n","      <th>...</th>\n","      <th>allocation_type_Not Reported</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Female</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>27</th>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>94</th>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>111</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>113</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>125</th>\n","      <td>1.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>127</th>\n","      <td>1.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>20.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>134</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>20.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>190</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>67.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>67.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>235</th>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>237</th>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>245</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>8.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>247</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>8.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>287</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>289</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>292</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>294</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>330</th>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>332</th>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>344</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>346</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>348</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>350</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>379</th>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>381</th>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>384</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>17.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>386</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>17.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>388</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>390</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>395</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>397</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>402</th>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>404</th>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>410</th>\n","      <td>8.0</td>\n","      <td>5.0</td>\n","      <td>10.0</td>\n","      <td>16.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>37 rows × 80 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c295d5ae-e302-4d6a-9cbf-87858b5c611f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c295d5ae-e302-4d6a-9cbf-87858b5c611f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c295d5ae-e302-4d6a-9cbf-87858b5c611f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":159}],"source":["#drop all columns that contain only zeros\n","X_df = X_df.loc[:, (X_df != 0).any(axis=0)]\n","X_df"]},{"cell_type":"markdown","metadata":{"id":"4B3sGPgEOjk-"},"source":["### Colinearity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PfGNmC5YOjk-"},"outputs":[],"source":["from statsmodels.stats.outliers_influence import variance_inflation_factor    \n","\n","def calculate_vif_(X_df, thresh=4.0):\n","    variables = list(range(X_df.shape[1]))\n","    dropped = True\n","    while dropped:\n","        dropped = False\n","        vif = [variance_inflation_factor(X_df.iloc[:, variables].values, ix)\n","               for ix in range(X_df.iloc[:, variables].shape[1])]\n","\n","        maxloc = vif.index(max(vif))\n","        if max(vif) > thresh:\n","            print('dropping \\'' + X_df.iloc[:, variables].columns[maxloc] +\n","                  '\\' at index: ' + str(maxloc))\n","            del variables[maxloc]\n","            dropped = True\n","\n","    print('Remaining variables:')\n","    print(X_df.columns[variables])\n","    return X_df.iloc[:, variables]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Jclt2J9Ojk-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896570534,"user_tz":240,"elapsed":156,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"41107435-e8c2-41c7-8361-61d11c1aac0a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  \\\n","27                            0.0   \n","29                            0.0   \n","92                            0.0   \n","94                            0.0   \n","111                           0.0   \n","113                           0.0   \n","125                           1.0   \n","127                           1.0   \n","132                           0.0   \n","134                           0.0   \n","190                           0.0   \n","192                           0.0   \n","235                           0.0   \n","237                           0.0   \n","245                           1.0   \n","247                           1.0   \n","287                           1.0   \n","289                           1.0   \n","292                           0.0   \n","294                           0.0   \n","330                           0.0   \n","332                           0.0   \n","344                           0.0   \n","346                           0.0   \n","348                           0.0   \n","350                           0.0   \n","379                           0.0   \n","381                           0.0   \n","384                           0.0   \n","386                           0.0   \n","388                           0.0   \n","390                           0.0   \n","395                           0.0   \n","397                           0.0   \n","402                           2.0   \n","404                           2.0   \n","410                           8.0   \n","\n","     dropout_reason_inclusion/exclusion criteria issue  \\\n","27                                                22.0   \n","29                                                22.0   \n","92                                                 3.0   \n","94                                                 3.0   \n","111                                                0.0   \n","113                                                0.0   \n","125                                                8.0   \n","127                                                8.0   \n","132                                                0.0   \n","134                                                0.0   \n","190                                                0.0   \n","192                                                0.0   \n","235                                                8.0   \n","237                                                8.0   \n","245                                                0.0   \n","247                                                0.0   \n","287                                                0.0   \n","289                                                0.0   \n","292                                                1.0   \n","294                                                1.0   \n","330                                                4.0   \n","332                                                4.0   \n","344                                                0.0   \n","346                                                0.0   \n","348                                                0.0   \n","350                                                0.0   \n","379                                                8.0   \n","381                                                8.0   \n","384                                                0.0   \n","386                                                0.0   \n","388                                                0.0   \n","390                                                0.0   \n","395                                                0.0   \n","397                                                0.0   \n","402                                                0.0   \n","404                                                0.0   \n","410                                                5.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","27                               0.0                               5.0   \n","29                               0.0                               5.0   \n","92                               0.0                               1.0   \n","94                               0.0                               1.0   \n","111                              0.0                               1.0   \n","113                              0.0                               1.0   \n","125                              0.0                               0.0   \n","127                              0.0                               0.0   \n","132                              0.0                               0.0   \n","134                              0.0                               0.0   \n","190                              0.0                              67.0   \n","192                              0.0                              67.0   \n","235                              0.0                               4.0   \n","237                              0.0                               4.0   \n","245                              0.0                               0.0   \n","247                              0.0                               0.0   \n","287                              0.0                               0.0   \n","289                              0.0                               0.0   \n","292                              0.0                               3.0   \n","294                              0.0                               3.0   \n","330                              0.0                              12.0   \n","332                              0.0                              12.0   \n","344                              0.0                               3.0   \n","346                              0.0                               3.0   \n","348                              0.0                               0.0   \n","350                              0.0                               0.0   \n","379                              0.0                              22.0   \n","381                              0.0                              22.0   \n","384                              0.0                              17.0   \n","386                              0.0                              17.0   \n","388                              0.0                               0.0   \n","390                              0.0                               0.0   \n","395                              0.0                               1.0   \n","397                              0.0                               1.0   \n","402                              0.0                              10.0   \n","404                              0.0                              10.0   \n","410                             10.0                              16.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","27                                 0.0                                0.0   \n","29                                 0.0                                0.0   \n","92                                 0.0                                1.0   \n","94                                 0.0                                1.0   \n","111                                2.0                                1.0   \n","113                                2.0                                1.0   \n","125                                0.0                                0.0   \n","127                                0.0                                0.0   \n","132                                4.0                                0.0   \n","134                                4.0                                0.0   \n","190                                0.0                                0.0   \n","192                                0.0                                0.0   \n","235                                1.0                                0.0   \n","237                                1.0                                0.0   \n","245                                0.0                                0.0   \n","247                                0.0                                0.0   \n","287                                0.0                                5.0   \n","289                                0.0                                5.0   \n","292                                0.0                                0.0   \n","294                                0.0                                0.0   \n","330                                0.0                                0.0   \n","332                                0.0                                0.0   \n","344                                9.0                                0.0   \n","346                                9.0                                0.0   \n","348                                0.0                                0.0   \n","350                                0.0                                0.0   \n","379                                0.0                                0.0   \n","381                                0.0                                0.0   \n","384                                0.0                                0.0   \n","386                                0.0                                0.0   \n","388                                0.0                                0.0   \n","390                                0.0                                0.0   \n","395                                0.0                                0.0   \n","397                                0.0                                0.0   \n","402                                0.0                                0.0   \n","404                                0.0                                0.0   \n","410                                2.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Influenza  Rash  Somnolence  ...  \\\n","27                                14.0        0.0   0.0         0.0  ...   \n","29                                14.0        0.0   0.0         0.0  ...   \n","92                                 1.0        0.0   4.0         0.0  ...   \n","94                                 1.0        0.0   4.0         0.0  ...   \n","111                                5.0        0.0   0.0         0.0  ...   \n","113                                5.0        0.0   0.0         0.0  ...   \n","125                                0.0        0.0   0.0         0.0  ...   \n","127                                0.0        0.0   0.0         0.0  ...   \n","132                               15.0        0.0   0.0        20.0  ...   \n","134                               15.0        0.0   0.0        20.0  ...   \n","190                                0.0        0.0   0.0         0.0  ...   \n","192                                0.0        0.0   0.0         0.0  ...   \n","235                                5.0        0.0   0.0         0.0  ...   \n","237                                5.0        0.0   0.0         0.0  ...   \n","245                                1.0        0.0   4.0         8.0  ...   \n","247                                1.0        0.0   4.0         8.0  ...   \n","287                               11.0        0.0   0.0         0.0  ...   \n","289                               11.0        0.0   0.0         0.0  ...   \n","292                                1.0        0.0   0.0         0.0  ...   \n","294                                1.0        0.0   0.0         0.0  ...   \n","330                                3.0        0.0   0.0         0.0  ...   \n","332                                3.0        0.0   0.0         0.0  ...   \n","344                                1.0        0.0   0.0         0.0  ...   \n","346                                1.0        0.0   0.0         0.0  ...   \n","348                                1.0        0.0   0.0         0.0  ...   \n","350                                1.0        0.0   0.0         0.0  ...   \n","379                                6.0        0.0   0.0         0.0  ...   \n","381                                6.0        0.0   0.0         0.0  ...   \n","384                                2.0        2.0   0.0         0.0  ...   \n","386                                2.0        2.0   0.0         0.0  ...   \n","388                                6.0        0.0   0.0         0.0  ...   \n","390                                6.0        0.0   0.0         0.0  ...   \n","395                                1.0        0.0   0.0         0.0  ...   \n","397                                1.0        0.0   0.0         0.0  ...   \n","402                                4.0        0.0   0.0         0.0  ...   \n","404                                4.0        0.0   0.0         0.0  ...   \n","410                                6.0        0.0   0.0         0.0  ...   \n","\n","     allocation_type_Not Reported  allocation_type_Randomized  \\\n","27                              0                           1   \n","29                              0                           1   \n","92                              0                           1   \n","94                              0                           1   \n","111                             0                           1   \n","113                             0                           1   \n","125                             0                           1   \n","127                             0                           1   \n","132                             0                           0   \n","134                             0                           0   \n","190                             0                           1   \n","192                             0                           1   \n","235                             0                           1   \n","237                             0                           1   \n","245                             0                           1   \n","247                             0                           1   \n","287                             0                           1   \n","289                             0                           1   \n","292                             1                           0   \n","294                             1                           0   \n","330                             0                           1   \n","332                             0                           1   \n","344                             0                           1   \n","346                             0                           1   \n","348                             0                           1   \n","350                             0                           1   \n","379                             0                           1   \n","381                             0                           1   \n","384                             0                           1   \n","386                             0                           1   \n","388                             0                           1   \n","390                             0                           1   \n","395                             0                           1   \n","397                             0                           1   \n","402                             0                           1   \n","404                             0                           1   \n","410                             0                           1   \n","\n","     masking_type_Double  masking_type_None (Open Label)  \\\n","27                     1                               0   \n","29                     1                               0   \n","92                     0                               0   \n","94                     0                               0   \n","111                    0                               0   \n","113                    0                               0   \n","125                    0                               0   \n","127                    0                               0   \n","132                    0                               1   \n","134                    0                               1   \n","190                    0                               1   \n","192                    0                               1   \n","235                    0                               0   \n","237                    0                               0   \n","245                    0                               0   \n","247                    0                               0   \n","287                    0                               0   \n","289                    0                               0   \n","292                    0                               1   \n","294                    0                               1   \n","330                    0                               1   \n","332                    0                               1   \n","344                    1                               0   \n","346                    1                               0   \n","348                    0                               0   \n","350                    0                               0   \n","379                    0                               1   \n","381                    0                               1   \n","384                    0                               1   \n","386                    0                               1   \n","388                    1                               0   \n","390                    1                               0   \n","395                    0                               0   \n","397                    0                               0   \n","402                    0                               1   \n","404                    0                               1   \n","410                    0                               0   \n","\n","     masking_type_Quadruple  masking_type_Single  masking_type_Triple  \\\n","27                        0                    0                    0   \n","29                        0                    0                    0   \n","92                        1                    0                    0   \n","94                        1                    0                    0   \n","111                       0                    0                    1   \n","113                       0                    0                    1   \n","125                       0                    0                    1   \n","127                       0                    0                    1   \n","132                       0                    0                    0   \n","134                       0                    0                    0   \n","190                       0                    0                    0   \n","192                       0                    0                    0   \n","235                       1                    0                    0   \n","237                       1                    0                    0   \n","245                       1                    0                    0   \n","247                       1                    0                    0   \n","287                       1                    0                    0   \n","289                       1                    0                    0   \n","292                       0                    0                    0   \n","294                       0                    0                    0   \n","330                       0                    0                    0   \n","332                       0                    0                    0   \n","344                       0                    0                    0   \n","346                       0                    0                    0   \n","348                       1                    0                    0   \n","350                       1                    0                    0   \n","379                       0                    0                    0   \n","381                       0                    0                    0   \n","384                       0                    0                    0   \n","386                       0                    0                    0   \n","388                       0                    0                    0   \n","390                       0                    0                    0   \n","395                       0                    1                    0   \n","397                       0                    1                    0   \n","402                       0                    0                    0   \n","404                       0                    0                    0   \n","410                       0                    0                    1   \n","\n","     study_gender_eligibility_All  study_gender_eligibility_Female  \\\n","27                              1                                0   \n","29                              1                                0   \n","92                              1                                0   \n","94                              1                                0   \n","111                             0                                1   \n","113                             0                                1   \n","125                             0                                1   \n","127                             0                                1   \n","132                             1                                0   \n","134                             1                                0   \n","190                             1                                0   \n","192                             1                                0   \n","235                             0                                1   \n","237                             0                                1   \n","245                             1                                0   \n","247                             1                                0   \n","287                             1                                0   \n","289                             1                                0   \n","292                             1                                0   \n","294                             1                                0   \n","330                             1                                0   \n","332                             1                                0   \n","344                             1                                0   \n","346                             1                                0   \n","348                             1                                0   \n","350                             1                                0   \n","379                             1                                0   \n","381                             1                                0   \n","384                             1                                0   \n","386                             1                                0   \n","388                             0                                0   \n","390                             0                                0   \n","395                             1                                0   \n","397                             1                                0   \n","402                             1                                0   \n","404                             1                                0   \n","410                             1                                0   \n","\n","     study_gender_eligibility_Male  \n","27                               0  \n","29                               0  \n","92                               0  \n","94                               0  \n","111                              0  \n","113                              0  \n","125                              0  \n","127                              0  \n","132                              0  \n","134                              0  \n","190                              0  \n","192                              0  \n","235                              0  \n","237                              0  \n","245                              0  \n","247                              0  \n","287                              0  \n","289                              0  \n","292                              0  \n","294                              0  \n","330                              0  \n","332                              0  \n","344                              0  \n","346                              0  \n","348                              0  \n","350                              0  \n","379                              0  \n","381                              0  \n","384                              0  \n","386                              0  \n","388                              1  \n","390                              1  \n","395                              0  \n","397                              0  \n","402                              0  \n","404                              0  \n","410                              0  \n","\n","[37 rows x 80 columns]"],"text/html":["\n","  <div id=\"df-9284c991-b4c5-462a-a067-d9fcc381a606\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>Rash</th>\n","      <th>Somnolence</th>\n","      <th>...</th>\n","      <th>allocation_type_Not Reported</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Female</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>27</th>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>94</th>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>111</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>113</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>125</th>\n","      <td>1.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>127</th>\n","      <td>1.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>20.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>134</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>20.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>190</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>67.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>67.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>235</th>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>237</th>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>245</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>8.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>247</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>8.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>287</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>289</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>292</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>294</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>330</th>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>332</th>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>344</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>346</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>348</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>350</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>379</th>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>381</th>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>384</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>17.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>386</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>17.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>388</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>390</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>395</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>397</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>402</th>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>404</th>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>410</th>\n","      <td>8.0</td>\n","      <td>5.0</td>\n","      <td>10.0</td>\n","      <td>16.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>37 rows × 80 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9284c991-b4c5-462a-a067-d9fcc381a606')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9284c991-b4c5-462a-a067-d9fcc381a606 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9284c991-b4c5-462a-a067-d9fcc381a606');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":161}],"source":["X_df"]},{"cell_type":"markdown","metadata":{"id":"S_YZL3IxcwwY"},"source":["### Corelated Feature Drop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N_gbS_m1cwwZ","colab":{"base_uri":"https://localhost:8080/","height":334},"executionInfo":{"status":"ok","timestamp":1659896571149,"user_tz":240,"elapsed":162,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"2166d250-7982-4d20-b429-5ea8d2e9ced6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   dropout_reason_adverse event  \\\n","dropout_reason_adverse event                                           1.000000   \n","dropout_reason_inclusion/exclusion criteria issue                      0.003749   \n","dropout_reason_lack of efficacy                                        0.915385   \n","dropout_reason_lost to follow-up                                       0.023230   \n","dropout_reason_physician decision                                     -0.004886   \n","\n","                                                   dropout_reason_inclusion/exclusion criteria issue  \\\n","dropout_reason_adverse event                                                                0.003749   \n","dropout_reason_inclusion/exclusion criteria issue                                           1.000000   \n","dropout_reason_lack of efficacy                                                             0.059922   \n","dropout_reason_lost to follow-up                                                           -0.037710   \n","dropout_reason_physician decision                                                          -0.177832   \n","\n","                                                   dropout_reason_lack of efficacy  \\\n","dropout_reason_adverse event                                              0.915385   \n","dropout_reason_inclusion/exclusion criteria issue                         0.059922   \n","dropout_reason_lack of efficacy                                           1.000000   \n","dropout_reason_lost to follow-up                                          0.082819   \n","dropout_reason_physician decision                                         0.082437   \n","\n","                                                   dropout_reason_lost to follow-up  \\\n","dropout_reason_adverse event                                               0.023230   \n","dropout_reason_inclusion/exclusion criteria issue                         -0.037710   \n","dropout_reason_lack of efficacy                                            0.082819   \n","dropout_reason_lost to follow-up                                           1.000000   \n","dropout_reason_physician decision                                         -0.148120   \n","\n","                                                   dropout_reason_physician decision  \\\n","dropout_reason_adverse event                                               -0.004886   \n","dropout_reason_inclusion/exclusion criteria issue                          -0.177832   \n","dropout_reason_lack of efficacy                                             0.082437   \n","dropout_reason_lost to follow-up                                           -0.148120   \n","dropout_reason_physician decision                                           1.000000   \n","\n","                                                   dropout_reason_protocol violation  \\\n","dropout_reason_adverse event                                                0.054918   \n","dropout_reason_inclusion/exclusion criteria issue                          -0.159981   \n","dropout_reason_lack of efficacy                                            -0.054967   \n","dropout_reason_lost to follow-up                                           -0.171632   \n","dropout_reason_physician decision                                          -0.095545   \n","\n","                                                   dropout_reason_subject withdrawal  \\\n","dropout_reason_adverse event                                                0.044829   \n","dropout_reason_inclusion/exclusion criteria issue                           0.407365   \n","dropout_reason_lack of efficacy                                             0.062360   \n","dropout_reason_lost to follow-up                                           -0.213275   \n","dropout_reason_physician decision                                           0.091041   \n","\n","                                                   Influenza      Rash  \\\n","dropout_reason_adverse event                       -0.085009  0.003439   \n","dropout_reason_inclusion/exclusion criteria issue  -0.134886 -0.099965   \n","dropout_reason_lack of efficacy                    -0.039841 -0.058026   \n","dropout_reason_lost to follow-up                    0.134261 -0.176355   \n","dropout_reason_physician decision                  -0.100501 -0.146374   \n","\n","                                                   Somnolence  ...  \\\n","dropout_reason_adverse event                        -0.046529  ...   \n","dropout_reason_inclusion/exclusion criteria issue   -0.178894  ...   \n","dropout_reason_lack of efficacy                     -0.052840  ...   \n","dropout_reason_lost to follow-up                    -0.170855  ...   \n","dropout_reason_physician decision                    0.281143  ...   \n","\n","                                                   allocation_type_Not Reported  \\\n","dropout_reason_adverse event                                          -0.085009   \n","dropout_reason_inclusion/exclusion criteria issue                     -0.090720   \n","dropout_reason_lack of efficacy                                       -0.039841   \n","dropout_reason_lost to follow-up                                      -0.082397   \n","dropout_reason_physician decision                                     -0.100501   \n","\n","                                                   allocation_type_Randomized  \\\n","dropout_reason_adverse event                                         0.123810   \n","dropout_reason_inclusion/exclusion criteria issue                    0.164290   \n","dropout_reason_lack of efficacy                                      0.058026   \n","dropout_reason_lost to follow-up                                     0.153815   \n","dropout_reason_physician decision                                   -0.172204   \n","\n","                                                   masking_type_Double  \\\n","dropout_reason_adverse event                                 -0.156451   \n","dropout_reason_inclusion/exclusion criteria issue             0.347835   \n","dropout_reason_lack of efficacy                              -0.073324   \n","dropout_reason_lost to follow-up                             -0.161138   \n","dropout_reason_physician decision                             0.418887   \n","\n","                                                   masking_type_None (Open Label)  \\\n","dropout_reason_adverse event                                            -0.114503   \n","dropout_reason_inclusion/exclusion criteria issue                       -0.172532   \n","dropout_reason_lack of efficacy                                         -0.130032   \n","dropout_reason_lost to follow-up                                         0.524785   \n","dropout_reason_physician decision                                       -0.124038   \n","\n","                                                   masking_type_Quadruple  \\\n","dropout_reason_adverse event                                    -0.038475   \n","dropout_reason_inclusion/exclusion criteria issue               -0.096031   \n","dropout_reason_lack of efficacy                                 -0.101430   \n","dropout_reason_lost to follow-up                                -0.288571   \n","dropout_reason_physician decision                               -0.200175   \n","\n","                                                   masking_type_Single  \\\n","dropout_reason_adverse event                                 -0.085009   \n","dropout_reason_inclusion/exclusion criteria issue            -0.134886   \n","dropout_reason_lack of efficacy                              -0.039841   \n","dropout_reason_lost to follow-up                             -0.113348   \n","dropout_reason_physician decision                            -0.100501   \n","\n","                                                   masking_type_Triple  \\\n","dropout_reason_adverse event                                  0.437329   \n","dropout_reason_inclusion/exclusion criteria issue             0.083692   \n","dropout_reason_lack of efficacy                               0.421637   \n","dropout_reason_lost to follow-up                             -0.120897   \n","dropout_reason_physician decision                             0.050834   \n","\n","                                                   study_gender_eligibility_All  \\\n","dropout_reason_adverse event                                           0.090796   \n","dropout_reason_inclusion/exclusion criteria issue                     -0.091795   \n","dropout_reason_lack of efficacy                                        0.087538   \n","dropout_reason_lost to follow-up                                       0.240546   \n","dropout_reason_physician decision                                      0.040592   \n","\n","                                                   study_gender_eligibility_Female  \\\n","dropout_reason_adverse event                                             -0.049253   \n","dropout_reason_inclusion/exclusion criteria issue                         0.185268   \n","dropout_reason_lack of efficacy                                          -0.073324   \n","dropout_reason_lost to follow-up                                         -0.189620   \n","dropout_reason_physician decision                                         0.016320   \n","\n","                                                   study_gender_eligibility_Male  \n","dropout_reason_adverse event                                           -0.085009  \n","dropout_reason_inclusion/exclusion criteria issue                      -0.134886  \n","dropout_reason_lack of efficacy                                        -0.039841  \n","dropout_reason_lost to follow-up                                       -0.128824  \n","dropout_reason_physician decision                                      -0.100501  \n","\n","[5 rows x 80 columns]"],"text/html":["\n","  <div id=\"df-ce898a91-08f6-4ba1-ace0-f836b81f7cfb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>Rash</th>\n","      <th>Somnolence</th>\n","      <th>...</th>\n","      <th>allocation_type_Not Reported</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Female</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>dropout_reason_adverse event</th>\n","      <td>1.000000</td>\n","      <td>0.003749</td>\n","      <td>0.915385</td>\n","      <td>0.023230</td>\n","      <td>-0.004886</td>\n","      <td>0.054918</td>\n","      <td>0.044829</td>\n","      <td>-0.085009</td>\n","      <td>0.003439</td>\n","      <td>-0.046529</td>\n","      <td>...</td>\n","      <td>-0.085009</td>\n","      <td>0.123810</td>\n","      <td>-0.156451</td>\n","      <td>-0.114503</td>\n","      <td>-0.038475</td>\n","      <td>-0.085009</td>\n","      <td>0.437329</td>\n","      <td>0.090796</td>\n","      <td>-0.049253</td>\n","      <td>-0.085009</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <td>0.003749</td>\n","      <td>1.000000</td>\n","      <td>0.059922</td>\n","      <td>-0.037710</td>\n","      <td>-0.177832</td>\n","      <td>-0.159981</td>\n","      <td>0.407365</td>\n","      <td>-0.134886</td>\n","      <td>-0.099965</td>\n","      <td>-0.178894</td>\n","      <td>...</td>\n","      <td>-0.090720</td>\n","      <td>0.164290</td>\n","      <td>0.347835</td>\n","      <td>-0.172532</td>\n","      <td>-0.096031</td>\n","      <td>-0.134886</td>\n","      <td>0.083692</td>\n","      <td>-0.091795</td>\n","      <td>0.185268</td>\n","      <td>-0.134886</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <td>0.915385</td>\n","      <td>0.059922</td>\n","      <td>1.000000</td>\n","      <td>0.082819</td>\n","      <td>0.082437</td>\n","      <td>-0.054967</td>\n","      <td>0.062360</td>\n","      <td>-0.039841</td>\n","      <td>-0.058026</td>\n","      <td>-0.052840</td>\n","      <td>...</td>\n","      <td>-0.039841</td>\n","      <td>0.058026</td>\n","      <td>-0.073324</td>\n","      <td>-0.130032</td>\n","      <td>-0.101430</td>\n","      <td>-0.039841</td>\n","      <td>0.421637</td>\n","      <td>0.087538</td>\n","      <td>-0.073324</td>\n","      <td>-0.039841</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <td>0.023230</td>\n","      <td>-0.037710</td>\n","      <td>0.082819</td>\n","      <td>1.000000</td>\n","      <td>-0.148120</td>\n","      <td>-0.171632</td>\n","      <td>-0.213275</td>\n","      <td>0.134261</td>\n","      <td>-0.176355</td>\n","      <td>-0.170855</td>\n","      <td>...</td>\n","      <td>-0.082397</td>\n","      <td>0.153815</td>\n","      <td>-0.161138</td>\n","      <td>0.524785</td>\n","      <td>-0.288571</td>\n","      <td>-0.113348</td>\n","      <td>-0.120897</td>\n","      <td>0.240546</td>\n","      <td>-0.189620</td>\n","      <td>-0.128824</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_physician decision</th>\n","      <td>-0.004886</td>\n","      <td>-0.177832</td>\n","      <td>0.082437</td>\n","      <td>-0.148120</td>\n","      <td>1.000000</td>\n","      <td>-0.095545</td>\n","      <td>0.091041</td>\n","      <td>-0.100501</td>\n","      <td>-0.146374</td>\n","      <td>0.281143</td>\n","      <td>...</td>\n","      <td>-0.100501</td>\n","      <td>-0.172204</td>\n","      <td>0.418887</td>\n","      <td>-0.124038</td>\n","      <td>-0.200175</td>\n","      <td>-0.100501</td>\n","      <td>0.050834</td>\n","      <td>0.040592</td>\n","      <td>0.016320</td>\n","      <td>-0.100501</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 80 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce898a91-08f6-4ba1-ace0-f836b81f7cfb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ce898a91-08f6-4ba1-ace0-f836b81f7cfb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ce898a91-08f6-4ba1-ace0-f836b81f7cfb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":162}],"source":["df_corr = X_df.corr()\n","df_corr.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aipwp-ITcwwZ"},"outputs":[],"source":["threshold = 0.9\n","\n","\n","columns = np.full((df_corr.shape[0],), True, dtype=bool)\n","for i in range(df_corr.shape[0]):\n","    for j in range(i+1, df_corr.shape[0]):\n","        if df_corr.iloc[i,j] >= threshold:\n","            if columns[j]:\n","                columns[j] = False\n","selected_columns = X_df.columns[columns]\n","selected_columns\n","X_df = X_df[selected_columns]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fMSRn7kfcwwZ","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1659896571494,"user_tz":240,"elapsed":4,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"449346da-484b-4cf6-8ced-0f17977b5487"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  \\\n","27                            0.0   \n","29                            0.0   \n","92                            0.0   \n","94                            0.0   \n","111                           0.0   \n","113                           0.0   \n","125                           1.0   \n","127                           1.0   \n","132                           0.0   \n","134                           0.0   \n","190                           0.0   \n","192                           0.0   \n","235                           0.0   \n","237                           0.0   \n","245                           1.0   \n","247                           1.0   \n","287                           1.0   \n","289                           1.0   \n","292                           0.0   \n","294                           0.0   \n","330                           0.0   \n","332                           0.0   \n","344                           0.0   \n","346                           0.0   \n","348                           0.0   \n","350                           0.0   \n","379                           0.0   \n","381                           0.0   \n","384                           0.0   \n","386                           0.0   \n","388                           0.0   \n","390                           0.0   \n","395                           0.0   \n","397                           0.0   \n","402                           2.0   \n","404                           2.0   \n","410                           8.0   \n","\n","     dropout_reason_inclusion/exclusion criteria issue  \\\n","27                                                22.0   \n","29                                                22.0   \n","92                                                 3.0   \n","94                                                 3.0   \n","111                                                0.0   \n","113                                                0.0   \n","125                                                8.0   \n","127                                                8.0   \n","132                                                0.0   \n","134                                                0.0   \n","190                                                0.0   \n","192                                                0.0   \n","235                                                8.0   \n","237                                                8.0   \n","245                                                0.0   \n","247                                                0.0   \n","287                                                0.0   \n","289                                                0.0   \n","292                                                1.0   \n","294                                                1.0   \n","330                                                4.0   \n","332                                                4.0   \n","344                                                0.0   \n","346                                                0.0   \n","348                                                0.0   \n","350                                                0.0   \n","379                                                8.0   \n","381                                                8.0   \n","384                                                0.0   \n","386                                                0.0   \n","388                                                0.0   \n","390                                                0.0   \n","395                                                0.0   \n","397                                                0.0   \n","402                                                0.0   \n","404                                                0.0   \n","410                                                5.0   \n","\n","     dropout_reason_lost to follow-up  dropout_reason_physician decision  \\\n","27                                5.0                                0.0   \n","29                                5.0                                0.0   \n","92                                1.0                                0.0   \n","94                                1.0                                0.0   \n","111                               1.0                                2.0   \n","113                               1.0                                2.0   \n","125                               0.0                                0.0   \n","127                               0.0                                0.0   \n","132                               0.0                                4.0   \n","134                               0.0                                4.0   \n","190                              67.0                                0.0   \n","192                              67.0                                0.0   \n","235                               4.0                                1.0   \n","237                               4.0                                1.0   \n","245                               0.0                                0.0   \n","247                               0.0                                0.0   \n","287                               0.0                                0.0   \n","289                               0.0                                0.0   \n","292                               3.0                                0.0   \n","294                               3.0                                0.0   \n","330                              12.0                                0.0   \n","332                              12.0                                0.0   \n","344                               3.0                                9.0   \n","346                               3.0                                9.0   \n","348                               0.0                                0.0   \n","350                               0.0                                0.0   \n","379                              22.0                                0.0   \n","381                              22.0                                0.0   \n","384                              17.0                                0.0   \n","386                              17.0                                0.0   \n","388                               0.0                                0.0   \n","390                               0.0                                0.0   \n","395                               1.0                                0.0   \n","397                               1.0                                0.0   \n","402                              10.0                                0.0   \n","404                              10.0                                0.0   \n","410                              16.0                                2.0   \n","\n","     dropout_reason_protocol violation  dropout_reason_subject withdrawal  \\\n","27                                 0.0                               14.0   \n","29                                 0.0                               14.0   \n","92                                 1.0                                1.0   \n","94                                 1.0                                1.0   \n","111                                1.0                                5.0   \n","113                                1.0                                5.0   \n","125                                0.0                                0.0   \n","127                                0.0                                0.0   \n","132                                0.0                               15.0   \n","134                                0.0                               15.0   \n","190                                0.0                                0.0   \n","192                                0.0                                0.0   \n","235                                0.0                                5.0   \n","237                                0.0                                5.0   \n","245                                0.0                                1.0   \n","247                                0.0                                1.0   \n","287                                5.0                               11.0   \n","289                                5.0                               11.0   \n","292                                0.0                                1.0   \n","294                                0.0                                1.0   \n","330                                0.0                                3.0   \n","332                                0.0                                3.0   \n","344                                0.0                                1.0   \n","346                                0.0                                1.0   \n","348                                0.0                                1.0   \n","350                                0.0                                1.0   \n","379                                0.0                                6.0   \n","381                                0.0                                6.0   \n","384                                0.0                                2.0   \n","386                                0.0                                2.0   \n","388                                0.0                                6.0   \n","390                                0.0                                6.0   \n","395                                0.0                                1.0   \n","397                                0.0                                1.0   \n","402                                0.0                                4.0   \n","404                                0.0                                4.0   \n","410                                0.0                                6.0   \n","\n","     Influenza  Rash  Somnolence  Nausea  ...  \\\n","27         0.0   0.0         0.0    60.0  ...   \n","29         0.0   0.0         0.0    60.0  ...   \n","92         0.0   4.0         0.0     0.0  ...   \n","94         0.0   4.0         0.0     0.0  ...   \n","111        0.0   0.0         0.0     0.0  ...   \n","113        0.0   0.0         0.0     0.0  ...   \n","125        0.0   0.0         0.0     0.0  ...   \n","127        0.0   0.0         0.0     0.0  ...   \n","132        0.0   0.0        20.0     0.0  ...   \n","134        0.0   0.0        20.0     0.0  ...   \n","190        0.0   0.0         0.0     0.0  ...   \n","192        0.0   0.0         0.0     0.0  ...   \n","235        0.0   0.0         0.0    64.0  ...   \n","237        0.0   0.0         0.0    64.0  ...   \n","245        0.0   4.0         8.0     0.0  ...   \n","247        0.0   4.0         8.0     0.0  ...   \n","287        0.0   0.0         0.0     0.0  ...   \n","289        0.0   0.0         0.0     0.0  ...   \n","292        0.0   0.0         0.0     0.0  ...   \n","294        0.0   0.0         0.0     0.0  ...   \n","330        0.0   0.0         0.0     0.0  ...   \n","332        0.0   0.0         0.0     0.0  ...   \n","344        0.0   0.0         0.0     0.0  ...   \n","346        0.0   0.0         0.0     0.0  ...   \n","348        0.0   0.0         0.0     0.0  ...   \n","350        0.0   0.0         0.0     0.0  ...   \n","379        0.0   0.0         0.0     0.0  ...   \n","381        0.0   0.0         0.0     0.0  ...   \n","384        2.0   0.0         0.0     0.0  ...   \n","386        2.0   0.0         0.0     0.0  ...   \n","388        0.0   0.0         0.0     0.0  ...   \n","390        0.0   0.0         0.0     0.0  ...   \n","395        0.0   0.0         0.0     0.0  ...   \n","397        0.0   0.0         0.0     0.0  ...   \n","402        0.0   0.0         0.0     0.0  ...   \n","404        0.0   0.0         0.0     0.0  ...   \n","410        0.0   0.0         0.0    15.0  ...   \n","\n","     intervention_model_type_Crossover Assignment  \\\n","27                                              0   \n","29                                              0   \n","92                                              1   \n","94                                              1   \n","111                                             0   \n","113                                             0   \n","125                                             0   \n","127                                             0   \n","132                                             0   \n","134                                             0   \n","190                                             0   \n","192                                             0   \n","235                                             0   \n","237                                             0   \n","245                                             1   \n","247                                             1   \n","287                                             0   \n","289                                             0   \n","292                                             0   \n","294                                             0   \n","330                                             0   \n","332                                             0   \n","344                                             0   \n","346                                             0   \n","348                                             1   \n","350                                             1   \n","379                                             0   \n","381                                             0   \n","384                                             0   \n","386                                             0   \n","388                                             0   \n","390                                             0   \n","395                                             0   \n","397                                             0   \n","402                                             0   \n","404                                             0   \n","410                                             0   \n","\n","     intervention_model_type_Parallel Assignment  allocation_type_Randomized  \\\n","27                                             1                           1   \n","29                                             1                           1   \n","92                                             0                           1   \n","94                                             0                           1   \n","111                                            1                           1   \n","113                                            1                           1   \n","125                                            1                           1   \n","127                                            1                           1   \n","132                                            1                           0   \n","134                                            1                           0   \n","190                                            1                           1   \n","192                                            1                           1   \n","235                                            1                           1   \n","237                                            1                           1   \n","245                                            0                           1   \n","247                                            0                           1   \n","287                                            1                           1   \n","289                                            1                           1   \n","292                                            0                           0   \n","294                                            0                           0   \n","330                                            1                           1   \n","332                                            1                           1   \n","344                                            1                           1   \n","346                                            1                           1   \n","348                                            0                           1   \n","350                                            0                           1   \n","379                                            1                           1   \n","381                                            1                           1   \n","384                                            1                           1   \n","386                                            1                           1   \n","388                                            1                           1   \n","390                                            1                           1   \n","395                                            1                           1   \n","397                                            1                           1   \n","402                                            1                           1   \n","404                                            1                           1   \n","410                                            1                           1   \n","\n","     masking_type_Double  masking_type_None (Open Label)  \\\n","27                     1                               0   \n","29                     1                               0   \n","92                     0                               0   \n","94                     0                               0   \n","111                    0                               0   \n","113                    0                               0   \n","125                    0                               0   \n","127                    0                               0   \n","132                    0                               1   \n","134                    0                               1   \n","190                    0                               1   \n","192                    0                               1   \n","235                    0                               0   \n","237                    0                               0   \n","245                    0                               0   \n","247                    0                               0   \n","287                    0                               0   \n","289                    0                               0   \n","292                    0                               1   \n","294                    0                               1   \n","330                    0                               1   \n","332                    0                               1   \n","344                    1                               0   \n","346                    1                               0   \n","348                    0                               0   \n","350                    0                               0   \n","379                    0                               1   \n","381                    0                               1   \n","384                    0                               1   \n","386                    0                               1   \n","388                    1                               0   \n","390                    1                               0   \n","395                    0                               0   \n","397                    0                               0   \n","402                    0                               1   \n","404                    0                               1   \n","410                    0                               0   \n","\n","     masking_type_Quadruple  masking_type_Single  masking_type_Triple  \\\n","27                        0                    0                    0   \n","29                        0                    0                    0   \n","92                        1                    0                    0   \n","94                        1                    0                    0   \n","111                       0                    0                    1   \n","113                       0                    0                    1   \n","125                       0                    0                    1   \n","127                       0                    0                    1   \n","132                       0                    0                    0   \n","134                       0                    0                    0   \n","190                       0                    0                    0   \n","192                       0                    0                    0   \n","235                       1                    0                    0   \n","237                       1                    0                    0   \n","245                       1                    0                    0   \n","247                       1                    0                    0   \n","287                       1                    0                    0   \n","289                       1                    0                    0   \n","292                       0                    0                    0   \n","294                       0                    0                    0   \n","330                       0                    0                    0   \n","332                       0                    0                    0   \n","344                       0                    0                    0   \n","346                       0                    0                    0   \n","348                       1                    0                    0   \n","350                       1                    0                    0   \n","379                       0                    0                    0   \n","381                       0                    0                    0   \n","384                       0                    0                    0   \n","386                       0                    0                    0   \n","388                       0                    0                    0   \n","390                       0                    0                    0   \n","395                       0                    1                    0   \n","397                       0                    1                    0   \n","402                       0                    0                    0   \n","404                       0                    0                    0   \n","410                       0                    0                    1   \n","\n","     study_gender_eligibility_All  study_gender_eligibility_Female  \n","27                              1                                0  \n","29                              1                                0  \n","92                              1                                0  \n","94                              1                                0  \n","111                             0                                1  \n","113                             0                                1  \n","125                             0                                1  \n","127                             0                                1  \n","132                             1                                0  \n","134                             1                                0  \n","190                             1                                0  \n","192                             1                                0  \n","235                             0                                1  \n","237                             0                                1  \n","245                             1                                0  \n","247                             1                                0  \n","287                             1                                0  \n","289                             1                                0  \n","292                             1                                0  \n","294                             1                                0  \n","330                             1                                0  \n","332                             1                                0  \n","344                             1                                0  \n","346                             1                                0  \n","348                             1                                0  \n","350                             1                                0  \n","379                             1                                0  \n","381                             1                                0  \n","384                             1                                0  \n","386                             1                                0  \n","388                             0                                0  \n","390                             0                                0  \n","395                             1                                0  \n","397                             1                                0  \n","402                             1                                0  \n","404                             1                                0  \n","410                             1                                0  \n","\n","[37 rows x 51 columns]"],"text/html":["\n","  <div id=\"df-fe19beaa-0760-475b-be29-f1e1634ee9ca\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>Rash</th>\n","      <th>Somnolence</th>\n","      <th>Nausea</th>\n","      <th>...</th>\n","      <th>intervention_model_type_Crossover Assignment</th>\n","      <th>intervention_model_type_Parallel Assignment</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Female</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>27</th>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>0.0</td>\n","      <td>22.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>60.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>94</th>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>111</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>113</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>125</th>\n","      <td>1.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>127</th>\n","      <td>1.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>20.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>134</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>20.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>190</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>67.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>67.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>235</th>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>64.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>237</th>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>64.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>245</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>247</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>287</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>289</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>292</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>294</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>330</th>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>332</th>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>344</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>346</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>348</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>350</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>379</th>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>381</th>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>384</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>17.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>386</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>17.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>388</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>390</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>395</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>397</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>402</th>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>404</th>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>410</th>\n","      <td>8.0</td>\n","      <td>5.0</td>\n","      <td>16.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>15.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>37 rows × 51 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe19beaa-0760-475b-be29-f1e1634ee9ca')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fe19beaa-0760-475b-be29-f1e1634ee9ca button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fe19beaa-0760-475b-be29-f1e1634ee9ca');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":164}],"source":["X_df"]},{"cell_type":"code","source":[""],"metadata":{"id":"RB-MZVVhi72l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N8P100zpcwwZ"},"source":["Standardize and split data "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oHF8UyrRcwwZ"},"outputs":[],"source":["X_df_norm = (X_df-X_df.min())/(X_df.max()-X_df.min())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3iVpHDDjhMqm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896571656,"user_tz":240,"elapsed":5,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"5e9640dc-5284-483a-a7d3-b608888c3392"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dropout_reason_adverse event                          0\n","dropout_reason_inclusion/exclusion criteria issue     0\n","dropout_reason_lost to follow-up                      0\n","dropout_reason_physician decision                     0\n","dropout_reason_protocol violation                     0\n","dropout_reason_subject withdrawal                     0\n","Influenza                                             0\n","Rash                                                  0\n","Somnolence                                            0\n","Nausea                                                0\n","Fatigue                                               0\n","Seizure                                               0\n","Dysuria                                               0\n","Headache                                              0\n","Pain in jaw                                           0\n","Aphasia                                               0\n","Feeling abnormal                                      0\n","Musculoskeletal stiffness                             0\n","Peptic ulcer                                          0\n","Ear infection                                         0\n","Binge drinking                                        0\n","Increased appetite                                    0\n","Panic attack                                          0\n","Suicide attempt                                       0\n","number_of_arms                                        0\n","has_dmc                                               0\n","study_duration_months                                 0\n","Accepts_Healthy_volunteers                            0\n","Behavioral                                            0\n","Other                                                 0\n","Procedure                                             0\n","Drug                                                  0\n","event_type_deaths                                     0\n","event_type_other                                      0\n","study_type_Interventional                            37\n","study_phase_Not Applicable                            0\n","study_phase_Phase 2                                   0\n","study_phase_Phase 3                                   0\n","study_phase_Phase 4                                   0\n","minimum_age_num_No Pediatric Subjects Included        0\n","minimum_age_num_Pediatric Subjects Included           0\n","intervention_model_type_Crossover Assignment          0\n","intervention_model_type_Parallel Assignment           0\n","allocation_type_Randomized                            0\n","masking_type_Double                                   0\n","masking_type_None (Open Label)                        0\n","masking_type_Quadruple                                0\n","masking_type_Single                                   0\n","masking_type_Triple                                   0\n","study_gender_eligibility_All                          0\n","study_gender_eligibility_Female                       0\n","dtype: int64"]},"metadata":{},"execution_count":166}],"source":["X_df_norm.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ILzlv5aWhRvb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896571656,"user_tz":240,"elapsed":3,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"e84e0e19-310b-40a3-9b79-6990533d3da9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Series([], dtype: object)"]},"metadata":{},"execution_count":167}],"source":["X_df_norm.columns.to_series()[np.isinf(X_df_norm).any()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UmVpgchZhshN"},"outputs":[],"source":["X_df_norm['study_type_Interventional'] = X_df_norm['study_type_Interventional'].fillna(0)"]},{"cell_type":"code","source":["mean(y_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V6C4_yBCi84r","executionInfo":{"status":"ok","timestamp":1659896589985,"user_tz":240,"elapsed":142,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"e5a30611-bf80-4e30-d366-25058ef908fe"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["21.933291946312977"]},"metadata":{},"execution_count":170}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ZOfrG-8cwwZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896571862,"user_tz":240,"elapsed":208,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"8636356e-7864-4b12-a4c7-7b7e9f8d9138"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((29, 51), (8, 51))"]},"metadata":{},"execution_count":169}],"source":["# Train/test split:\n","X_train, X_test, y_train, y_test = train_test_split(X_df_norm, y_df, test_size = 0.2, random_state = 2)\n","\n","X_train.shape, X_test.shape"]},{"cell_type":"code","source":[""],"metadata":{"id":"KP5Z-J7a0g2c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VVM2N9jw0g-w"},"source":["### Feature Selection"]},{"cell_type":"markdown","metadata":{"id":"rafh7mTP0g-w"},"source":["#### Feature Importance with Gradient Boosting"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1659890131292,"user_tz":240,"elapsed":178,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4661acf5-1779-49c7-f5d4-3335c78e0fb7","id":"CbL8IOuY0g-w"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4288759363250807"]},"metadata":{},"execution_count":28}],"source":["# GradientBoostingRegressor will be used for feature importance\n","reg_model = GradientBoostingRegressor(random_state=0)   \n","reg_model.fit(X_train, y_train)\n","y_preds = reg_model.predict(X_test)\n","r2_score(y_test, y_preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1659890131293,"user_tz":240,"elapsed":4,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"colab":{"base_uri":"https://localhost:8080/","height":676},"outputId":"a0c48973-a909-4f20-dca5-cf341bbe25e2","id":"Y3QEdF0H0g-w"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   importance\n","dropout_reason_inclusion/exclusion criteria issue    0.318439\n","dropout_reason_lost to follow-up                     0.058545\n","event_type_other                                     0.045327\n","Headache                                             0.040401\n","study_duration_months                                0.038388\n","Abdominal pain                                       0.037683\n","intervention_model_type_Factorial Assignment         0.037326\n","Genetic                                              0.034936\n","Nausea                                               0.028028\n","dropout_reason_adverse event                         0.025854\n","Dissociation                                         0.024618\n","Overdose                                             0.022068\n","dropout_reason_subject withdrawal                    0.017419\n","Glossitis                                            0.017076\n","Major depression                                     0.013135\n","masking_type_Quadruple                               0.012135\n","Lethargy                                             0.011323\n","Tremor                                               0.010559\n","intervention_model_type_Single Group Assignment      0.010132\n","dropout_reason_lack of efficacy                      0.009232"],"text/html":["\n","  <div id=\"df-94066c3e-bb63-41de-87b5-f6560594c6e0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>importance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <td>0.318439</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <td>0.058545</td>\n","    </tr>\n","    <tr>\n","      <th>event_type_other</th>\n","      <td>0.045327</td>\n","    </tr>\n","    <tr>\n","      <th>Headache</th>\n","      <td>0.040401</td>\n","    </tr>\n","    <tr>\n","      <th>study_duration_months</th>\n","      <td>0.038388</td>\n","    </tr>\n","    <tr>\n","      <th>Abdominal pain</th>\n","      <td>0.037683</td>\n","    </tr>\n","    <tr>\n","      <th>intervention_model_type_Factorial Assignment</th>\n","      <td>0.037326</td>\n","    </tr>\n","    <tr>\n","      <th>Genetic</th>\n","      <td>0.034936</td>\n","    </tr>\n","    <tr>\n","      <th>Nausea</th>\n","      <td>0.028028</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_adverse event</th>\n","      <td>0.025854</td>\n","    </tr>\n","    <tr>\n","      <th>Dissociation</th>\n","      <td>0.024618</td>\n","    </tr>\n","    <tr>\n","      <th>Overdose</th>\n","      <td>0.022068</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <td>0.017419</td>\n","    </tr>\n","    <tr>\n","      <th>Glossitis</th>\n","      <td>0.017076</td>\n","    </tr>\n","    <tr>\n","      <th>Major depression</th>\n","      <td>0.013135</td>\n","    </tr>\n","    <tr>\n","      <th>masking_type_Quadruple</th>\n","      <td>0.012135</td>\n","    </tr>\n","    <tr>\n","      <th>Lethargy</th>\n","      <td>0.011323</td>\n","    </tr>\n","    <tr>\n","      <th>Tremor</th>\n","      <td>0.010559</td>\n","    </tr>\n","    <tr>\n","      <th>intervention_model_type_Single Group Assignment</th>\n","      <td>0.010132</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <td>0.009232</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94066c3e-bb63-41de-87b5-f6560594c6e0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-94066c3e-bb63-41de-87b5-f6560594c6e0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-94066c3e-bb63-41de-87b5-f6560594c6e0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":29}],"source":["feature_imp = pd.DataFrame(reg_model.feature_importances_,\n","                                   index = X_train.columns,\n","                                   columns=['importance']).sort_values('importance', ascending=False)\n","\n","feature_imp.head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sj_Ga8bj0g-w"},"outputs":[],"source":["#create list of top 30 features\n","boost_top_10 = feature_imp.head(10).index.values\n","boost_top_10_list = list(boost_top_10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JPB9B6RA0g-w"},"outputs":[],"source":["X_boost_df = X_df[X_df.columns.intersection(boost_top_10_list)]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1659890131482,"user_tz":240,"elapsed":3,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9298c539-76d9-4551-f6a0-512d56403e0f","id":"2m64H2AG0g-w"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((271, 10), (68, 10))"]},"metadata":{},"execution_count":32}],"source":["# Train/test split:\n","X_boost_train, X_boost_test, y_train, y_test = train_test_split(X_boost_df, y_df, test_size = 0.2, random_state = 2)\n","\n","X_boost_train.shape, X_boost_test.shape"]},{"cell_type":"markdown","source":["##### Model Set-up"],"metadata":{"id":"5zFd-gYk0g-w"}},{"cell_type":"code","source":["# Continous outcome prediction:\n","\n","def train_and_test(reg_model, X_train, y_train, X_test, y_test):\n","  reg_model.fit(X_train, y_train)\n","  # Make predictions with model\n","  y_pred = reg_model.predict(X_test)\n","  #Metrics\n","  mse_score_val = mean_squared_error(y_test, y_pred)\n","  r2_score_val = r2_score(y_test, y_pred)\n","  return {\"MSE_Score\": mse_score_val, \"R2_Score\": r2_score_val}"],"metadata":{"id":"U9Ec0iEQ0g-x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Linear Regression"],"metadata":{"id":"lfKwsNpc0g-x"}},{"cell_type":"code","source":["# Linear Regression:\n","\n","lr_model = LinearRegression()\n","\n","scores = cross_val_score(lr_model, X_boost_train, y_train, scoring='r2', cv=5)\n","scores   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893244224,"user_tz":240,"elapsed":149,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"7e15afcf-dc7e-4be4-9ead-b02e6c00e426","id":"D8sEtnI90g-x"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.52372859,  0.22300902,  0.40490087,  0.28289511,  0.22152235])"]},"metadata":{},"execution_count":104}]},{"cell_type":"code","source":["# k-fold CV (using all the boost variables)\n","train_and_test(lr_model, X_boost_train, y_train, X_boost_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893245438,"user_tz":240,"elapsed":2,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"1580e64d-dfae-49fb-ad3d-97cc49d9cbbc","id":"mByizz6C0g-x"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'MSE_Score': 320.12078109174996, 'R2_Score': 0.27008943892479653}"]},"metadata":{},"execution_count":105}]},{"cell_type":"markdown","source":["Random Forest"],"metadata":{"id":"j7e6-I200g-x"}},{"cell_type":"code","source":["# Random Forest Regression:\n","\n","rfr_model = RandomForestRegressor()\n","\n","scores = cross_val_score(rfr_model, X_boost_train, y_train, scoring='r2', cv=5)\n","scores   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893012236,"user_tz":240,"elapsed":2255,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"3379fa3e-f132-4e1a-dfba-ae15c9339c25","id":"P8AoXkZr0g-x"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.21087431, 0.4829302 , 0.49542987, 0.26260168, 0.45673906])"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["\n","train_and_test(rfr_model, X_boost_train, y_train, X_boost_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893013554,"user_tz":240,"elapsed":607,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"44be92a3-36fd-42ca-98b1-f2321d638b9f","id":"gDkn08-w0g-x"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'MSE_Score': 239.01657569297282, 'R2_Score': 0.455015940310575}"]},"metadata":{},"execution_count":97}]},{"cell_type":"markdown","source":["Gradient Boosting"],"metadata":{"id":"ndjfrP4i0g-x"}},{"cell_type":"code","source":["# Gradient Boost for feature importance:\n","\n","boost_model = GradientBoostingRegressor(random_state=0)   \n","\n","scores = cross_val_score(boost_model, X_boost_train, y_train, scoring='r2', cv=5)\n","scores   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893141201,"user_tz":240,"elapsed":860,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"cd9eebc5-824a-4f51-d233-07aaff560c52","id":"qtK-IyCJ0g-x"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.11861583, 0.52141256, 0.46201785, 0.23063168, 0.37609487])"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":["boost_model.fit(X_boost_train, y_train)\n","y_preds = boost_model.predict(X_boost_test)\n","r2_score(y_test, y_preds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893147475,"user_tz":240,"elapsed":316,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"f4bcf021-b3e3-4597-a9f4-494dc6deff67","id":"0Cw50K4R0g-x"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4156543656927092"]},"metadata":{},"execution_count":100}]},{"cell_type":"code","source":["#chose five models to train the data with to see which performs the best : Linear Regression and Support Vector Regression\n","pipe_lr = Pipeline([('LR', LinearRegression())])\n","pipe_svm = Pipeline([('SVM', SVR())])\n","pipe_rfr = Pipeline([('RFR', RandomForestRegressor())])\n","pipe_dtr = Pipeline([('DTR', DecisionTreeRegressor())])\n","pipe_gbr = Pipeline([('DTR', GradientBoostingRegressor())])\n","\n","#create GridSearch parameters\n","\n","#creates lists to pass into the grid below\n","C = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n","epsilon = [0, 0.01, 0.1, 0.5, 1, 2, 4, 5]\n","n_estimators = [50,100,150, 200, 300, 500,1000, 1500]\n","n_jobs = np.array([1, 10, 100, 290, 500])\n","bootstrap = [True, False]\n","max_depth = [3,4,6,8,10]\n","min_samples_split = [10,20,40]\n","max_depth = [2, 6, 8]\n","min_samples_leaf = [20, 40, 100]\n","max_leaf_nodes = [5, 20, 100]\n","learning_rate = [0.01,0.02,0.03,0.04]\n","subsample = [0.9, 0.5, 0.2, 0.1]\n","\n","#these will be passed to the GridSearchCV function below -> which will take a pipeline model and test out each paramter value passed through in the following parameter list\n","lr_space = [{'fit_intercept':[True, False]}]\n","\n","svr_space = [{'kernel': ['linear'], 'C' : C, 'epsilon' : epsilon},\n","         {'kernel': ['rbf'], 'C' : C, 'gamma' : C, 'epsilon' : epsilon}]\n","\n","rfr_space = [{'max_features' : [\"auto\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"sqrt\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"log2\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","dtr_space = [{'criterion': ['squared_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes},\n","            {'criterion': ['absolute_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes}]\n","\n","gbr_space = [{'learning_rate': learning_rate, 'subsample' : subsample, 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","\n","\n","##use the GridSearchCV function and pass in both the pipeline created above and the grid parameters \n","\n","#pass in cv=5 for the gridsearch to perform cross-validation on our training set\n","#pass score = accuracy for get the accrucay score when the test is performed \n","lr_gs = GridSearchCV(LinearRegression(), param_grid = lr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","svm_gs = GridSearchCV(SVR(), param_grid = svr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","rfr_gs = GridSearchCV(RandomForestRegressor(), param_grid = rfr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","dtr_gs = GridSearchCV(DecisionTreeRegressor(), param_grid = dtr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","gbr_gs = GridSearchCV(GradientBoostingRegressor(), param_grid = gbr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","\n","lr_grids = [lr_gs]\n","\n","for lr_pipe in lr_grids:\n","    lr_pipe.fit(X_boost_train,y_train)\n","\n","svm_grids = [svm_gs]\n","\n","for svm_pipe in svm_grids:\n","    svm_pipe.fit(X_boost_train,y_train)\n","\n","rfr_grids = [rfr_gs]\n","\n","for rfr_pipe in rfr_grids:\n","    rfr_pipe.fit(X_boost_train,y_train)\n","\n","dtr_grids = [dtr_gs]\n","\n","for dtr_pipe in dtr_grids:\n","    dtr_pipe.fit(X_boost_train,y_train)\n","\n","gbr_grids = [gbr_gs]\n","\n","for gbr_pipe in gbr_grids:\n","    gbr_pipe.fit(X_boost_train,y_train)"],"metadata":{"id":"8ZaASH3U0g-x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#first create a dictionary that contains the classifier types to used int eh for loop. \n","lr_grid_dict = {0: 'Linear Regression'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(lr_grids):\n","    print('{} Train R_Square: {}'.format(lr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","lr_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,lr_y_pred)*100\n","\n","for i, model in enumerate(lr_grids):\n","    print('{} Test R_Square: {}'.format(lr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","svm_grid_dict = {0: 'Support Vector Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(svm_grids):\n","    print('{} Train R_Square: {}'.format(svm_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","svm_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,svm_y_pred)*100\n","\n","for i, model in enumerate(svm_grids):\n","    print('{} Test R_Square: {}'.format(svm_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          results.best_params_))\n","    \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","rfr_grid_dict = {0: 'Random Forest Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(rfr_grids):\n","    print('{} Train R_Square: {}'.format(rfr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","rf_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,rf_y_pred)*100\n","\n","for i, model in enumerate(rfr_grids):\n","    print('{} Test R_Square: {}'.format(rfr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","dtr_grid_dict = {0: 'Decision Tree Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(dtr_grids):\n","    print('{} Train R_Square: {}'.format(dtr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","dtr_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,dtr_y_pred)*100\n","\n","for i, model in enumerate(dtr_grids):\n","    print('{} Test R_Square: {}'.format(dtr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","gbr_grid_dict = {0: 'Gradient Boosting Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(gbr_grids):\n","    print('{} Train R_Square: {}'.format(gbr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","gbr_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,gbr_y_pred)*100\n","\n","for i, model in enumerate(gbr_grids):\n","    print('{} Test R_Square: {}'.format(gbr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          results.best_params_))"],"metadata":{"id":"kM1c69wf0g-y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yTtpoGeo0g-y"},"source":["#### Mutual Information Feature Selection "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659724797561,"user_tz":240,"elapsed":2931,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"7f430427-d146-4f57-c8f0-ac55c5f102fa","id":"sTDCPxAO0g-y"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1.93329965e-01 2.79787357e-02 0.00000000e+00 2.85353136e-01\n"," 1.12896336e-01 2.04555356e-01 6.47709408e-02 1.89068091e-02\n"," 2.36317673e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.14886389e-02 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 9.31302684e-04 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 2.32252200e-03 1.40305033e-01\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.39487101e-02\n"," 7.96625655e-03 0.00000000e+00 9.11215201e-02 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 2.24477243e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 5.80357087e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.13094503e-01 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.45845098e-03 7.19362761e-03\n"," 0.00000000e+00 0.00000000e+00 2.40973048e-03 7.97151068e-03\n"," 1.65255318e-02 2.68652715e-02 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 4.78600247e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 9.50697768e-04 2.04791150e-03 0.00000000e+00 0.00000000e+00\n"," 1.41220624e-03 0.00000000e+00 5.01277239e-03 0.00000000e+00\n"," 0.00000000e+00 7.38843507e-03 0.00000000e+00 0.00000000e+00\n"," 1.29290297e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 6.44048285e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 5.02576173e-03 0.00000000e+00 0.00000000e+00 1.99348901e-03\n"," 7.05102041e-03 8.03350383e-03 9.70502791e-04 1.17793054e-03\n"," 5.30411535e-03 0.00000000e+00 5.33382372e-03 3.65177267e-04\n"," 8.64074784e-03 0.00000000e+00 1.19599897e-02 0.00000000e+00\n"," 2.84805174e-03 1.38729789e-03 0.00000000e+00 1.02384043e-02\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 1.09570251e-02 1.19276081e-02 0.00000000e+00 2.53345761e-04\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.42389858e-02\n"," 0.00000000e+00 1.85970340e-02 1.75240411e-03 3.44523841e-03\n"," 9.75414247e-03 2.92779979e-03 0.00000000e+00 0.00000000e+00\n"," 1.77997772e-03 0.00000000e+00 8.69478688e-04 2.96583868e-03\n"," 0.00000000e+00 8.08535841e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 1.97063305e-02 3.67974827e-05 1.96065812e-05\n"," 0.00000000e+00 0.00000000e+00 3.69781965e-04 0.00000000e+00\n"," 0.00000000e+00 1.26305402e-03 0.00000000e+00 0.00000000e+00\n"," 4.49748302e-03 8.72724855e-03 4.24913952e-03 4.28808130e-03\n"," 0.00000000e+00 0.00000000e+00 1.04173726e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 2.68405974e-03 9.93819846e-04\n"," 0.00000000e+00 2.74253287e-02 5.91776086e-03 0.00000000e+00\n"," 3.12987092e-03 0.00000000e+00 0.00000000e+00 1.84500421e-02\n"," 0.00000000e+00 7.46316487e-04 0.00000000e+00 2.83490536e-03\n"," 6.22400733e-03 9.66883491e-03 1.97294403e-02 0.00000000e+00\n"," 4.05093784e-03 0.00000000e+00 4.27624185e-05 9.47262668e-06\n"," 0.00000000e+00 2.39920972e-03 0.00000000e+00 0.00000000e+00\n"," 2.83998190e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 6.63027663e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 2.69679475e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 3.30421947e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 9.72412049e-04\n"," 0.00000000e+00 0.00000000e+00 1.51862016e-03 1.57903235e-02\n"," 0.00000000e+00 0.00000000e+00 5.30980431e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 6.48832115e-04 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.46576918e-04\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.60120945e-02\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.08799955e-02 5.67464207e-03\n"," 0.00000000e+00 0.00000000e+00 2.99233670e-03 3.60552397e-03\n"," 2.10738798e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 1.36375133e-02 0.00000000e+00 0.00000000e+00\n"," 1.38784031e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 2.36206964e-03 0.00000000e+00 0.00000000e+00\n"," 4.14751754e-04 4.63904996e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 3.81096621e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 1.43343054e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 9.67265880e-04 4.12500329e-04\n"," 1.32235983e-02 7.88329410e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 3.73740846e-04 0.00000000e+00 5.22484888e-03\n"," 6.29731809e-02 0.00000000e+00 6.21929279e-02 1.49949132e-01\n"," 8.69707919e-03 1.86974960e-02 3.31688153e-03 6.98487316e-02\n"," 5.58862446e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 1.70697662e-01 1.35633449e-01 0.00000000e+00\n"," 0.00000000e+00 8.44687426e-03 0.00000000e+00 3.92890583e-04\n"," 3.05852092e-02 0.00000000e+00 1.77488514e-02 3.18491126e-02\n"," 4.92078625e-02 5.25771761e-02 3.57412169e-02 0.00000000e+00\n"," 0.00000000e+00 6.05903110e-02 2.00073829e-02 2.41637927e-02\n"," 2.98299349e-02 6.85765039e-04 0.00000000e+00 3.66658126e-02\n"," 8.50858185e-02 8.20275432e-03 0.00000000e+00 1.04039135e-02\n"," 2.37977376e-02 7.00182719e-03]\n"]}],"source":["from sklearn.feature_selection import mutual_info_regression  \n","from sklearn.feature_selection import SelectKBest\n","selector = SelectKBest(mutual_info_regression, k=10)\n","X_train_new = selector.fit_transform(X_train, y_train)  #Applying transformation to the training set\n","#to get names of the selected features\n","mask = selector.get_support()  \n","\n","print(selector.scores_)   \n","\n","new_features = X_train.columns[mask]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_J-JDdR0g-y"},"outputs":[],"source":["X_MI_df = V4_master_df[new_features]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":375},"executionInfo":{"status":"error","timestamp":1659724798118,"user_tz":240,"elapsed":289,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"b261267e-2132-4ed7-fe08-e4c25bcaeb52","id":"im_t-YuN0g-y"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-82-a1d14a8e7824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train/test split:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_MI_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_MI_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_MI_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_MI_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_MI_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2417\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [800, 339]"]}],"source":["# Train/test split:\n","X_MI_train, X_MI_test, y_train, y_test = train_test_split(X_MI_df, y_df, test_size = 0.2, random_state = 2)\n","\n","X_MI_train.shape, X_MI_test.shape"]},{"cell_type":"code","source":["logreg=LogisticRegression()\n","kf=KFold(n_splits=5)\n","score=cross_val_score(logreg,X_MI_train,y_train,cv=kf)\n","print(\"Cross Validation Scores are {}\".format(score))\n","print(\"Average Cross Validation score :{}\".format(score.mean()))\n","\n","# Train classifiers\n","reg1 = GradientBoostingRegressor(random_state=1)\n","reg2 = RandomForestRegressor(random_state=1)\n","reg3 = LinearRegression()\n","\n","reg1.fit(X_MI_train, y_train)\n","reg2.fit(X_MI_train, y_train)\n","reg3.fit(X_MI_train, y_train)\n","\n","ereg = VotingRegressor([(\"gb\", reg1), (\"rf\", reg2), (\"lr\", reg3)])\n","ereg.fit(X_MI_train, y_train)\n","\n","#predict \n","pred1 = reg1.predict(X_boost_test)\n","pred2 = reg2.predict(X_boost_test)\n","pred3 = reg3.predict(X_boost_test)\n","pred4 = ereg.predict(X_boost_test)\n","\n","#plot\n","plt.figure()\n","plt.plot(pred1, \"gd\", label=\"GradientBoostingRegressor\")\n","plt.plot(pred2, \"b^\", label=\"RandomForestRegressor\")\n","plt.plot(pred3, \"ys\", label=\"LinearRegression\")\n","plt.plot(pred4, \"r*\", ms=10, label=\"VotingRegressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"training samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions and their average - Depression\")\n","plt.setp(plt.gca(),ylim=(0,100))\n","\n","plt.show()"],"metadata":{"id":"mRBcANsG0g-y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#chose five models to train the data with to see which performs the best : Linear Regression and Support Vector Regression\n","pipe_lr = Pipeline([('LR', LinearRegression())])\n","pipe_svm = Pipeline([('SVM', SVR())])\n","pipe_rfr = Pipeline([('RFR', RandomForestRegressor())])\n","pipe_dtr = Pipeline([('DTR', DecisionTreeRegressor())])\n","pipe_gbr = Pipeline([('DTR', GradientBoostingRegressor())])\n","\n","#create GridSearch parameters\n","\n","#creates lists to pass into the grid below\n","C = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n","epsilon = [0, 0.01, 0.1, 0.5, 1, 2, 4, 5]\n","n_estimators = [50,100,150, 200, 300, 500,1000, 1500]\n","n_jobs = np.array([1, 10, 100, 290, 500])\n","bootstrap = [True, False]\n","max_depth = [3,4,6,8,10]\n","min_samples_split = [10,20,40]\n","max_depth = [2, 6, 8]\n","min_samples_leaf = [20, 40, 100]\n","max_leaf_nodes = [5, 20, 100]\n","learning_rate = [0.01,0.02,0.03,0.04]\n","subsample = [0.9, 0.5, 0.2, 0.1]\n","\n","#these will be passed to the GridSearchCV function below -> which will take a pipeline model and test out each paramter value passed through in the following parameter list\n","lr_space = [{'fit_intercept': ['svd'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['cholesky'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['lsqr'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sparse_cg'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sag'],  'n_jobs' : n_jobs},\n","         {'fit_intercept': ['saga'], 'n_jobs' : n_jobs}]\n","\n","svr_space = [{'kernel': ['linear'], 'C' : C, 'epsilon' : epsilon},\n","         {'kernel': ['rbf'], 'C' : C, 'gamma' : C, 'epsilon' : epsilon}]\n","\n","rfr_space = [{'max_features' : [\"auto\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"sqrt\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"log2\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","dtr_space = [{'criterion': ['mse'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes},\n","         {'criterion': ['absolute_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes}]\n","\n","gbr_space = [{'learning_rate': learning_rate, 'subsample' : subsample, 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","\n","\n","##use the GridSearchCV function and pass in both the pipeline created above and the frid parameters \n","\n","#pass in cv=3 for the fridsearch to perform cross-validation on our training set\n","#pass score = accuracy for get the accrucay score when the test is performed \n","lr_gs = GridSearchCV(LinearRegression(), param_grid = lr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","svm_gs = GridSearchCV(SVR(), param_grid = svr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","rfr_gs = GridSearchCV(RandomForestRegressor(), param_grid = rfr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","dtr_gs = GridSearchCV(DecisionTreeRegressor(), param_grid = dtr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","gbr_gs = GridSearchCV(GradientBoostingRegressor(), param_grid = gbr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","\n","lr_grids = [lr_gs]\n","\n","for lr_pipe in lr_grids:\n","    lr_pipe.fit(X_MI_train,y_train)\n","\n","svm_grids = [svm_gs]\n","\n","for svm_pipe in svm_grids:\n","    svm_pipe.fit(X_MI_train,y_train)\n","\n","rfr_grids = [rfr_gs]\n","\n","for rfr_pipe in rfr_grids:\n","    rfr_pipe.fit(X_MI_train,y_train)\n","\n","dtr_grids = [dtr_gs]\n","\n","for dtr_pipe in dtr_grids:\n","    dtr_pipe.fit(X_MI_train,y_train)\n","\n","gbr_grids = [gbr_gs]\n","\n","for gbr_pipe in gbr_grids:\n","    gbr_pipe.fit(X_MI_train,y_train)"],"metadata":{"id":"vu0jUBUz0g-y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#first create a dictionary that contains the classifier types to used int eh for loop. \n","lr_grid_dict = {0: 'Linear Regression'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(lr_grids):\n","    print('{} Train R_Square: {}'.format(lr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(lr_grids):\n","    print('{} Test R_Square: {}'.format(lr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","svm_grid_dict = {0: 'Support Vector Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(svm_grids):\n","    print('{} Train R_Square: {}'.format(svm_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(svm_grids):\n","    print('{} Test R_Square: {}'.format(svm_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","rfr_grid_dict = {0: 'Random Forest Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(rfr_grids):\n","    print('{} Train R_Square: {}'.format(rfr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(rfr_grids):\n","    print('{} Test R_Square: {}'.format(rfr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","dtr_grid_dict = {0: 'Decision Tree Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(dtr_grids):\n","    print('{} Train R_Square: {}'.format(dtr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(dtr_grids):\n","    print('{} Test R_Square: {}'.format(dtr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","gbr_grid_dict = {0: 'Gradient Boosting Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(gbr_grids):\n","    print('{} Train R_Square: {}'.format(gbr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(gbr_grids):\n","    print('{} Test R_Square: {}'.format(gbr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))"],"metadata":{"id":"bI_x23Qs0g-y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m9C6-bn10g-z"},"source":["#### Knowledge Feature Selection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z2202Ged0g-z"},"outputs":[],"source":["df_list = list(X_df[['number_of_arms', 'has_dmc', 'number_of_facilities', 'study_duration_months', 'event_type_deaths', 'event_type_other', 'event_type_serious']])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5fs4GBL20g-z"},"outputs":[],"source":["dropout_list = list(X_df[['dropout_reason_adverse event', 'dropout_reason_inclusion/exclusion criteria issue', 'dropout_reason_lost to follow-up']])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659724854258,"user_tz":240,"elapsed":139,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"6e474a56-8e67-44c6-ba63-94dc82d8b857","id":"wwoJvnJf0g-z"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Headache',\n"," 'Nausea',\n"," 'Fatigue',\n"," 'Vomiting',\n"," 'Decreased appetite',\n"," 'Diarrhoea',\n"," 'Sedation',\n"," 'Rash',\n"," 'Increased appetite',\n"," 'Palpitations']"]},"metadata":{},"execution_count":85}],"source":["top_ae_table_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wdkkrXpy0g-z"},"outputs":[],"source":["X_knowledge_df = X_df[X_df.columns.intersection(top_ae_table_list+dropout_list+df_list)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"80RsguRW0g-z"},"outputs":[],"source":["X_knowledge_norm = (X_knowledge_df-X_knowledge_df.min())/(X_knowledge_df.max()-X_knowledge_df.min())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659724857924,"user_tz":240,"elapsed":117,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"1f81e75a-1e24-4ea5-fc14-1c0e06343aca","id":"5HdIyyj_0g-z"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((271, 20), (68, 20))"]},"metadata":{},"execution_count":88}],"source":["# Train/test split:\n","X_knowledge_train, X_knowledge_test, y_train, y_test = train_test_split(X_knowledge_norm, y_df, test_size = 0.2, random_state = 2)\n","\n","X_knowledge_train.shape, X_knowledge_test.shape"]},{"cell_type":"code","source":["logreg=LogisticRegression()\n","kf=KFold(n_splits=5)\n","score=cross_val_score(logreg,X_knowledge_train,y_train,cv=kf)\n","print(\"Cross Validation Scores are {}\".format(score))\n","print(\"Average Cross Validation score :{}\".format(score.mean()))\n","\n","# Train classifiers\n","reg1 = GradientBoostingRegressor(random_state=1)\n","reg2 = RandomForestRegressor(random_state=1)\n","reg3 = LinearRegression()\n","\n","reg1.fit(X_knowledge_train, y_train)\n","reg2.fit(X_knowledge_train, y_train)\n","reg3.fit(X_knowledge_train, y_train)\n","\n","ereg = VotingRegressor([(\"gb\", reg1), (\"rf\", reg2), (\"lr\", reg3)])\n","ereg.fit(X_knowledge_train, y_train)\n","\n","#predict \n","pred1 = reg1.predict(X_knowledge_test)\n","pred2 = reg2.predict(X_knowledge_test)\n","pred3 = reg3.predict(X_knowledge_test)\n","pred4 = ereg.predict(X_knowledge_test)\n","\n","#plot\n","plt.figure()\n","plt.plot(pred1, \"gd\", label=\"GradientBoostingRegressor\")\n","plt.plot(pred2, \"b^\", label=\"RandomForestRegressor\")\n","plt.plot(pred3, \"ys\", label=\"LinearRegression\")\n","plt.plot(pred4, \"r*\", ms=10, label=\"VotingRegressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"training samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions and their average - Depression\")\n","plt.setp(plt.gca(),ylim=(0,100))\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":640},"executionInfo":{"status":"ok","timestamp":1659724939828,"user_tz":240,"elapsed":2577,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"4fa6ee0a-25ae-442b-80ff-50a084b78f97","id":"tgKawcDF0g-z"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","5 fits failed out of a total of 5.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","5 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1516, in fit\n","    check_classification_targets(y)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 197, in check_classification_targets\n","    raise ValueError(\"Unknown label type: %r\" % y_type)\n","ValueError: Unknown label type: 'continuous'\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Cross Validation Scores are [nan nan nan nan nan]\n","Average Cross Validation score :nan\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["#chose five models to train the data with to see which performs the best : Linear Regression and Support Vector Regression\n","pipe_lr = Pipeline([('LR', LinearRegression())])\n","pipe_svm = Pipeline([('SVM', SVR())])\n","pipe_rfr = Pipeline([('RFR', RandomForestRegressor())])\n","pipe_dtr = Pipeline([('DTR', DecisionTreeRegressor())])\n","pipe_gbr = Pipeline([('DTR', GradientBoostingRegressor())])\n","\n","#create GridSearch parameters\n","\n","#creates lists to pass into the grid below\n","C = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n","epsilon = [0, 0.01, 0.1, 0.5, 1, 2, 4, 5]\n","n_estimators = [50,100,150, 200, 300, 500,1000, 1500]\n","n_jobs = np.array([1, 10, 100, 290, 500])\n","bootstrap = [True, False]\n","max_depth = [3,4,6,8,10]\n","min_samples_split = [10,20,40]\n","max_depth = [2, 6, 8]\n","min_samples_leaf = [20, 40, 100]\n","max_leaf_nodes = [5, 20, 100]\n","learning_rate = [0.01,0.02,0.03,0.04]\n","subsample = [0.9, 0.5, 0.2, 0.1]\n","\n","#these will be passed to the GridSearchCV function below -> which will take a pipeline model and test out each paramter value passed through in the following parameter list\n","lr_space = [{'fit_intercept': ['svd'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['cholesky'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['lsqr'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sparse_cg'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sag'],  'n_jobs' : n_jobs},\n","         {'fit_intercept': ['saga'], 'n_jobs' : n_jobs}]\n","\n","svr_space = [{'kernel': ['linear'], 'C' : C, 'epsilon' : epsilon},\n","         {'kernel': ['rbf'], 'C' : C, 'gamma' : C, 'epsilon' : epsilon}]\n","\n","rfr_space = [{'max_features' : [\"auto\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"sqrt\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"log2\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","dtr_space = [{'criterion': ['mse'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes},\n","         {'criterion': ['absolute_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes}]\n","\n","gbr_space = [{'learning_rate': learning_rate, 'subsample' : subsample, 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","\n","\n","##use the GridSearchCV function and pass in both the pipeline created above and the frid parameters \n","\n","#pass in cv=3 for the fridsearch to perform cross-validation on our training set\n","#pass score = accuracy for get the accrucay score when the test is performed \n","lr_gs = GridSearchCV(LinearRegression(), param_grid = lr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","svm_gs = GridSearchCV(SVR(), param_grid = svr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","rfr_gs = GridSearchCV(RandomForestRegressor(), param_grid = rfr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","dtr_gs = GridSearchCV(DecisionTreeRegressor(), param_grid = dtr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","gbr_gs = GridSearchCV(GradientBoostingRegressor(), param_grid = gbr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","\n","lr_grids = [lr_gs]\n","\n","for lr_pipe in lr_grids:\n","    lr_pipe.fit(X_knowledge_train,y_train)\n","\n","svm_grids = [svm_gs]\n","\n","for svm_pipe in svm_grids:\n","    svm_pipe.fit(X_knowledge_train,y_train)\n","\n","rfr_grids = [rfr_gs]\n","\n","for rfr_pipe in rfr_grids:\n","    rfr_pipe.fit(X_knowledge_train,y_train)\n","\n","dtr_grids = [dtr_gs]\n","\n","for dtr_pipe in dtr_grids:\n","    dtr_pipe.fit(X_knowledge_train,y_train)\n","\n","gbr_grids = [gbr_gs]\n","\n","for gbr_pipe in gbr_grids:\n","    gbr_pipe.fit(X_knowledge_train,y_train)"],"metadata":{"id":"xLFTbC-a0g-z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#first create a dictionary that contains the classifier types to used int eh for loop. \n","lr_grid_dict = {0: 'Linear Regression'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(lr_grids):\n","    print('{} Train R_Square: {}'.format(lr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","lr_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,lr_y_pred)*100\n","\n","for i, model in enumerate(lr_grids):\n","    print('{} Test R_Square: {}'.format(lr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","svm_grid_dict = {0: 'Support Vector Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(svm_grids):\n","    print('{} Train R_Square: {}'.format(svm_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","svm_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,svm_y_pred)*100\n","\n","for i, model in enumerate(svm_grids):\n","    print('{} Test R_Square: {}'.format(svm_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          results.best_params_))\n","    \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","rfr_grid_dict = {0: 'Random Forest Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(rfr_grids):\n","    print('{} Train R_Square: {}'.format(rfr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","rf_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,rf_y_pred)*100\n","\n","for i, model in enumerate(rfr_grids):\n","    print('{} Test R_Square: {}'.format(rfr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","dtr_grid_dict = {0: 'Decision Tree Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(dtr_grids):\n","    print('{} Train R_Square: {}'.format(dtr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","dtr_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,dtr_y_pred)*100\n","\n","for i, model in enumerate(dtr_grids):\n","    print('{} Test R_Square: {}'.format(dtr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","gbr_grid_dict = {0: 'Gradient Boosting Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(gbr_grids):\n","    print('{} Train R_Square: {}'.format(gbr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","gbr_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,gbr_y_pred)*100\n","\n","for i, model in enumerate(gbr_grids):\n","    print('{} Test R_Square: {}'.format(gbr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          results.best_params_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":592},"executionInfo":{"status":"error","timestamp":1659726446747,"user_tz":240,"elapsed":329,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"ce5abbb0-34da-4c3e-c4d7-0a55fe99180e","id":"icYd8veE0g-z"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n","Feature names unseen at fit time:\n","- Abdominal distension\n","- Abdominal hernia\n","- Abdominal pain\n","- Abortion spontaneous\n","- Accepts_Healthy_volunteers\n","- ...\n","Feature names must be in the same order as they were in fit.\n","\n","  warnings.warn(message, FutureWarning)\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-93-d716c58a4f93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#then create a for loop to train them all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_grids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Train R_Square: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_grid_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Best Params: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_grid_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;31m# callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimetric_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         )\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \"\"\"\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod_caller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return self._sign * self._score_func(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;34m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \"\"\"\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise ValueError(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: X has 334 features, but LinearRegression is expecting 20 features as input."]}]},{"cell_type":"code","source":["#plot predictions \n","plt.figure()\n","plt.plot(lr_y_pred, \"gd\", label=\"Linear Regression\")\n","plt.plot(svm_y_pred, \"b^\", label=\"Support Vector Regressor\")\n","plt.plot(rf_y_pred, \"ys\", label=\"Random Forest Regressor\")\n","plt.plot(dtr_y_pred, \"r*\", ms=10, label=\"Decision Tree Regressor\")\n","plt.plot(gbr_y_pred, \"bs\", label=\"Gradient Boosting Regressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"Training Samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions - Knowledge Based Feature Selection - Depression\")\n","plt.setp(plt.gca(),ylim=(0,100))"],"metadata":{"id":"__0hVpx60g-0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vHGqh7C_FSgB"},"source":["## Bipolar"]},{"cell_type":"markdown","metadata":{"id":"tPooryCm3xzP"},"source":["### Subset Bipolar Studies / Split into test and train sets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C29cZn_L3xzP"},"outputs":[],"source":["V4_bipolar_df = V4_master_df[V4_master_df['disease_type'] == \"Bipolar\"]\n","V4_bipolar_df = V4_bipolar_df.drop(columns=['disease_type', 'intervention_model_type_Sequential Assignment'])\n","\n","#split into features and outcome dataframes\n","X_df = V4_bipolar_df.drop(columns=['percent_attrition'])\n","y_df = V4_bipolar_df.percent_attrition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8_nGApxQ3xzP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896614332,"user_tz":240,"elapsed":2,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"623171b1-5033-4dca-be93-3b6fec897b13"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((29, 2010), (8, 2010))"]},"metadata":{},"execution_count":172}],"source":["# Train/test split:\n","X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size = 0.2, random_state = 2)\n","\n","X_train.shape, X_test.shape"]},{"cell_type":"code","source":["#select all ae columns\n","ae_df = X_df.iloc[:,9:1962]\n","\n","#replace all non zero cells with 1\n","ae_df[ae_df != 0] = 1\n","\n","#add all columns and select the top ten most prevelant\n","s = ae_df.sum()\n","top_ae_table = ae_df[s.sort_values(ascending=False).index[:10]]\n","\n","#generated list of most prevelant ae\n","top_ae_table_list = list(top_ae_table.columns)"],"metadata":{"id":"h6NQpuynofbE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4rU_f4ymcGk_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896614638,"user_tz":240,"elapsed":307,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"9feb7222-3fd0-4a94-bd37-c46c5bf58b0b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  dropout_reason_consent withdrawn  \\\n","37                            1.0                               0.0   \n","39                            1.0                               0.0   \n","54                            6.0                               0.0   \n","56                           12.0                               0.0   \n","65                            0.0                               0.0   \n","67                            0.0                               0.0   \n","99                            0.0                               0.0   \n","101                           0.0                               0.0   \n","170                           0.0                               0.0   \n","172                           0.0                               0.0   \n","276                           0.0                               0.0   \n","278                           0.0                               0.0   \n","352                          21.0                              19.0   \n","354                          21.0                              19.0   \n","356                          20.0                              17.0   \n","358                          20.0                              17.0   \n","361                           1.0                               0.0   \n","363                           1.0                               0.0   \n","409                           4.0                               0.0   \n","411                           8.0                               0.0   \n","412                          78.0                               0.0   \n","413                           6.0                               0.0   \n","414                          36.0                               0.0   \n","415                           0.0                               0.0   \n","416                           0.0                               0.0   \n","417                           7.0                               0.0   \n","418                           0.0                               0.0   \n","419                           0.0                               0.0   \n","420                           2.0                               0.0   \n","421                           1.0                               0.0   \n","422                          12.0                               0.0   \n","423                          10.0                               0.0   \n","424                          26.0                               0.0   \n","425                           0.0                               0.0   \n","426                           0.0                               0.0   \n","427                           0.0                               0.0   \n","428                           8.0                               0.0   \n","\n","     dropout_reason_inclusion/exclusion criteria issue  \\\n","37                                                 0.0   \n","39                                                 0.0   \n","54                                                 0.0   \n","56                                                 0.0   \n","65                                                 8.0   \n","67                                                 8.0   \n","99                                                 0.0   \n","101                                                0.0   \n","170                                                6.0   \n","172                                                6.0   \n","276                                                0.0   \n","278                                                0.0   \n","352                                                9.0   \n","354                                                9.0   \n","356                                               24.0   \n","358                                               24.0   \n","361                                                6.0   \n","363                                                6.0   \n","409                                                8.0   \n","411                                                5.0   \n","412                                               39.0   \n","413                                                2.0   \n","414                                               26.0   \n","415                                                1.0   \n","416                                                0.0   \n","417                                                0.0   \n","418                                                0.0   \n","419                                                0.0   \n","420                                                2.0   \n","421                                                2.0   \n","422                                                3.0   \n","423                                                4.0   \n","424                                               25.0   \n","425                                                2.0   \n","426                                                0.0   \n","427                                                0.0   \n","428                                                5.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","37                               0.0                              33.0   \n","39                               0.0                              33.0   \n","54                               2.0                               3.0   \n","56                               4.0                               6.0   \n","65                               0.0                               0.0   \n","67                               0.0                               0.0   \n","99                               0.0                               0.0   \n","101                              0.0                               0.0   \n","170                              0.0                              19.0   \n","172                              0.0                              19.0   \n","276                              0.0                               7.0   \n","278                              0.0                               7.0   \n","352                             10.0                              27.0   \n","354                             10.0                              27.0   \n","356                              5.0                              18.0   \n","358                              5.0                              18.0   \n","361                              0.0                               1.0   \n","363                              0.0                               1.0   \n","409                              6.0                               0.0   \n","411                             10.0                              16.0   \n","412                             32.0                              37.0   \n","413                              6.0                               6.0   \n","414                              8.0                               2.0   \n","415                              0.0                               0.0   \n","416                              0.0                               1.0   \n","417                              3.0                               3.0   \n","418                              0.0                               0.0   \n","419                              0.0                               0.0   \n","420                              3.0                               1.0   \n","421                              1.0                               4.0   \n","422                              3.0                               8.0   \n","423                             10.0                               2.0   \n","424                              1.0                              32.0   \n","425                              0.0                               0.0   \n","426                              0.0                               2.0   \n","427                              0.0                               8.0   \n","428                              0.0                               1.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","37                                 0.0                                0.0   \n","39                                 0.0                                0.0   \n","54                                 0.0                                0.0   \n","56                                 0.0                                0.0   \n","65                                 0.0                                0.0   \n","67                                 0.0                                0.0   \n","99                                 0.0                                0.0   \n","101                                0.0                                0.0   \n","170                                0.0                                1.0   \n","172                                0.0                                1.0   \n","276                                0.0                                0.0   \n","278                                0.0                                0.0   \n","352                                0.0                                8.0   \n","354                                0.0                                8.0   \n","356                                0.0                                1.0   \n","358                                0.0                                1.0   \n","361                                1.0                                0.0   \n","363                                1.0                                0.0   \n","409                                0.0                                2.0   \n","411                                2.0                                0.0   \n","412                                0.0                               33.0   \n","413                                0.0                                3.0   \n","414                                0.0                                0.0   \n","415                                0.0                                0.0   \n","416                                0.0                                0.0   \n","417                                0.0                                0.0   \n","418                                2.0                                0.0   \n","419                                0.0                                0.0   \n","420                                0.0                                0.0   \n","421                                0.0                                0.0   \n","422                                4.0                                0.0   \n","423                                3.0                                0.0   \n","424                               10.0                                3.0   \n","425                                0.0                                0.0   \n","426                                0.0                                0.0   \n","427                                0.0                                0.0   \n","428                                0.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Rash  Pain  ...  \\\n","37                                 9.0   0.0   0.0  ...   \n","39                                 9.0   0.0   0.0  ...   \n","54                                 0.0   0.0   0.0  ...   \n","56                                 0.0   0.0   0.0  ...   \n","65                                 1.0   0.0   0.0  ...   \n","67                                 1.0   0.0   0.0  ...   \n","99                                 6.0   0.0   0.0  ...   \n","101                               12.0   0.0   0.0  ...   \n","170                               11.0   0.0   0.0  ...   \n","172                               11.0   0.0   0.0  ...   \n","276                                0.0   0.0   4.0  ...   \n","278                                0.0   0.0   4.0  ...   \n","352                                0.0   0.0   0.0  ...   \n","354                                0.0   0.0   0.0  ...   \n","356                                0.0   0.0   0.0  ...   \n","358                                0.0   0.0   0.0  ...   \n","361                                2.0  22.0   0.0  ...   \n","363                                2.0  22.0   0.0  ...   \n","409                                2.0   0.0   0.0  ...   \n","411                                6.0   0.0   0.0  ...   \n","412                              105.0   0.0   0.0  ...   \n","413                                9.0   0.0   0.0  ...   \n","414                                0.0   0.0   0.0  ...   \n","415                                1.0   0.0   0.0  ...   \n","416                                0.0   0.0   0.0  ...   \n","417                                0.0   0.0   0.0  ...   \n","418                               11.0   0.0   0.0  ...   \n","419                                4.0   0.0   0.0  ...   \n","420                                4.0   0.0   0.0  ...   \n","421                                3.0   0.0   0.0  ...   \n","422                               40.0   0.0   0.0  ...   \n","423                               35.0   0.0   0.0  ...   \n","424                               79.0   0.0   0.0  ...   \n","425                                2.0   0.0   0.0  ...   \n","426                                0.0   0.0   0.0  ...   \n","427                                4.0   0.0   0.0  ...   \n","428                                6.0   0.0   0.0  ...   \n","\n","     intervention_model_type_Parallel Assignment  \\\n","37                                             1   \n","39                                             1   \n","54                                             1   \n","56                                             1   \n","65                                             1   \n","67                                             1   \n","99                                             1   \n","101                                            1   \n","170                                            1   \n","172                                            1   \n","276                                            1   \n","278                                            1   \n","352                                            1   \n","354                                            1   \n","356                                            1   \n","358                                            1   \n","361                                            0   \n","363                                            0   \n","409                                            1   \n","411                                            1   \n","412                                            0   \n","413                                            1   \n","414                                            1   \n","415                                            0   \n","416                                            0   \n","417                                            1   \n","418                                            1   \n","419                                            0   \n","420                                            0   \n","421                                            0   \n","422                                            1   \n","423                                            1   \n","424                                            1   \n","425                                            0   \n","426                                            0   \n","427                                            0   \n","428                                            0   \n","\n","     intervention_model_type_Single Group Assignment  \\\n","37                                                 0   \n","39                                                 0   \n","54                                                 0   \n","56                                                 0   \n","65                                                 0   \n","67                                                 0   \n","99                                                 0   \n","101                                                0   \n","170                                                0   \n","172                                                0   \n","276                                                0   \n","278                                                0   \n","352                                                0   \n","354                                                0   \n","356                                                0   \n","358                                                0   \n","361                                                1   \n","363                                                1   \n","409                                                0   \n","411                                                0   \n","412                                                1   \n","413                                                0   \n","414                                                0   \n","415                                                1   \n","416                                                0   \n","417                                                0   \n","418                                                0   \n","419                                                1   \n","420                                                1   \n","421                                                0   \n","422                                                0   \n","423                                                0   \n","424                                                0   \n","425                                                0   \n","426                                                1   \n","427                                                1   \n","428                                                1   \n","\n","     allocation_type_Non-Randomized  allocation_type_Not Reported  \\\n","37                                0                             0   \n","39                                0                             0   \n","54                                0                             0   \n","56                                0                             0   \n","65                                0                             0   \n","67                                0                             0   \n","99                                0                             0   \n","101                               0                             0   \n","170                               0                             0   \n","172                               0                             0   \n","276                               0                             0   \n","278                               0                             0   \n","352                               0                             0   \n","354                               0                             0   \n","356                               0                             0   \n","358                               0                             0   \n","361                               0                             1   \n","363                               0                             1   \n","409                               0                             0   \n","411                               0                             0   \n","412                               0                             1   \n","413                               0                             0   \n","414                               0                             0   \n","415                               0                             1   \n","416                               0                             0   \n","417                               0                             0   \n","418                               0                             0   \n","419                               0                             1   \n","420                               0                             1   \n","421                               0                             0   \n","422                               0                             0   \n","423                               0                             0   \n","424                               0                             1   \n","425                               0                             0   \n","426                               0                             1   \n","427                               1                             0   \n","428                               0                             1   \n","\n","     allocation_type_Randomized  masking_type_Double  \\\n","37                            1                    0   \n","39                            1                    0   \n","54                            1                    1   \n","56                            1                    1   \n","65                            1                    0   \n","67                            1                    0   \n","99                            1                    0   \n","101                           1                    0   \n","170                           1                    0   \n","172                           1                    0   \n","276                           1                    1   \n","278                           1                    1   \n","352                           1                    0   \n","354                           1                    0   \n","356                           1                    0   \n","358                           1                    0   \n","361                           0                    0   \n","363                           0                    0   \n","409                           1                    1   \n","411                           1                    0   \n","412                           0                    0   \n","413                           1                    0   \n","414                           1                    0   \n","415                           0                    0   \n","416                           1                    0   \n","417                           1                    0   \n","418                           1                    0   \n","419                           0                    0   \n","420                           0                    0   \n","421                           1                    0   \n","422                           1                    0   \n","423                           1                    0   \n","424                           0                    0   \n","425                           1                    0   \n","426                           0                    0   \n","427                           0                    0   \n","428                           0                    0   \n","\n","     masking_type_None (Open Label)  masking_type_Quadruple  \\\n","37                                0                       1   \n","39                                0                       1   \n","54                                0                       0   \n","56                                0                       0   \n","65                                0                       0   \n","67                                0                       0   \n","99                                0                       0   \n","101                               0                       0   \n","170                               0                       0   \n","172                               0                       0   \n","276                               0                       0   \n","278                               0                       0   \n","352                               0                       1   \n","354                               0                       1   \n","356                               0                       1   \n","358                               0                       1   \n","361                               1                       0   \n","363                               1                       0   \n","409                               0                       0   \n","411                               0                       0   \n","412                               1                       0   \n","413                               0                       1   \n","414                               0                       0   \n","415                               1                       0   \n","416                               1                       0   \n","417                               0                       1   \n","418                               0                       0   \n","419                               1                       0   \n","420                               1                       0   \n","421                               0                       1   \n","422                               0                       1   \n","423                               0                       1   \n","424                               1                       0   \n","425                               0                       1   \n","426                               1                       0   \n","427                               1                       0   \n","428                               1                       0   \n","\n","     masking_type_Triple  study_gender_eligibility_All  \n","37                     0                             1  \n","39                     0                             1  \n","54                     0                             1  \n","56                     0                             1  \n","65                     1                             1  \n","67                     1                             1  \n","99                     1                             1  \n","101                    1                             1  \n","170                    1                             1  \n","172                    1                             1  \n","276                    0                             1  \n","278                    0                             1  \n","352                    0                             1  \n","354                    0                             1  \n","356                    0                             1  \n","358                    0                             1  \n","361                    0                             1  \n","363                    0                             1  \n","409                    0                             1  \n","411                    1                             1  \n","412                    0                             1  \n","413                    0                             1  \n","414                    1                             1  \n","415                    0                             1  \n","416                    0                             1  \n","417                    0                             1  \n","418                    1                             1  \n","419                    0                             1  \n","420                    0                             1  \n","421                    0                             1  \n","422                    0                             1  \n","423                    0                             1  \n","424                    0                             1  \n","425                    0                             1  \n","426                    0                             1  \n","427                    0                             1  \n","428                    0                             1  \n","\n","[37 rows x 110 columns]"],"text/html":["\n","  <div id=\"df-2128450c-d1c0-47b2-8cc5-6ec223f88230\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Rash</th>\n","      <th>Pain</th>\n","      <th>...</th>\n","      <th>intervention_model_type_Parallel Assignment</th>\n","      <th>intervention_model_type_Single Group Assignment</th>\n","      <th>allocation_type_Non-Randomized</th>\n","      <th>allocation_type_Not Reported</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>37</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>33.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>33.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>170</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>19.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>172</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>19.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>276</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>278</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>352</th>\n","      <td>21.0</td>\n","      <td>19.0</td>\n","      <td>9.0</td>\n","      <td>10.0</td>\n","      <td>27.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>354</th>\n","      <td>21.0</td>\n","      <td>19.0</td>\n","      <td>9.0</td>\n","      <td>10.0</td>\n","      <td>27.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>356</th>\n","      <td>20.0</td>\n","      <td>17.0</td>\n","      <td>24.0</td>\n","      <td>5.0</td>\n","      <td>18.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>358</th>\n","      <td>20.0</td>\n","      <td>17.0</td>\n","      <td>24.0</td>\n","      <td>5.0</td>\n","      <td>18.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>361</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>363</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>409</th>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>411</th>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>10.0</td>\n","      <td>16.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>412</th>\n","      <td>78.0</td>\n","      <td>0.0</td>\n","      <td>39.0</td>\n","      <td>32.0</td>\n","      <td>37.0</td>\n","      <td>0.0</td>\n","      <td>33.0</td>\n","      <td>105.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>413</th>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>414</th>\n","      <td>36.0</td>\n","      <td>0.0</td>\n","      <td>26.0</td>\n","      <td>8.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>415</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>416</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>417</th>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>418</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>419</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>420</th>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>421</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>422</th>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>8.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>40.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>423</th>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>10.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>35.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>424</th>\n","      <td>26.0</td>\n","      <td>0.0</td>\n","      <td>25.0</td>\n","      <td>1.0</td>\n","      <td>32.0</td>\n","      <td>10.0</td>\n","      <td>3.0</td>\n","      <td>79.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>425</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>426</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>427</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>428</th>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>37 rows × 110 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2128450c-d1c0-47b2-8cc5-6ec223f88230')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2128450c-d1c0-47b2-8cc5-6ec223f88230 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2128450c-d1c0-47b2-8cc5-6ec223f88230');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":174}],"source":["X_df = X_df.loc[:, (X_df != 0).any(axis=0)]\n","X_df"]},{"cell_type":"markdown","metadata":{"id":"rARysuQbOn6K"},"source":["### Colinearity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yrGLsMyIOn6K"},"outputs":[],"source":["from statsmodels.stats.outliers_influence import variance_inflation_factor    \n","\n","def calculate_vif_(X_df, thresh=4.0):\n","    variables = list(range(X_df.shape[1]))\n","    dropped = True\n","    while dropped:\n","        dropped = False\n","        vif = [variance_inflation_factor(X_df.iloc[:, variables].values, ix)\n","               for ix in range(X_df.iloc[:, variables].shape[1])]\n","\n","        maxloc = vif.index(max(vif))\n","        if max(vif) > thresh:\n","            print('dropping \\'' + X_df.iloc[:, variables].columns[maxloc] +\n","                  '\\' at index: ' + str(maxloc))\n","            del variables[maxloc]\n","            dropped = True\n","\n","    print('Remaining variables:')\n","    print(X_df.columns[variables])\n","    return X_df.iloc[:, variables]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HePRJD6nOn6K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896614956,"user_tz":240,"elapsed":179,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"b3aa78db-8374-4add-c3bf-0919748e846a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  dropout_reason_consent withdrawn  \\\n","37                            1.0                               0.0   \n","39                            1.0                               0.0   \n","54                            6.0                               0.0   \n","56                           12.0                               0.0   \n","65                            0.0                               0.0   \n","67                            0.0                               0.0   \n","99                            0.0                               0.0   \n","101                           0.0                               0.0   \n","170                           0.0                               0.0   \n","172                           0.0                               0.0   \n","276                           0.0                               0.0   \n","278                           0.0                               0.0   \n","352                          21.0                              19.0   \n","354                          21.0                              19.0   \n","356                          20.0                              17.0   \n","358                          20.0                              17.0   \n","361                           1.0                               0.0   \n","363                           1.0                               0.0   \n","409                           4.0                               0.0   \n","411                           8.0                               0.0   \n","412                          78.0                               0.0   \n","413                           6.0                               0.0   \n","414                          36.0                               0.0   \n","415                           0.0                               0.0   \n","416                           0.0                               0.0   \n","417                           7.0                               0.0   \n","418                           0.0                               0.0   \n","419                           0.0                               0.0   \n","420                           2.0                               0.0   \n","421                           1.0                               0.0   \n","422                          12.0                               0.0   \n","423                          10.0                               0.0   \n","424                          26.0                               0.0   \n","425                           0.0                               0.0   \n","426                           0.0                               0.0   \n","427                           0.0                               0.0   \n","428                           8.0                               0.0   \n","\n","     dropout_reason_inclusion/exclusion criteria issue  \\\n","37                                                 0.0   \n","39                                                 0.0   \n","54                                                 0.0   \n","56                                                 0.0   \n","65                                                 8.0   \n","67                                                 8.0   \n","99                                                 0.0   \n","101                                                0.0   \n","170                                                6.0   \n","172                                                6.0   \n","276                                                0.0   \n","278                                                0.0   \n","352                                                9.0   \n","354                                                9.0   \n","356                                               24.0   \n","358                                               24.0   \n","361                                                6.0   \n","363                                                6.0   \n","409                                                8.0   \n","411                                                5.0   \n","412                                               39.0   \n","413                                                2.0   \n","414                                               26.0   \n","415                                                1.0   \n","416                                                0.0   \n","417                                                0.0   \n","418                                                0.0   \n","419                                                0.0   \n","420                                                2.0   \n","421                                                2.0   \n","422                                                3.0   \n","423                                                4.0   \n","424                                               25.0   \n","425                                                2.0   \n","426                                                0.0   \n","427                                                0.0   \n","428                                                5.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","37                               0.0                              33.0   \n","39                               0.0                              33.0   \n","54                               2.0                               3.0   \n","56                               4.0                               6.0   \n","65                               0.0                               0.0   \n","67                               0.0                               0.0   \n","99                               0.0                               0.0   \n","101                              0.0                               0.0   \n","170                              0.0                              19.0   \n","172                              0.0                              19.0   \n","276                              0.0                               7.0   \n","278                              0.0                               7.0   \n","352                             10.0                              27.0   \n","354                             10.0                              27.0   \n","356                              5.0                              18.0   \n","358                              5.0                              18.0   \n","361                              0.0                               1.0   \n","363                              0.0                               1.0   \n","409                              6.0                               0.0   \n","411                             10.0                              16.0   \n","412                             32.0                              37.0   \n","413                              6.0                               6.0   \n","414                              8.0                               2.0   \n","415                              0.0                               0.0   \n","416                              0.0                               1.0   \n","417                              3.0                               3.0   \n","418                              0.0                               0.0   \n","419                              0.0                               0.0   \n","420                              3.0                               1.0   \n","421                              1.0                               4.0   \n","422                              3.0                               8.0   \n","423                             10.0                               2.0   \n","424                              1.0                              32.0   \n","425                              0.0                               0.0   \n","426                              0.0                               2.0   \n","427                              0.0                               8.0   \n","428                              0.0                               1.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","37                                 0.0                                0.0   \n","39                                 0.0                                0.0   \n","54                                 0.0                                0.0   \n","56                                 0.0                                0.0   \n","65                                 0.0                                0.0   \n","67                                 0.0                                0.0   \n","99                                 0.0                                0.0   \n","101                                0.0                                0.0   \n","170                                0.0                                1.0   \n","172                                0.0                                1.0   \n","276                                0.0                                0.0   \n","278                                0.0                                0.0   \n","352                                0.0                                8.0   \n","354                                0.0                                8.0   \n","356                                0.0                                1.0   \n","358                                0.0                                1.0   \n","361                                1.0                                0.0   \n","363                                1.0                                0.0   \n","409                                0.0                                2.0   \n","411                                2.0                                0.0   \n","412                                0.0                               33.0   \n","413                                0.0                                3.0   \n","414                                0.0                                0.0   \n","415                                0.0                                0.0   \n","416                                0.0                                0.0   \n","417                                0.0                                0.0   \n","418                                2.0                                0.0   \n","419                                0.0                                0.0   \n","420                                0.0                                0.0   \n","421                                0.0                                0.0   \n","422                                4.0                                0.0   \n","423                                3.0                                0.0   \n","424                               10.0                                3.0   \n","425                                0.0                                0.0   \n","426                                0.0                                0.0   \n","427                                0.0                                0.0   \n","428                                0.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Rash  Pain  ...  \\\n","37                                 9.0   0.0   0.0  ...   \n","39                                 9.0   0.0   0.0  ...   \n","54                                 0.0   0.0   0.0  ...   \n","56                                 0.0   0.0   0.0  ...   \n","65                                 1.0   0.0   0.0  ...   \n","67                                 1.0   0.0   0.0  ...   \n","99                                 6.0   0.0   0.0  ...   \n","101                               12.0   0.0   0.0  ...   \n","170                               11.0   0.0   0.0  ...   \n","172                               11.0   0.0   0.0  ...   \n","276                                0.0   0.0   4.0  ...   \n","278                                0.0   0.0   4.0  ...   \n","352                                0.0   0.0   0.0  ...   \n","354                                0.0   0.0   0.0  ...   \n","356                                0.0   0.0   0.0  ...   \n","358                                0.0   0.0   0.0  ...   \n","361                                2.0  22.0   0.0  ...   \n","363                                2.0  22.0   0.0  ...   \n","409                                2.0   0.0   0.0  ...   \n","411                                6.0   0.0   0.0  ...   \n","412                              105.0   0.0   0.0  ...   \n","413                                9.0   0.0   0.0  ...   \n","414                                0.0   0.0   0.0  ...   \n","415                                1.0   0.0   0.0  ...   \n","416                                0.0   0.0   0.0  ...   \n","417                                0.0   0.0   0.0  ...   \n","418                               11.0   0.0   0.0  ...   \n","419                                4.0   0.0   0.0  ...   \n","420                                4.0   0.0   0.0  ...   \n","421                                3.0   0.0   0.0  ...   \n","422                               40.0   0.0   0.0  ...   \n","423                               35.0   0.0   0.0  ...   \n","424                               79.0   0.0   0.0  ...   \n","425                                2.0   0.0   0.0  ...   \n","426                                0.0   0.0   0.0  ...   \n","427                                4.0   0.0   0.0  ...   \n","428                                6.0   0.0   0.0  ...   \n","\n","     intervention_model_type_Parallel Assignment  \\\n","37                                             1   \n","39                                             1   \n","54                                             1   \n","56                                             1   \n","65                                             1   \n","67                                             1   \n","99                                             1   \n","101                                            1   \n","170                                            1   \n","172                                            1   \n","276                                            1   \n","278                                            1   \n","352                                            1   \n","354                                            1   \n","356                                            1   \n","358                                            1   \n","361                                            0   \n","363                                            0   \n","409                                            1   \n","411                                            1   \n","412                                            0   \n","413                                            1   \n","414                                            1   \n","415                                            0   \n","416                                            0   \n","417                                            1   \n","418                                            1   \n","419                                            0   \n","420                                            0   \n","421                                            0   \n","422                                            1   \n","423                                            1   \n","424                                            1   \n","425                                            0   \n","426                                            0   \n","427                                            0   \n","428                                            0   \n","\n","     intervention_model_type_Single Group Assignment  \\\n","37                                                 0   \n","39                                                 0   \n","54                                                 0   \n","56                                                 0   \n","65                                                 0   \n","67                                                 0   \n","99                                                 0   \n","101                                                0   \n","170                                                0   \n","172                                                0   \n","276                                                0   \n","278                                                0   \n","352                                                0   \n","354                                                0   \n","356                                                0   \n","358                                                0   \n","361                                                1   \n","363                                                1   \n","409                                                0   \n","411                                                0   \n","412                                                1   \n","413                                                0   \n","414                                                0   \n","415                                                1   \n","416                                                0   \n","417                                                0   \n","418                                                0   \n","419                                                1   \n","420                                                1   \n","421                                                0   \n","422                                                0   \n","423                                                0   \n","424                                                0   \n","425                                                0   \n","426                                                1   \n","427                                                1   \n","428                                                1   \n","\n","     allocation_type_Non-Randomized  allocation_type_Not Reported  \\\n","37                                0                             0   \n","39                                0                             0   \n","54                                0                             0   \n","56                                0                             0   \n","65                                0                             0   \n","67                                0                             0   \n","99                                0                             0   \n","101                               0                             0   \n","170                               0                             0   \n","172                               0                             0   \n","276                               0                             0   \n","278                               0                             0   \n","352                               0                             0   \n","354                               0                             0   \n","356                               0                             0   \n","358                               0                             0   \n","361                               0                             1   \n","363                               0                             1   \n","409                               0                             0   \n","411                               0                             0   \n","412                               0                             1   \n","413                               0                             0   \n","414                               0                             0   \n","415                               0                             1   \n","416                               0                             0   \n","417                               0                             0   \n","418                               0                             0   \n","419                               0                             1   \n","420                               0                             1   \n","421                               0                             0   \n","422                               0                             0   \n","423                               0                             0   \n","424                               0                             1   \n","425                               0                             0   \n","426                               0                             1   \n","427                               1                             0   \n","428                               0                             1   \n","\n","     allocation_type_Randomized  masking_type_Double  \\\n","37                            1                    0   \n","39                            1                    0   \n","54                            1                    1   \n","56                            1                    1   \n","65                            1                    0   \n","67                            1                    0   \n","99                            1                    0   \n","101                           1                    0   \n","170                           1                    0   \n","172                           1                    0   \n","276                           1                    1   \n","278                           1                    1   \n","352                           1                    0   \n","354                           1                    0   \n","356                           1                    0   \n","358                           1                    0   \n","361                           0                    0   \n","363                           0                    0   \n","409                           1                    1   \n","411                           1                    0   \n","412                           0                    0   \n","413                           1                    0   \n","414                           1                    0   \n","415                           0                    0   \n","416                           1                    0   \n","417                           1                    0   \n","418                           1                    0   \n","419                           0                    0   \n","420                           0                    0   \n","421                           1                    0   \n","422                           1                    0   \n","423                           1                    0   \n","424                           0                    0   \n","425                           1                    0   \n","426                           0                    0   \n","427                           0                    0   \n","428                           0                    0   \n","\n","     masking_type_None (Open Label)  masking_type_Quadruple  \\\n","37                                0                       1   \n","39                                0                       1   \n","54                                0                       0   \n","56                                0                       0   \n","65                                0                       0   \n","67                                0                       0   \n","99                                0                       0   \n","101                               0                       0   \n","170                               0                       0   \n","172                               0                       0   \n","276                               0                       0   \n","278                               0                       0   \n","352                               0                       1   \n","354                               0                       1   \n","356                               0                       1   \n","358                               0                       1   \n","361                               1                       0   \n","363                               1                       0   \n","409                               0                       0   \n","411                               0                       0   \n","412                               1                       0   \n","413                               0                       1   \n","414                               0                       0   \n","415                               1                       0   \n","416                               1                       0   \n","417                               0                       1   \n","418                               0                       0   \n","419                               1                       0   \n","420                               1                       0   \n","421                               0                       1   \n","422                               0                       1   \n","423                               0                       1   \n","424                               1                       0   \n","425                               0                       1   \n","426                               1                       0   \n","427                               1                       0   \n","428                               1                       0   \n","\n","     masking_type_Triple  study_gender_eligibility_All  \n","37                     0                             1  \n","39                     0                             1  \n","54                     0                             1  \n","56                     0                             1  \n","65                     1                             1  \n","67                     1                             1  \n","99                     1                             1  \n","101                    1                             1  \n","170                    1                             1  \n","172                    1                             1  \n","276                    0                             1  \n","278                    0                             1  \n","352                    0                             1  \n","354                    0                             1  \n","356                    0                             1  \n","358                    0                             1  \n","361                    0                             1  \n","363                    0                             1  \n","409                    0                             1  \n","411                    1                             1  \n","412                    0                             1  \n","413                    0                             1  \n","414                    1                             1  \n","415                    0                             1  \n","416                    0                             1  \n","417                    0                             1  \n","418                    1                             1  \n","419                    0                             1  \n","420                    0                             1  \n","421                    0                             1  \n","422                    0                             1  \n","423                    0                             1  \n","424                    0                             1  \n","425                    0                             1  \n","426                    0                             1  \n","427                    0                             1  \n","428                    0                             1  \n","\n","[37 rows x 110 columns]"],"text/html":["\n","  <div id=\"df-d9b0dd1b-d4df-4a6f-889e-3f5cd5958fba\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Rash</th>\n","      <th>Pain</th>\n","      <th>...</th>\n","      <th>intervention_model_type_Parallel Assignment</th>\n","      <th>intervention_model_type_Single Group Assignment</th>\n","      <th>allocation_type_Non-Randomized</th>\n","      <th>allocation_type_Not Reported</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>37</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>33.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>33.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>170</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>19.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>172</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>19.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>276</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>278</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>352</th>\n","      <td>21.0</td>\n","      <td>19.0</td>\n","      <td>9.0</td>\n","      <td>10.0</td>\n","      <td>27.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>354</th>\n","      <td>21.0</td>\n","      <td>19.0</td>\n","      <td>9.0</td>\n","      <td>10.0</td>\n","      <td>27.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>356</th>\n","      <td>20.0</td>\n","      <td>17.0</td>\n","      <td>24.0</td>\n","      <td>5.0</td>\n","      <td>18.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>358</th>\n","      <td>20.0</td>\n","      <td>17.0</td>\n","      <td>24.0</td>\n","      <td>5.0</td>\n","      <td>18.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>361</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>363</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>409</th>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>411</th>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>10.0</td>\n","      <td>16.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>412</th>\n","      <td>78.0</td>\n","      <td>0.0</td>\n","      <td>39.0</td>\n","      <td>32.0</td>\n","      <td>37.0</td>\n","      <td>0.0</td>\n","      <td>33.0</td>\n","      <td>105.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>413</th>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>414</th>\n","      <td>36.0</td>\n","      <td>0.0</td>\n","      <td>26.0</td>\n","      <td>8.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>415</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>416</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>417</th>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>418</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>419</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>420</th>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>421</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>422</th>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>8.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>40.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>423</th>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>10.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>35.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>424</th>\n","      <td>26.0</td>\n","      <td>0.0</td>\n","      <td>25.0</td>\n","      <td>1.0</td>\n","      <td>32.0</td>\n","      <td>10.0</td>\n","      <td>3.0</td>\n","      <td>79.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>425</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>426</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>427</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>428</th>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>37 rows × 110 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9b0dd1b-d4df-4a6f-889e-3f5cd5958fba')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d9b0dd1b-d4df-4a6f-889e-3f5cd5958fba button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d9b0dd1b-d4df-4a6f-889e-3f5cd5958fba');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":176}],"source":["X_df"]},{"cell_type":"markdown","metadata":{"id":"geySr50uczVY"},"source":["### Corelated Feature Drop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jQdeJL7kczVZ","colab":{"base_uri":"https://localhost:8080/","height":334},"executionInfo":{"status":"ok","timestamp":1659896615581,"user_tz":240,"elapsed":3,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"8ad38b72-239e-4cec-8146-faa9d1066899"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   dropout_reason_adverse event  \\\n","dropout_reason_adverse event                                           1.000000   \n","dropout_reason_consent withdrawn                                       0.293471   \n","dropout_reason_inclusion/exclusion criteria issue                      0.863580   \n","dropout_reason_lack of efficacy                                        0.886992   \n","dropout_reason_lost to follow-up                                       0.536462   \n","\n","                                                   dropout_reason_consent withdrawn  \\\n","dropout_reason_adverse event                                               0.293471   \n","dropout_reason_consent withdrawn                                           1.000000   \n","dropout_reason_inclusion/exclusion criteria issue                          0.372603   \n","dropout_reason_lack of efficacy                                            0.261720   \n","dropout_reason_lost to follow-up                                           0.410323   \n","\n","                                                   dropout_reason_inclusion/exclusion criteria issue  \\\n","dropout_reason_adverse event                                                                0.863580   \n","dropout_reason_consent withdrawn                                                            0.372603   \n","dropout_reason_inclusion/exclusion criteria issue                                           1.000000   \n","dropout_reason_lack of efficacy                                                             0.664121   \n","dropout_reason_lost to follow-up                                                            0.487182   \n","\n","                                                   dropout_reason_lack of efficacy  \\\n","dropout_reason_adverse event                                              0.886992   \n","dropout_reason_consent withdrawn                                          0.261720   \n","dropout_reason_inclusion/exclusion criteria issue                         0.664121   \n","dropout_reason_lack of efficacy                                           1.000000   \n","dropout_reason_lost to follow-up                                          0.457765   \n","\n","                                                   dropout_reason_lost to follow-up  \\\n","dropout_reason_adverse event                                               0.536462   \n","dropout_reason_consent withdrawn                                           0.410323   \n","dropout_reason_inclusion/exclusion criteria issue                          0.487182   \n","dropout_reason_lack of efficacy                                            0.457765   \n","dropout_reason_lost to follow-up                                           1.000000   \n","\n","                                                   dropout_reason_physician decision  \\\n","dropout_reason_adverse event                                                0.171939   \n","dropout_reason_consent withdrawn                                           -0.119617   \n","dropout_reason_inclusion/exclusion criteria issue                           0.248795   \n","dropout_reason_lack of efficacy                                            -0.005027   \n","dropout_reason_lost to follow-up                                            0.234654   \n","\n","                                                   dropout_reason_protocol violation  \\\n","dropout_reason_adverse event                                                0.848965   \n","dropout_reason_consent withdrawn                                            0.190506   \n","dropout_reason_inclusion/exclusion criteria issue                           0.638815   \n","dropout_reason_lack of efficacy                                             0.880176   \n","dropout_reason_lost to follow-up                                            0.542978   \n","\n","                                                   dropout_reason_subject withdrawal  \\\n","dropout_reason_adverse event                                                0.701763   \n","dropout_reason_consent withdrawn                                           -0.163261   \n","dropout_reason_inclusion/exclusion criteria issue                           0.583045   \n","dropout_reason_lack of efficacy                                             0.606561   \n","dropout_reason_lost to follow-up                                            0.498929   \n","\n","                                                       Rash      Pain  ...  \\\n","dropout_reason_adverse event                      -0.116910 -0.133233  ...   \n","dropout_reason_consent withdrawn                  -0.083081 -0.083081  ...   \n","dropout_reason_inclusion/exclusion criteria issue -0.005616 -0.161451  ...   \n","dropout_reason_lack of efficacy                   -0.130905 -0.130905  ...   \n","dropout_reason_lost to follow-up                  -0.172239 -0.046872  ...   \n","\n","                                                   intervention_model_type_Parallel Assignment  \\\n","dropout_reason_adverse event                                                          0.027384   \n","dropout_reason_consent withdrawn                                                      0.240793   \n","dropout_reason_inclusion/exclusion criteria issue                                     0.072732   \n","dropout_reason_lack of efficacy                                                       0.025506   \n","dropout_reason_lost to follow-up                                                      0.277149   \n","\n","                                                   intervention_model_type_Single Group Assignment  \\\n","dropout_reason_adverse event                                                              0.071150   \n","dropout_reason_consent withdrawn                                                         -0.197045   \n","dropout_reason_inclusion/exclusion criteria issue                                         0.020903   \n","dropout_reason_lack of efficacy                                                           0.064935   \n","dropout_reason_lost to follow-up                                                         -0.177240   \n","\n","                                                   allocation_type_Non-Randomized  \\\n","dropout_reason_adverse event                                            -0.092892   \n","dropout_reason_consent withdrawn                                        -0.057926   \n","dropout_reason_inclusion/exclusion criteria issue                       -0.112566   \n","dropout_reason_lack of efficacy                                         -0.091269   \n","dropout_reason_lost to follow-up                                        -0.018112   \n","\n","                                                   allocation_type_Not Reported  \\\n","dropout_reason_adverse event                                           0.182991   \n","dropout_reason_consent withdrawn                                      -0.197045   \n","dropout_reason_inclusion/exclusion criteria issue                      0.192012   \n","dropout_reason_lack of efficacy                                        0.075660   \n","dropout_reason_lost to follow-up                                      -0.045091   \n","\n","                                                   allocation_type_Randomized  \\\n","dropout_reason_adverse event                                        -0.142866   \n","dropout_reason_consent withdrawn                                     0.211515   \n","dropout_reason_inclusion/exclusion criteria issue                   -0.144398   \n","dropout_reason_lack of efficacy                                     -0.039768   \n","dropout_reason_lost to follow-up                                     0.050176   \n","\n","                                                   masking_type_Double  \\\n","dropout_reason_adverse event                                 -0.101549   \n","dropout_reason_consent withdrawn                             -0.137383   \n","dropout_reason_inclusion/exclusion criteria issue            -0.198257   \n","dropout_reason_lack of efficacy                              -0.054934   \n","dropout_reason_lost to follow-up                             -0.160429   \n","\n","                                                   masking_type_None (Open Label)  \\\n","dropout_reason_adverse event                                             0.105856   \n","dropout_reason_consent withdrawn                                        -0.226065   \n","dropout_reason_inclusion/exclusion criteria issue                        0.100363   \n","dropout_reason_lack of efficacy                                          0.006259   \n","dropout_reason_lost to follow-up                                        -0.091358   \n","\n","                                                   masking_type_Quadruple  \\\n","dropout_reason_adverse event                                     0.086947   \n","dropout_reason_consent withdrawn                                 0.501652   \n","dropout_reason_inclusion/exclusion criteria issue                0.027635   \n","dropout_reason_lack of efficacy                                  0.141610   \n","dropout_reason_lost to follow-up                                 0.343572   \n","\n","                                                   masking_type_Triple  \\\n","dropout_reason_adverse event                                 -0.126722   \n","dropout_reason_consent withdrawn                             -0.197045   \n","dropout_reason_inclusion/exclusion criteria issue             0.020903   \n","dropout_reason_lack of efficacy                              -0.117404   \n","dropout_reason_lost to follow-up                             -0.149709   \n","\n","                                                   study_gender_eligibility_All  \n","dropout_reason_adverse event                                                NaN  \n","dropout_reason_consent withdrawn                                            NaN  \n","dropout_reason_inclusion/exclusion criteria issue                           NaN  \n","dropout_reason_lack of efficacy                                             NaN  \n","dropout_reason_lost to follow-up                                            NaN  \n","\n","[5 rows x 110 columns]"],"text/html":["\n","  <div id=\"df-421edd0a-04d0-4320-87e2-229af4bbb488\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Rash</th>\n","      <th>Pain</th>\n","      <th>...</th>\n","      <th>intervention_model_type_Parallel Assignment</th>\n","      <th>intervention_model_type_Single Group Assignment</th>\n","      <th>allocation_type_Non-Randomized</th>\n","      <th>allocation_type_Not Reported</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>dropout_reason_adverse event</th>\n","      <td>1.000000</td>\n","      <td>0.293471</td>\n","      <td>0.863580</td>\n","      <td>0.886992</td>\n","      <td>0.536462</td>\n","      <td>0.171939</td>\n","      <td>0.848965</td>\n","      <td>0.701763</td>\n","      <td>-0.116910</td>\n","      <td>-0.133233</td>\n","      <td>...</td>\n","      <td>0.027384</td>\n","      <td>0.071150</td>\n","      <td>-0.092892</td>\n","      <td>0.182991</td>\n","      <td>-0.142866</td>\n","      <td>-0.101549</td>\n","      <td>0.105856</td>\n","      <td>0.086947</td>\n","      <td>-0.126722</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <td>0.293471</td>\n","      <td>1.000000</td>\n","      <td>0.372603</td>\n","      <td>0.261720</td>\n","      <td>0.410323</td>\n","      <td>-0.119617</td>\n","      <td>0.190506</td>\n","      <td>-0.163261</td>\n","      <td>-0.083081</td>\n","      <td>-0.083081</td>\n","      <td>...</td>\n","      <td>0.240793</td>\n","      <td>-0.197045</td>\n","      <td>-0.057926</td>\n","      <td>-0.197045</td>\n","      <td>0.211515</td>\n","      <td>-0.137383</td>\n","      <td>-0.226065</td>\n","      <td>0.501652</td>\n","      <td>-0.197045</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <td>0.863580</td>\n","      <td>0.372603</td>\n","      <td>1.000000</td>\n","      <td>0.664121</td>\n","      <td>0.487182</td>\n","      <td>0.248795</td>\n","      <td>0.638815</td>\n","      <td>0.583045</td>\n","      <td>-0.005616</td>\n","      <td>-0.161451</td>\n","      <td>...</td>\n","      <td>0.072732</td>\n","      <td>0.020903</td>\n","      <td>-0.112566</td>\n","      <td>0.192012</td>\n","      <td>-0.144398</td>\n","      <td>-0.198257</td>\n","      <td>0.100363</td>\n","      <td>0.027635</td>\n","      <td>0.020903</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <td>0.886992</td>\n","      <td>0.261720</td>\n","      <td>0.664121</td>\n","      <td>1.000000</td>\n","      <td>0.457765</td>\n","      <td>-0.005027</td>\n","      <td>0.880176</td>\n","      <td>0.606561</td>\n","      <td>-0.130905</td>\n","      <td>-0.130905</td>\n","      <td>...</td>\n","      <td>0.025506</td>\n","      <td>0.064935</td>\n","      <td>-0.091269</td>\n","      <td>0.075660</td>\n","      <td>-0.039768</td>\n","      <td>-0.054934</td>\n","      <td>0.006259</td>\n","      <td>0.141610</td>\n","      <td>-0.117404</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <td>0.536462</td>\n","      <td>0.410323</td>\n","      <td>0.487182</td>\n","      <td>0.457765</td>\n","      <td>1.000000</td>\n","      <td>0.234654</td>\n","      <td>0.542978</td>\n","      <td>0.498929</td>\n","      <td>-0.172239</td>\n","      <td>-0.046872</td>\n","      <td>...</td>\n","      <td>0.277149</td>\n","      <td>-0.177240</td>\n","      <td>-0.018112</td>\n","      <td>-0.045091</td>\n","      <td>0.050176</td>\n","      <td>-0.160429</td>\n","      <td>-0.091358</td>\n","      <td>0.343572</td>\n","      <td>-0.149709</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 110 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-421edd0a-04d0-4320-87e2-229af4bbb488')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-421edd0a-04d0-4320-87e2-229af4bbb488 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-421edd0a-04d0-4320-87e2-229af4bbb488');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":177}],"source":["df_corr = X_df.corr()\n","df_corr.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z3FM5yTZczVZ"},"outputs":[],"source":["threshold = 0.9\n","\n","\n","columns = np.full((df_corr.shape[0],), True, dtype=bool)\n","for i in range(df_corr.shape[0]):\n","    for j in range(i+1, df_corr.shape[0]):\n","        if df_corr.iloc[i,j] >= threshold:\n","            if columns[j]:\n","                columns[j] = False\n","selected_columns = X_df.columns[columns]\n","selected_columns\n","X_df = X_df[selected_columns]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dnSrWyRdczVZ","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1659896616274,"user_tz":240,"elapsed":4,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"bcd3181f-94d1-44b8-bf03-e078209b1e0c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  dropout_reason_consent withdrawn  \\\n","37                            1.0                               0.0   \n","39                            1.0                               0.0   \n","54                            6.0                               0.0   \n","56                           12.0                               0.0   \n","65                            0.0                               0.0   \n","67                            0.0                               0.0   \n","99                            0.0                               0.0   \n","101                           0.0                               0.0   \n","170                           0.0                               0.0   \n","172                           0.0                               0.0   \n","276                           0.0                               0.0   \n","278                           0.0                               0.0   \n","352                          21.0                              19.0   \n","354                          21.0                              19.0   \n","356                          20.0                              17.0   \n","358                          20.0                              17.0   \n","361                           1.0                               0.0   \n","363                           1.0                               0.0   \n","409                           4.0                               0.0   \n","411                           8.0                               0.0   \n","412                          78.0                               0.0   \n","413                           6.0                               0.0   \n","414                          36.0                               0.0   \n","415                           0.0                               0.0   \n","416                           0.0                               0.0   \n","417                           7.0                               0.0   \n","418                           0.0                               0.0   \n","419                           0.0                               0.0   \n","420                           2.0                               0.0   \n","421                           1.0                               0.0   \n","422                          12.0                               0.0   \n","423                          10.0                               0.0   \n","424                          26.0                               0.0   \n","425                           0.0                               0.0   \n","426                           0.0                               0.0   \n","427                           0.0                               0.0   \n","428                           8.0                               0.0   \n","\n","     dropout_reason_inclusion/exclusion criteria issue  \\\n","37                                                 0.0   \n","39                                                 0.0   \n","54                                                 0.0   \n","56                                                 0.0   \n","65                                                 8.0   \n","67                                                 8.0   \n","99                                                 0.0   \n","101                                                0.0   \n","170                                                6.0   \n","172                                                6.0   \n","276                                                0.0   \n","278                                                0.0   \n","352                                                9.0   \n","354                                                9.0   \n","356                                               24.0   \n","358                                               24.0   \n","361                                                6.0   \n","363                                                6.0   \n","409                                                8.0   \n","411                                                5.0   \n","412                                               39.0   \n","413                                                2.0   \n","414                                               26.0   \n","415                                                1.0   \n","416                                                0.0   \n","417                                                0.0   \n","418                                                0.0   \n","419                                                0.0   \n","420                                                2.0   \n","421                                                2.0   \n","422                                                3.0   \n","423                                                4.0   \n","424                                               25.0   \n","425                                                2.0   \n","426                                                0.0   \n","427                                                0.0   \n","428                                                5.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","37                               0.0                              33.0   \n","39                               0.0                              33.0   \n","54                               2.0                               3.0   \n","56                               4.0                               6.0   \n","65                               0.0                               0.0   \n","67                               0.0                               0.0   \n","99                               0.0                               0.0   \n","101                              0.0                               0.0   \n","170                              0.0                              19.0   \n","172                              0.0                              19.0   \n","276                              0.0                               7.0   \n","278                              0.0                               7.0   \n","352                             10.0                              27.0   \n","354                             10.0                              27.0   \n","356                              5.0                              18.0   \n","358                              5.0                              18.0   \n","361                              0.0                               1.0   \n","363                              0.0                               1.0   \n","409                              6.0                               0.0   \n","411                             10.0                              16.0   \n","412                             32.0                              37.0   \n","413                              6.0                               6.0   \n","414                              8.0                               2.0   \n","415                              0.0                               0.0   \n","416                              0.0                               1.0   \n","417                              3.0                               3.0   \n","418                              0.0                               0.0   \n","419                              0.0                               0.0   \n","420                              3.0                               1.0   \n","421                              1.0                               4.0   \n","422                              3.0                               8.0   \n","423                             10.0                               2.0   \n","424                              1.0                              32.0   \n","425                              0.0                               0.0   \n","426                              0.0                               2.0   \n","427                              0.0                               8.0   \n","428                              0.0                               1.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","37                                 0.0                                0.0   \n","39                                 0.0                                0.0   \n","54                                 0.0                                0.0   \n","56                                 0.0                                0.0   \n","65                                 0.0                                0.0   \n","67                                 0.0                                0.0   \n","99                                 0.0                                0.0   \n","101                                0.0                                0.0   \n","170                                0.0                                1.0   \n","172                                0.0                                1.0   \n","276                                0.0                                0.0   \n","278                                0.0                                0.0   \n","352                                0.0                                8.0   \n","354                                0.0                                8.0   \n","356                                0.0                                1.0   \n","358                                0.0                                1.0   \n","361                                1.0                                0.0   \n","363                                1.0                                0.0   \n","409                                0.0                                2.0   \n","411                                2.0                                0.0   \n","412                                0.0                               33.0   \n","413                                0.0                                3.0   \n","414                                0.0                                0.0   \n","415                                0.0                                0.0   \n","416                                0.0                                0.0   \n","417                                0.0                                0.0   \n","418                                2.0                                0.0   \n","419                                0.0                                0.0   \n","420                                0.0                                0.0   \n","421                                0.0                                0.0   \n","422                                4.0                                0.0   \n","423                                3.0                                0.0   \n","424                               10.0                                3.0   \n","425                                0.0                                0.0   \n","426                                0.0                                0.0   \n","427                                0.0                                0.0   \n","428                                0.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Rash  Pain  ...  \\\n","37                                 9.0   0.0   0.0  ...   \n","39                                 9.0   0.0   0.0  ...   \n","54                                 0.0   0.0   0.0  ...   \n","56                                 0.0   0.0   0.0  ...   \n","65                                 1.0   0.0   0.0  ...   \n","67                                 1.0   0.0   0.0  ...   \n","99                                 6.0   0.0   0.0  ...   \n","101                               12.0   0.0   0.0  ...   \n","170                               11.0   0.0   0.0  ...   \n","172                               11.0   0.0   0.0  ...   \n","276                                0.0   0.0   4.0  ...   \n","278                                0.0   0.0   4.0  ...   \n","352                                0.0   0.0   0.0  ...   \n","354                                0.0   0.0   0.0  ...   \n","356                                0.0   0.0   0.0  ...   \n","358                                0.0   0.0   0.0  ...   \n","361                                2.0  22.0   0.0  ...   \n","363                                2.0  22.0   0.0  ...   \n","409                                2.0   0.0   0.0  ...   \n","411                                6.0   0.0   0.0  ...   \n","412                              105.0   0.0   0.0  ...   \n","413                                9.0   0.0   0.0  ...   \n","414                                0.0   0.0   0.0  ...   \n","415                                1.0   0.0   0.0  ...   \n","416                                0.0   0.0   0.0  ...   \n","417                                0.0   0.0   0.0  ...   \n","418                               11.0   0.0   0.0  ...   \n","419                                4.0   0.0   0.0  ...   \n","420                                4.0   0.0   0.0  ...   \n","421                                3.0   0.0   0.0  ...   \n","422                               40.0   0.0   0.0  ...   \n","423                               35.0   0.0   0.0  ...   \n","424                               79.0   0.0   0.0  ...   \n","425                                2.0   0.0   0.0  ...   \n","426                                0.0   0.0   0.0  ...   \n","427                                4.0   0.0   0.0  ...   \n","428                                6.0   0.0   0.0  ...   \n","\n","     intervention_model_type_Parallel Assignment  \\\n","37                                             1   \n","39                                             1   \n","54                                             1   \n","56                                             1   \n","65                                             1   \n","67                                             1   \n","99                                             1   \n","101                                            1   \n","170                                            1   \n","172                                            1   \n","276                                            1   \n","278                                            1   \n","352                                            1   \n","354                                            1   \n","356                                            1   \n","358                                            1   \n","361                                            0   \n","363                                            0   \n","409                                            1   \n","411                                            1   \n","412                                            0   \n","413                                            1   \n","414                                            1   \n","415                                            0   \n","416                                            0   \n","417                                            1   \n","418                                            1   \n","419                                            0   \n","420                                            0   \n","421                                            0   \n","422                                            1   \n","423                                            1   \n","424                                            1   \n","425                                            0   \n","426                                            0   \n","427                                            0   \n","428                                            0   \n","\n","     intervention_model_type_Single Group Assignment  \\\n","37                                                 0   \n","39                                                 0   \n","54                                                 0   \n","56                                                 0   \n","65                                                 0   \n","67                                                 0   \n","99                                                 0   \n","101                                                0   \n","170                                                0   \n","172                                                0   \n","276                                                0   \n","278                                                0   \n","352                                                0   \n","354                                                0   \n","356                                                0   \n","358                                                0   \n","361                                                1   \n","363                                                1   \n","409                                                0   \n","411                                                0   \n","412                                                1   \n","413                                                0   \n","414                                                0   \n","415                                                1   \n","416                                                0   \n","417                                                0   \n","418                                                0   \n","419                                                1   \n","420                                                1   \n","421                                                0   \n","422                                                0   \n","423                                                0   \n","424                                                0   \n","425                                                0   \n","426                                                1   \n","427                                                1   \n","428                                                1   \n","\n","     allocation_type_Non-Randomized  allocation_type_Not Reported  \\\n","37                                0                             0   \n","39                                0                             0   \n","54                                0                             0   \n","56                                0                             0   \n","65                                0                             0   \n","67                                0                             0   \n","99                                0                             0   \n","101                               0                             0   \n","170                               0                             0   \n","172                               0                             0   \n","276                               0                             0   \n","278                               0                             0   \n","352                               0                             0   \n","354                               0                             0   \n","356                               0                             0   \n","358                               0                             0   \n","361                               0                             1   \n","363                               0                             1   \n","409                               0                             0   \n","411                               0                             0   \n","412                               0                             1   \n","413                               0                             0   \n","414                               0                             0   \n","415                               0                             1   \n","416                               0                             0   \n","417                               0                             0   \n","418                               0                             0   \n","419                               0                             1   \n","420                               0                             1   \n","421                               0                             0   \n","422                               0                             0   \n","423                               0                             0   \n","424                               0                             1   \n","425                               0                             0   \n","426                               0                             1   \n","427                               1                             0   \n","428                               0                             1   \n","\n","     allocation_type_Randomized  masking_type_Double  \\\n","37                            1                    0   \n","39                            1                    0   \n","54                            1                    1   \n","56                            1                    1   \n","65                            1                    0   \n","67                            1                    0   \n","99                            1                    0   \n","101                           1                    0   \n","170                           1                    0   \n","172                           1                    0   \n","276                           1                    1   \n","278                           1                    1   \n","352                           1                    0   \n","354                           1                    0   \n","356                           1                    0   \n","358                           1                    0   \n","361                           0                    0   \n","363                           0                    0   \n","409                           1                    1   \n","411                           1                    0   \n","412                           0                    0   \n","413                           1                    0   \n","414                           1                    0   \n","415                           0                    0   \n","416                           1                    0   \n","417                           1                    0   \n","418                           1                    0   \n","419                           0                    0   \n","420                           0                    0   \n","421                           1                    0   \n","422                           1                    0   \n","423                           1                    0   \n","424                           0                    0   \n","425                           1                    0   \n","426                           0                    0   \n","427                           0                    0   \n","428                           0                    0   \n","\n","     masking_type_None (Open Label)  masking_type_Quadruple  \\\n","37                                0                       1   \n","39                                0                       1   \n","54                                0                       0   \n","56                                0                       0   \n","65                                0                       0   \n","67                                0                       0   \n","99                                0                       0   \n","101                               0                       0   \n","170                               0                       0   \n","172                               0                       0   \n","276                               0                       0   \n","278                               0                       0   \n","352                               0                       1   \n","354                               0                       1   \n","356                               0                       1   \n","358                               0                       1   \n","361                               1                       0   \n","363                               1                       0   \n","409                               0                       0   \n","411                               0                       0   \n","412                               1                       0   \n","413                               0                       1   \n","414                               0                       0   \n","415                               1                       0   \n","416                               1                       0   \n","417                               0                       1   \n","418                               0                       0   \n","419                               1                       0   \n","420                               1                       0   \n","421                               0                       1   \n","422                               0                       1   \n","423                               0                       1   \n","424                               1                       0   \n","425                               0                       1   \n","426                               1                       0   \n","427                               1                       0   \n","428                               1                       0   \n","\n","     masking_type_Triple  study_gender_eligibility_All  \n","37                     0                             1  \n","39                     0                             1  \n","54                     0                             1  \n","56                     0                             1  \n","65                     1                             1  \n","67                     1                             1  \n","99                     1                             1  \n","101                    1                             1  \n","170                    1                             1  \n","172                    1                             1  \n","276                    0                             1  \n","278                    0                             1  \n","352                    0                             1  \n","354                    0                             1  \n","356                    0                             1  \n","358                    0                             1  \n","361                    0                             1  \n","363                    0                             1  \n","409                    0                             1  \n","411                    1                             1  \n","412                    0                             1  \n","413                    0                             1  \n","414                    1                             1  \n","415                    0                             1  \n","416                    0                             1  \n","417                    0                             1  \n","418                    1                             1  \n","419                    0                             1  \n","420                    0                             1  \n","421                    0                             1  \n","422                    0                             1  \n","423                    0                             1  \n","424                    0                             1  \n","425                    0                             1  \n","426                    0                             1  \n","427                    0                             1  \n","428                    0                             1  \n","\n","[37 rows x 61 columns]"],"text/html":["\n","  <div id=\"df-ec1f5a8e-b66c-483b-8a03-8eb48e029467\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Rash</th>\n","      <th>Pain</th>\n","      <th>...</th>\n","      <th>intervention_model_type_Parallel Assignment</th>\n","      <th>intervention_model_type_Single Group Assignment</th>\n","      <th>allocation_type_Non-Randomized</th>\n","      <th>allocation_type_Not Reported</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>37</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>33.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>33.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>170</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>19.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>172</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>19.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>276</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>278</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>352</th>\n","      <td>21.0</td>\n","      <td>19.0</td>\n","      <td>9.0</td>\n","      <td>10.0</td>\n","      <td>27.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>354</th>\n","      <td>21.0</td>\n","      <td>19.0</td>\n","      <td>9.0</td>\n","      <td>10.0</td>\n","      <td>27.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>356</th>\n","      <td>20.0</td>\n","      <td>17.0</td>\n","      <td>24.0</td>\n","      <td>5.0</td>\n","      <td>18.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>358</th>\n","      <td>20.0</td>\n","      <td>17.0</td>\n","      <td>24.0</td>\n","      <td>5.0</td>\n","      <td>18.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>361</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>363</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>409</th>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>411</th>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>10.0</td>\n","      <td>16.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>412</th>\n","      <td>78.0</td>\n","      <td>0.0</td>\n","      <td>39.0</td>\n","      <td>32.0</td>\n","      <td>37.0</td>\n","      <td>0.0</td>\n","      <td>33.0</td>\n","      <td>105.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>413</th>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>414</th>\n","      <td>36.0</td>\n","      <td>0.0</td>\n","      <td>26.0</td>\n","      <td>8.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>415</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>416</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>417</th>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>418</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>419</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>420</th>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>421</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>422</th>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>8.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>40.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>423</th>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>10.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>35.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>424</th>\n","      <td>26.0</td>\n","      <td>0.0</td>\n","      <td>25.0</td>\n","      <td>1.0</td>\n","      <td>32.0</td>\n","      <td>10.0</td>\n","      <td>3.0</td>\n","      <td>79.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>425</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>426</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>427</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>428</th>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>37 rows × 61 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec1f5a8e-b66c-483b-8a03-8eb48e029467')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ec1f5a8e-b66c-483b-8a03-8eb48e029467 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ec1f5a8e-b66c-483b-8a03-8eb48e029467');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":179}],"source":["X_df"]},{"cell_type":"markdown","metadata":{"id":"YynVlmLwczVZ"},"source":["Standardize and split data "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BqZSJs0TczVZ"},"outputs":[],"source":["X_df_norm = (X_df-X_df.min())/(X_df.max()-X_df.min())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H3qw89itiLbo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896616442,"user_tz":240,"elapsed":6,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"68f401b3-69bc-440a-c2d3-aa87b03ba5fe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Series([], dtype: object)"]},"metadata":{},"execution_count":181}],"source":["X_df_norm.columns.to_series()[np.isinf(X_df_norm).any()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XvXUGzbSiXl-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896616443,"user_tz":240,"elapsed":6,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"22f29086-c9a9-4378-8e9b-fd0e66152c06"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dropout_reason_adverse event                          0\n","dropout_reason_consent withdrawn                      0\n","dropout_reason_inclusion/exclusion criteria issue     0\n","dropout_reason_lack of efficacy                       0\n","dropout_reason_lost to follow-up                      0\n","                                                     ..\n","masking_type_Double                                   0\n","masking_type_None (Open Label)                        0\n","masking_type_Quadruple                                0\n","masking_type_Triple                                   0\n","study_gender_eligibility_All                         37\n","Length: 61, dtype: int64"]},"metadata":{},"execution_count":182}],"source":["X_df_norm.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TiM-NLYuiMJs"},"outputs":[],"source":["X_df_norm = X_df_norm.fillna(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"45iFLCEVRZyA"},"outputs":[],"source":["count = np.isnan(X_df_norm).values.sum()"]},{"cell_type":"code","source":["mean(y_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sP4Qaa7ZjGSA","executionInfo":{"status":"ok","timestamp":1659896625260,"user_tz":240,"elapsed":135,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"70b844cc-f003-41ad-e043-2853f4972fc7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30.43135113148484"]},"metadata":{},"execution_count":186}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UBHNew7wiOow","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896616443,"user_tz":240,"elapsed":3,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"873b3d2f-29da-4465-8ecc-e44537a18cdc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((29, 61), (8, 61))"]},"metadata":{},"execution_count":185}],"source":["# Train/test split:\n","X_train, X_test, y_train, y_test = train_test_split(X_df_norm, y_df, test_size = 0.2, random_state = 2)\n","\n","X_train.shape, X_test.shape"]},{"cell_type":"markdown","metadata":{"id":"RVXQKK0p0lkc"},"source":["### Feature Selection"]},{"cell_type":"markdown","metadata":{"id":"sj7fof-L0lkc"},"source":["#### Feature Importance with Gradient Boosting"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1659890131292,"user_tz":240,"elapsed":178,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4661acf5-1779-49c7-f5d4-3335c78e0fb7","id":"ON0oo11D0lkc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4288759363250807"]},"metadata":{},"execution_count":28}],"source":["# GradientBoostingRegressor will be used for feature importance\n","reg_model = GradientBoostingRegressor(random_state=0)   \n","reg_model.fit(X_train, y_train)\n","y_preds = reg_model.predict(X_test)\n","r2_score(y_test, y_preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1659890131293,"user_tz":240,"elapsed":4,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"colab":{"base_uri":"https://localhost:8080/","height":676},"outputId":"a0c48973-a909-4f20-dca5-cf341bbe25e2","id":"ggiaNXmN0lkd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   importance\n","dropout_reason_inclusion/exclusion criteria issue    0.318439\n","dropout_reason_lost to follow-up                     0.058545\n","event_type_other                                     0.045327\n","Headache                                             0.040401\n","study_duration_months                                0.038388\n","Abdominal pain                                       0.037683\n","intervention_model_type_Factorial Assignment         0.037326\n","Genetic                                              0.034936\n","Nausea                                               0.028028\n","dropout_reason_adverse event                         0.025854\n","Dissociation                                         0.024618\n","Overdose                                             0.022068\n","dropout_reason_subject withdrawal                    0.017419\n","Glossitis                                            0.017076\n","Major depression                                     0.013135\n","masking_type_Quadruple                               0.012135\n","Lethargy                                             0.011323\n","Tremor                                               0.010559\n","intervention_model_type_Single Group Assignment      0.010132\n","dropout_reason_lack of efficacy                      0.009232"],"text/html":["\n","  <div id=\"df-94066c3e-bb63-41de-87b5-f6560594c6e0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>importance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <td>0.318439</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <td>0.058545</td>\n","    </tr>\n","    <tr>\n","      <th>event_type_other</th>\n","      <td>0.045327</td>\n","    </tr>\n","    <tr>\n","      <th>Headache</th>\n","      <td>0.040401</td>\n","    </tr>\n","    <tr>\n","      <th>study_duration_months</th>\n","      <td>0.038388</td>\n","    </tr>\n","    <tr>\n","      <th>Abdominal pain</th>\n","      <td>0.037683</td>\n","    </tr>\n","    <tr>\n","      <th>intervention_model_type_Factorial Assignment</th>\n","      <td>0.037326</td>\n","    </tr>\n","    <tr>\n","      <th>Genetic</th>\n","      <td>0.034936</td>\n","    </tr>\n","    <tr>\n","      <th>Nausea</th>\n","      <td>0.028028</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_adverse event</th>\n","      <td>0.025854</td>\n","    </tr>\n","    <tr>\n","      <th>Dissociation</th>\n","      <td>0.024618</td>\n","    </tr>\n","    <tr>\n","      <th>Overdose</th>\n","      <td>0.022068</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <td>0.017419</td>\n","    </tr>\n","    <tr>\n","      <th>Glossitis</th>\n","      <td>0.017076</td>\n","    </tr>\n","    <tr>\n","      <th>Major depression</th>\n","      <td>0.013135</td>\n","    </tr>\n","    <tr>\n","      <th>masking_type_Quadruple</th>\n","      <td>0.012135</td>\n","    </tr>\n","    <tr>\n","      <th>Lethargy</th>\n","      <td>0.011323</td>\n","    </tr>\n","    <tr>\n","      <th>Tremor</th>\n","      <td>0.010559</td>\n","    </tr>\n","    <tr>\n","      <th>intervention_model_type_Single Group Assignment</th>\n","      <td>0.010132</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <td>0.009232</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94066c3e-bb63-41de-87b5-f6560594c6e0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-94066c3e-bb63-41de-87b5-f6560594c6e0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-94066c3e-bb63-41de-87b5-f6560594c6e0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":29}],"source":["feature_imp = pd.DataFrame(reg_model.feature_importances_,\n","                                   index = X_train.columns,\n","                                   columns=['importance']).sort_values('importance', ascending=False)\n","\n","feature_imp.head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YaLxcSjj0lkd"},"outputs":[],"source":["#create list of top 30 features\n","boost_top_10 = feature_imp.head(10).index.values\n","boost_top_10_list = list(boost_top_10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fYWVN8dz0lkd"},"outputs":[],"source":["X_boost_df = X_df[X_df.columns.intersection(boost_top_10_list)]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1659890131482,"user_tz":240,"elapsed":3,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9298c539-76d9-4551-f6a0-512d56403e0f","id":"ig7rxboK0lkd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((271, 10), (68, 10))"]},"metadata":{},"execution_count":32}],"source":["# Train/test split:\n","X_boost_train, X_boost_test, y_train, y_test = train_test_split(X_boost_df, y_df, test_size = 0.2, random_state = 2)\n","\n","X_boost_train.shape, X_boost_test.shape"]},{"cell_type":"markdown","source":["##### Model Set-up"],"metadata":{"id":"_pYywo680lkd"}},{"cell_type":"code","source":["# Continous outcome prediction:\n","\n","def train_and_test(reg_model, X_train, y_train, X_test, y_test):\n","  reg_model.fit(X_train, y_train)\n","  # Make predictions with model\n","  y_pred = reg_model.predict(X_test)\n","  #Metrics\n","  mse_score_val = mean_squared_error(y_test, y_pred)\n","  r2_score_val = r2_score(y_test, y_pred)\n","  return {\"MSE_Score\": mse_score_val, \"R2_Score\": r2_score_val}"],"metadata":{"id":"2Qj1YiWr0lkd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Linear Regression"],"metadata":{"id":"Kt3NKc6n0lkd"}},{"cell_type":"code","source":["# Linear Regression:\n","\n","lr_model = LinearRegression()\n","\n","scores = cross_val_score(lr_model, X_boost_train, y_train, scoring='r2', cv=5)\n","scores   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893244224,"user_tz":240,"elapsed":149,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"7e15afcf-dc7e-4be4-9ead-b02e6c00e426","id":"dC943y2H0lkd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.52372859,  0.22300902,  0.40490087,  0.28289511,  0.22152235])"]},"metadata":{},"execution_count":104}]},{"cell_type":"code","source":["# k-fold CV (using all the boost variables)\n","train_and_test(lr_model, X_boost_train, y_train, X_boost_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893245438,"user_tz":240,"elapsed":2,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"1580e64d-dfae-49fb-ad3d-97cc49d9cbbc","id":"3BnkpXA20lkd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'MSE_Score': 320.12078109174996, 'R2_Score': 0.27008943892479653}"]},"metadata":{},"execution_count":105}]},{"cell_type":"markdown","source":["Random Forest"],"metadata":{"id":"Q4O00fRl0lkd"}},{"cell_type":"code","source":["# Random Forest Regression:\n","\n","rfr_model = RandomForestRegressor()\n","\n","scores = cross_val_score(rfr_model, X_boost_train, y_train, scoring='r2', cv=5)\n","scores   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893012236,"user_tz":240,"elapsed":2255,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"3379fa3e-f132-4e1a-dfba-ae15c9339c25","id":"Y8Uoi4Rg0lke"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.21087431, 0.4829302 , 0.49542987, 0.26260168, 0.45673906])"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["\n","train_and_test(rfr_model, X_boost_train, y_train, X_boost_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893013554,"user_tz":240,"elapsed":607,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"44be92a3-36fd-42ca-98b1-f2321d638b9f","id":"eFj7vaEl0lke"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'MSE_Score': 239.01657569297282, 'R2_Score': 0.455015940310575}"]},"metadata":{},"execution_count":97}]},{"cell_type":"markdown","source":["Gradient Boosting"],"metadata":{"id":"QUJiZdNh0lke"}},{"cell_type":"code","source":["# Gradient Boost for feature importance:\n","\n","boost_model = GradientBoostingRegressor(random_state=0)   \n","\n","scores = cross_val_score(boost_model, X_boost_train, y_train, scoring='r2', cv=5)\n","scores   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893141201,"user_tz":240,"elapsed":860,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"cd9eebc5-824a-4f51-d233-07aaff560c52","id":"oHmHCSAW0lke"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.11861583, 0.52141256, 0.46201785, 0.23063168, 0.37609487])"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":["boost_model.fit(X_boost_train, y_train)\n","y_preds = boost_model.predict(X_boost_test)\n","r2_score(y_test, y_preds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893147475,"user_tz":240,"elapsed":316,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"f4bcf021-b3e3-4597-a9f4-494dc6deff67","id":"1YfkXGIj0lke"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4156543656927092"]},"metadata":{},"execution_count":100}]},{"cell_type":"code","source":["#chose five models to train the data with to see which performs the best : Linear Regression and Support Vector Regression\n","pipe_lr = Pipeline([('LR', LinearRegression())])\n","pipe_svm = Pipeline([('SVM', SVR())])\n","pipe_rfr = Pipeline([('RFR', RandomForestRegressor())])\n","pipe_dtr = Pipeline([('DTR', DecisionTreeRegressor())])\n","pipe_gbr = Pipeline([('DTR', GradientBoostingRegressor())])\n","\n","#create GridSearch parameters\n","\n","#creates lists to pass into the grid below\n","C = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n","epsilon = [0, 0.01, 0.1, 0.5, 1, 2, 4, 5]\n","n_estimators = [50,100,150, 200, 300, 500,1000, 1500]\n","n_jobs = np.array([1, 10, 100, 290, 500])\n","bootstrap = [True, False]\n","max_depth = [3,4,6,8,10]\n","min_samples_split = [10,20,40]\n","max_depth = [2, 6, 8]\n","min_samples_leaf = [20, 40, 100]\n","max_leaf_nodes = [5, 20, 100]\n","learning_rate = [0.01,0.02,0.03,0.04]\n","subsample = [0.9, 0.5, 0.2, 0.1]\n","\n","#these will be passed to the GridSearchCV function below -> which will take a pipeline model and test out each paramter value passed through in the following parameter list\n","lr_space = [{'fit_intercept':[True, False]}]\n","\n","svr_space = [{'kernel': ['linear'], 'C' : C, 'epsilon' : epsilon},\n","         {'kernel': ['rbf'], 'C' : C, 'gamma' : C, 'epsilon' : epsilon}]\n","\n","rfr_space = [{'max_features' : [\"auto\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"sqrt\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"log2\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","dtr_space = [{'criterion': ['squared_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes},\n","            {'criterion': ['absolute_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes}]\n","\n","gbr_space = [{'learning_rate': learning_rate, 'subsample' : subsample, 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","\n","\n","##use the GridSearchCV function and pass in both the pipeline created above and the grid parameters \n","\n","#pass in cv=5 for the gridsearch to perform cross-validation on our training set\n","#pass score = accuracy for get the accrucay score when the test is performed \n","lr_gs = GridSearchCV(LinearRegression(), param_grid = lr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","svm_gs = GridSearchCV(SVR(), param_grid = svr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","rfr_gs = GridSearchCV(RandomForestRegressor(), param_grid = rfr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","dtr_gs = GridSearchCV(DecisionTreeRegressor(), param_grid = dtr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","gbr_gs = GridSearchCV(GradientBoostingRegressor(), param_grid = gbr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","\n","lr_grids = [lr_gs]\n","\n","for lr_pipe in lr_grids:\n","    lr_pipe.fit(X_boost_train,y_train)\n","\n","svm_grids = [svm_gs]\n","\n","for svm_pipe in svm_grids:\n","    svm_pipe.fit(X_boost_train,y_train)\n","\n","rfr_grids = [rfr_gs]\n","\n","for rfr_pipe in rfr_grids:\n","    rfr_pipe.fit(X_boost_train,y_train)\n","\n","dtr_grids = [dtr_gs]\n","\n","for dtr_pipe in dtr_grids:\n","    dtr_pipe.fit(X_boost_train,y_train)\n","\n","gbr_grids = [gbr_gs]\n","\n","for gbr_pipe in gbr_grids:\n","    gbr_pipe.fit(X_boost_train,y_train)"],"metadata":{"id":"VyqFb72Y0lke"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#first create a dictionary that contains the classifier types to used int eh for loop. \n","lr_grid_dict = {0: 'Linear Regression'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(lr_grids):\n","    print('{} Train R_Square: {}'.format(lr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","lr_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,lr_y_pred)*100\n","\n","for i, model in enumerate(lr_grids):\n","    print('{} Test R_Square: {}'.format(lr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","svm_grid_dict = {0: 'Support Vector Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(svm_grids):\n","    print('{} Train R_Square: {}'.format(svm_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","svm_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,svm_y_pred)*100\n","\n","for i, model in enumerate(svm_grids):\n","    print('{} Test R_Square: {}'.format(svm_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          results.best_params_))\n","    \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","rfr_grid_dict = {0: 'Random Forest Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(rfr_grids):\n","    print('{} Train R_Square: {}'.format(rfr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","rf_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,rf_y_pred)*100\n","\n","for i, model in enumerate(rfr_grids):\n","    print('{} Test R_Square: {}'.format(rfr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","dtr_grid_dict = {0: 'Decision Tree Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(dtr_grids):\n","    print('{} Train R_Square: {}'.format(dtr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","dtr_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,dtr_y_pred)*100\n","\n","for i, model in enumerate(dtr_grids):\n","    print('{} Test R_Square: {}'.format(dtr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","gbr_grid_dict = {0: 'Gradient Boosting Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(gbr_grids):\n","    print('{} Train R_Square: {}'.format(gbr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","gbr_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,gbr_y_pred)*100\n","\n","for i, model in enumerate(gbr_grids):\n","    print('{} Test R_Square: {}'.format(gbr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          results.best_params_))"],"metadata":{"id":"W8oMNsYV0lke"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xr_wrPio0lke"},"source":["#### Mutual Information Feature Selection "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659724797561,"user_tz":240,"elapsed":2931,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"7f430427-d146-4f57-c8f0-ac55c5f102fa","id":"R1BfJZ9q0lke"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1.93329965e-01 2.79787357e-02 0.00000000e+00 2.85353136e-01\n"," 1.12896336e-01 2.04555356e-01 6.47709408e-02 1.89068091e-02\n"," 2.36317673e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.14886389e-02 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 9.31302684e-04 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 2.32252200e-03 1.40305033e-01\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.39487101e-02\n"," 7.96625655e-03 0.00000000e+00 9.11215201e-02 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 2.24477243e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 5.80357087e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.13094503e-01 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.45845098e-03 7.19362761e-03\n"," 0.00000000e+00 0.00000000e+00 2.40973048e-03 7.97151068e-03\n"," 1.65255318e-02 2.68652715e-02 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 4.78600247e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 9.50697768e-04 2.04791150e-03 0.00000000e+00 0.00000000e+00\n"," 1.41220624e-03 0.00000000e+00 5.01277239e-03 0.00000000e+00\n"," 0.00000000e+00 7.38843507e-03 0.00000000e+00 0.00000000e+00\n"," 1.29290297e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 6.44048285e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 5.02576173e-03 0.00000000e+00 0.00000000e+00 1.99348901e-03\n"," 7.05102041e-03 8.03350383e-03 9.70502791e-04 1.17793054e-03\n"," 5.30411535e-03 0.00000000e+00 5.33382372e-03 3.65177267e-04\n"," 8.64074784e-03 0.00000000e+00 1.19599897e-02 0.00000000e+00\n"," 2.84805174e-03 1.38729789e-03 0.00000000e+00 1.02384043e-02\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 1.09570251e-02 1.19276081e-02 0.00000000e+00 2.53345761e-04\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.42389858e-02\n"," 0.00000000e+00 1.85970340e-02 1.75240411e-03 3.44523841e-03\n"," 9.75414247e-03 2.92779979e-03 0.00000000e+00 0.00000000e+00\n"," 1.77997772e-03 0.00000000e+00 8.69478688e-04 2.96583868e-03\n"," 0.00000000e+00 8.08535841e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 1.97063305e-02 3.67974827e-05 1.96065812e-05\n"," 0.00000000e+00 0.00000000e+00 3.69781965e-04 0.00000000e+00\n"," 0.00000000e+00 1.26305402e-03 0.00000000e+00 0.00000000e+00\n"," 4.49748302e-03 8.72724855e-03 4.24913952e-03 4.28808130e-03\n"," 0.00000000e+00 0.00000000e+00 1.04173726e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 2.68405974e-03 9.93819846e-04\n"," 0.00000000e+00 2.74253287e-02 5.91776086e-03 0.00000000e+00\n"," 3.12987092e-03 0.00000000e+00 0.00000000e+00 1.84500421e-02\n"," 0.00000000e+00 7.46316487e-04 0.00000000e+00 2.83490536e-03\n"," 6.22400733e-03 9.66883491e-03 1.97294403e-02 0.00000000e+00\n"," 4.05093784e-03 0.00000000e+00 4.27624185e-05 9.47262668e-06\n"," 0.00000000e+00 2.39920972e-03 0.00000000e+00 0.00000000e+00\n"," 2.83998190e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 6.63027663e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 2.69679475e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 3.30421947e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 9.72412049e-04\n"," 0.00000000e+00 0.00000000e+00 1.51862016e-03 1.57903235e-02\n"," 0.00000000e+00 0.00000000e+00 5.30980431e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 6.48832115e-04 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.46576918e-04\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.60120945e-02\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.08799955e-02 5.67464207e-03\n"," 0.00000000e+00 0.00000000e+00 2.99233670e-03 3.60552397e-03\n"," 2.10738798e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 1.36375133e-02 0.00000000e+00 0.00000000e+00\n"," 1.38784031e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 2.36206964e-03 0.00000000e+00 0.00000000e+00\n"," 4.14751754e-04 4.63904996e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 3.81096621e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 1.43343054e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 9.67265880e-04 4.12500329e-04\n"," 1.32235983e-02 7.88329410e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 3.73740846e-04 0.00000000e+00 5.22484888e-03\n"," 6.29731809e-02 0.00000000e+00 6.21929279e-02 1.49949132e-01\n"," 8.69707919e-03 1.86974960e-02 3.31688153e-03 6.98487316e-02\n"," 5.58862446e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 1.70697662e-01 1.35633449e-01 0.00000000e+00\n"," 0.00000000e+00 8.44687426e-03 0.00000000e+00 3.92890583e-04\n"," 3.05852092e-02 0.00000000e+00 1.77488514e-02 3.18491126e-02\n"," 4.92078625e-02 5.25771761e-02 3.57412169e-02 0.00000000e+00\n"," 0.00000000e+00 6.05903110e-02 2.00073829e-02 2.41637927e-02\n"," 2.98299349e-02 6.85765039e-04 0.00000000e+00 3.66658126e-02\n"," 8.50858185e-02 8.20275432e-03 0.00000000e+00 1.04039135e-02\n"," 2.37977376e-02 7.00182719e-03]\n"]}],"source":["from sklearn.feature_selection import mutual_info_regression  \n","from sklearn.feature_selection import SelectKBest\n","selector = SelectKBest(mutual_info_regression, k=10)\n","X_train_new = selector.fit_transform(X_train, y_train)  #Applying transformation to the training set\n","#to get names of the selected features\n","mask = selector.get_support()  \n","\n","print(selector.scores_)   \n","\n","new_features = X_train.columns[mask]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"POrxSzuG0lkf"},"outputs":[],"source":["X_MI_df = V4_master_df[new_features]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":375},"executionInfo":{"status":"error","timestamp":1659724798118,"user_tz":240,"elapsed":289,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"b261267e-2132-4ed7-fe08-e4c25bcaeb52","id":"KRoTJidt0lkf"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-82-a1d14a8e7824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train/test split:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_MI_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_MI_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_MI_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_MI_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_MI_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2417\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [800, 339]"]}],"source":["# Train/test split:\n","X_MI_train, X_MI_test, y_train, y_test = train_test_split(X_MI_df, y_df, test_size = 0.2, random_state = 2)\n","\n","X_MI_train.shape, X_MI_test.shape"]},{"cell_type":"code","source":["logreg=LogisticRegression()\n","kf=KFold(n_splits=5)\n","score=cross_val_score(logreg,X_MI_train,y_train,cv=kf)\n","print(\"Cross Validation Scores are {}\".format(score))\n","print(\"Average Cross Validation score :{}\".format(score.mean()))\n","\n","# Train classifiers\n","reg1 = GradientBoostingRegressor(random_state=1)\n","reg2 = RandomForestRegressor(random_state=1)\n","reg3 = LinearRegression()\n","\n","reg1.fit(X_MI_train, y_train)\n","reg2.fit(X_MI_train, y_train)\n","reg3.fit(X_MI_train, y_train)\n","\n","ereg = VotingRegressor([(\"gb\", reg1), (\"rf\", reg2), (\"lr\", reg3)])\n","ereg.fit(X_MI_train, y_train)\n","\n","#predict \n","pred1 = reg1.predict(X_boost_test)\n","pred2 = reg2.predict(X_boost_test)\n","pred3 = reg3.predict(X_boost_test)\n","pred4 = ereg.predict(X_boost_test)\n","\n","#plot\n","plt.figure()\n","plt.plot(pred1, \"gd\", label=\"GradientBoostingRegressor\")\n","plt.plot(pred2, \"b^\", label=\"RandomForestRegressor\")\n","plt.plot(pred3, \"ys\", label=\"LinearRegression\")\n","plt.plot(pred4, \"r*\", ms=10, label=\"VotingRegressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"training samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions and their average - Depression\")\n","plt.setp(plt.gca(),ylim=(0,100))\n","\n","plt.show()"],"metadata":{"id":"Z-5GmdqM0lkf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#chose five models to train the data with to see which performs the best : Linear Regression and Support Vector Regression\n","pipe_lr = Pipeline([('LR', LinearRegression())])\n","pipe_svm = Pipeline([('SVM', SVR())])\n","pipe_rfr = Pipeline([('RFR', RandomForestRegressor())])\n","pipe_dtr = Pipeline([('DTR', DecisionTreeRegressor())])\n","pipe_gbr = Pipeline([('DTR', GradientBoostingRegressor())])\n","\n","#create GridSearch parameters\n","\n","#creates lists to pass into the grid below\n","C = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n","epsilon = [0, 0.01, 0.1, 0.5, 1, 2, 4, 5]\n","n_estimators = [50,100,150, 200, 300, 500,1000, 1500]\n","n_jobs = np.array([1, 10, 100, 290, 500])\n","bootstrap = [True, False]\n","max_depth = [3,4,6,8,10]\n","min_samples_split = [10,20,40]\n","max_depth = [2, 6, 8]\n","min_samples_leaf = [20, 40, 100]\n","max_leaf_nodes = [5, 20, 100]\n","learning_rate = [0.01,0.02,0.03,0.04]\n","subsample = [0.9, 0.5, 0.2, 0.1]\n","\n","#these will be passed to the GridSearchCV function below -> which will take a pipeline model and test out each paramter value passed through in the following parameter list\n","lr_space = [{'fit_intercept': ['svd'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['cholesky'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['lsqr'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sparse_cg'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sag'],  'n_jobs' : n_jobs},\n","         {'fit_intercept': ['saga'], 'n_jobs' : n_jobs}]\n","\n","svr_space = [{'kernel': ['linear'], 'C' : C, 'epsilon' : epsilon},\n","         {'kernel': ['rbf'], 'C' : C, 'gamma' : C, 'epsilon' : epsilon}]\n","\n","rfr_space = [{'max_features' : [\"auto\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"sqrt\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"log2\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","dtr_space = [{'criterion': ['mse'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes},\n","         {'criterion': ['absolute_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes}]\n","\n","gbr_space = [{'learning_rate': learning_rate, 'subsample' : subsample, 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","\n","\n","##use the GridSearchCV function and pass in both the pipeline created above and the frid parameters \n","\n","#pass in cv=3 for the fridsearch to perform cross-validation on our training set\n","#pass score = accuracy for get the accrucay score when the test is performed \n","lr_gs = GridSearchCV(LinearRegression(), param_grid = lr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","svm_gs = GridSearchCV(SVR(), param_grid = svr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","rfr_gs = GridSearchCV(RandomForestRegressor(), param_grid = rfr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","dtr_gs = GridSearchCV(DecisionTreeRegressor(), param_grid = dtr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","gbr_gs = GridSearchCV(GradientBoostingRegressor(), param_grid = gbr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","\n","lr_grids = [lr_gs]\n","\n","for lr_pipe in lr_grids:\n","    lr_pipe.fit(X_MI_train,y_train)\n","\n","svm_grids = [svm_gs]\n","\n","for svm_pipe in svm_grids:\n","    svm_pipe.fit(X_MI_train,y_train)\n","\n","rfr_grids = [rfr_gs]\n","\n","for rfr_pipe in rfr_grids:\n","    rfr_pipe.fit(X_MI_train,y_train)\n","\n","dtr_grids = [dtr_gs]\n","\n","for dtr_pipe in dtr_grids:\n","    dtr_pipe.fit(X_MI_train,y_train)\n","\n","gbr_grids = [gbr_gs]\n","\n","for gbr_pipe in gbr_grids:\n","    gbr_pipe.fit(X_MI_train,y_train)"],"metadata":{"id":"2tBYkJvq0lkf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#first create a dictionary that contains the classifier types to used int eh for loop. \n","lr_grid_dict = {0: 'Linear Regression'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(lr_grids):\n","    print('{} Train R_Square: {}'.format(lr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(lr_grids):\n","    print('{} Test R_Square: {}'.format(lr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","svm_grid_dict = {0: 'Support Vector Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(svm_grids):\n","    print('{} Train R_Square: {}'.format(svm_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(svm_grids):\n","    print('{} Test R_Square: {}'.format(svm_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","rfr_grid_dict = {0: 'Random Forest Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(rfr_grids):\n","    print('{} Train R_Square: {}'.format(rfr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(rfr_grids):\n","    print('{} Test R_Square: {}'.format(rfr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","dtr_grid_dict = {0: 'Decision Tree Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(dtr_grids):\n","    print('{} Train R_Square: {}'.format(dtr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(dtr_grids):\n","    print('{} Test R_Square: {}'.format(dtr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","gbr_grid_dict = {0: 'Gradient Boosting Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(gbr_grids):\n","    print('{} Train R_Square: {}'.format(gbr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(gbr_grids):\n","    print('{} Test R_Square: {}'.format(gbr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))"],"metadata":{"id":"NmOT6Mh70lkf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KI3vFZ790lkf"},"source":["#### Knowledge Feature Selection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PCgokEOI0lkf"},"outputs":[],"source":["df_list = list(X_df[['number_of_arms', 'has_dmc', 'number_of_facilities', 'study_duration_months', 'event_type_deaths', 'event_type_other', 'event_type_serious']])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"40hyL4pN0lkf"},"outputs":[],"source":["dropout_list = list(X_df[['dropout_reason_adverse event', 'dropout_reason_inclusion/exclusion criteria issue', 'dropout_reason_lost to follow-up']])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659724854258,"user_tz":240,"elapsed":139,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"6e474a56-8e67-44c6-ba63-94dc82d8b857","id":"SW714x5B0lkf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Headache',\n"," 'Nausea',\n"," 'Fatigue',\n"," 'Vomiting',\n"," 'Decreased appetite',\n"," 'Diarrhoea',\n"," 'Sedation',\n"," 'Rash',\n"," 'Increased appetite',\n"," 'Palpitations']"]},"metadata":{},"execution_count":85}],"source":["top_ae_table_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Zg63XSU0lkg"},"outputs":[],"source":["X_knowledge_df = X_df[X_df.columns.intersection(top_ae_table_list+dropout_list+df_list)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hdnTPy8V0lkg"},"outputs":[],"source":["X_knowledge_norm = (X_knowledge_df-X_knowledge_df.min())/(X_knowledge_df.max()-X_knowledge_df.min())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659724857924,"user_tz":240,"elapsed":117,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"1f81e75a-1e24-4ea5-fc14-1c0e06343aca","id":"Fx36Wjyr0lkg"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((271, 20), (68, 20))"]},"metadata":{},"execution_count":88}],"source":["# Train/test split:\n","X_knowledge_train, X_knowledge_test, y_train, y_test = train_test_split(X_knowledge_norm, y_df, test_size = 0.2, random_state = 2)\n","\n","X_knowledge_train.shape, X_knowledge_test.shape"]},{"cell_type":"code","source":["logreg=LogisticRegression()\n","kf=KFold(n_splits=5)\n","score=cross_val_score(logreg,X_knowledge_train,y_train,cv=kf)\n","print(\"Cross Validation Scores are {}\".format(score))\n","print(\"Average Cross Validation score :{}\".format(score.mean()))\n","\n","# Train classifiers\n","reg1 = GradientBoostingRegressor(random_state=1)\n","reg2 = RandomForestRegressor(random_state=1)\n","reg3 = LinearRegression()\n","\n","reg1.fit(X_knowledge_train, y_train)\n","reg2.fit(X_knowledge_train, y_train)\n","reg3.fit(X_knowledge_train, y_train)\n","\n","ereg = VotingRegressor([(\"gb\", reg1), (\"rf\", reg2), (\"lr\", reg3)])\n","ereg.fit(X_knowledge_train, y_train)\n","\n","#predict \n","pred1 = reg1.predict(X_knowledge_test)\n","pred2 = reg2.predict(X_knowledge_test)\n","pred3 = reg3.predict(X_knowledge_test)\n","pred4 = ereg.predict(X_knowledge_test)\n","\n","#plot\n","plt.figure()\n","plt.plot(pred1, \"gd\", label=\"GradientBoostingRegressor\")\n","plt.plot(pred2, \"b^\", label=\"RandomForestRegressor\")\n","plt.plot(pred3, \"ys\", label=\"LinearRegression\")\n","plt.plot(pred4, \"r*\", ms=10, label=\"VotingRegressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"training samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions and their average - Depression\")\n","plt.setp(plt.gca(),ylim=(0,100))\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":640},"executionInfo":{"status":"ok","timestamp":1659724939828,"user_tz":240,"elapsed":2577,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"4fa6ee0a-25ae-442b-80ff-50a084b78f97","id":"BwCVddB70lkg"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","5 fits failed out of a total of 5.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","5 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1516, in fit\n","    check_classification_targets(y)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 197, in check_classification_targets\n","    raise ValueError(\"Unknown label type: %r\" % y_type)\n","ValueError: Unknown label type: 'continuous'\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Cross Validation Scores are [nan nan nan nan nan]\n","Average Cross Validation score :nan\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["#chose five models to train the data with to see which performs the best : Linear Regression and Support Vector Regression\n","pipe_lr = Pipeline([('LR', LinearRegression())])\n","pipe_svm = Pipeline([('SVM', SVR())])\n","pipe_rfr = Pipeline([('RFR', RandomForestRegressor())])\n","pipe_dtr = Pipeline([('DTR', DecisionTreeRegressor())])\n","pipe_gbr = Pipeline([('DTR', GradientBoostingRegressor())])\n","\n","#create GridSearch parameters\n","\n","#creates lists to pass into the grid below\n","C = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n","epsilon = [0, 0.01, 0.1, 0.5, 1, 2, 4, 5]\n","n_estimators = [50,100,150, 200, 300, 500,1000, 1500]\n","n_jobs = np.array([1, 10, 100, 290, 500])\n","bootstrap = [True, False]\n","max_depth = [3,4,6,8,10]\n","min_samples_split = [10,20,40]\n","max_depth = [2, 6, 8]\n","min_samples_leaf = [20, 40, 100]\n","max_leaf_nodes = [5, 20, 100]\n","learning_rate = [0.01,0.02,0.03,0.04]\n","subsample = [0.9, 0.5, 0.2, 0.1]\n","\n","#these will be passed to the GridSearchCV function below -> which will take a pipeline model and test out each paramter value passed through in the following parameter list\n","lr_space = [{'fit_intercept': ['svd'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['cholesky'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['lsqr'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sparse_cg'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sag'],  'n_jobs' : n_jobs},\n","         {'fit_intercept': ['saga'], 'n_jobs' : n_jobs}]\n","\n","svr_space = [{'kernel': ['linear'], 'C' : C, 'epsilon' : epsilon},\n","         {'kernel': ['rbf'], 'C' : C, 'gamma' : C, 'epsilon' : epsilon}]\n","\n","rfr_space = [{'max_features' : [\"auto\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"sqrt\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"log2\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","dtr_space = [{'criterion': ['mse'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes},\n","         {'criterion': ['absolute_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes}]\n","\n","gbr_space = [{'learning_rate': learning_rate, 'subsample' : subsample, 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","\n","\n","##use the GridSearchCV function and pass in both the pipeline created above and the frid parameters \n","\n","#pass in cv=3 for the fridsearch to perform cross-validation on our training set\n","#pass score = accuracy for get the accrucay score when the test is performed \n","lr_gs = GridSearchCV(LinearRegression(), param_grid = lr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","svm_gs = GridSearchCV(SVR(), param_grid = svr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","rfr_gs = GridSearchCV(RandomForestRegressor(), param_grid = rfr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","dtr_gs = GridSearchCV(DecisionTreeRegressor(), param_grid = dtr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","gbr_gs = GridSearchCV(GradientBoostingRegressor(), param_grid = gbr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","\n","lr_grids = [lr_gs]\n","\n","for lr_pipe in lr_grids:\n","    lr_pipe.fit(X_knowledge_train,y_train)\n","\n","svm_grids = [svm_gs]\n","\n","for svm_pipe in svm_grids:\n","    svm_pipe.fit(X_knowledge_train,y_train)\n","\n","rfr_grids = [rfr_gs]\n","\n","for rfr_pipe in rfr_grids:\n","    rfr_pipe.fit(X_knowledge_train,y_train)\n","\n","dtr_grids = [dtr_gs]\n","\n","for dtr_pipe in dtr_grids:\n","    dtr_pipe.fit(X_knowledge_train,y_train)\n","\n","gbr_grids = [gbr_gs]\n","\n","for gbr_pipe in gbr_grids:\n","    gbr_pipe.fit(X_knowledge_train,y_train)"],"metadata":{"id":"lRtsE7Bq0lkg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#first create a dictionary that contains the classifier types to used int eh for loop. \n","lr_grid_dict = {0: 'Linear Regression'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(lr_grids):\n","    print('{} Train R_Square: {}'.format(lr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","lr_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,lr_y_pred)*100\n","\n","for i, model in enumerate(lr_grids):\n","    print('{} Test R_Square: {}'.format(lr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","svm_grid_dict = {0: 'Support Vector Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(svm_grids):\n","    print('{} Train R_Square: {}'.format(svm_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","svm_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,svm_y_pred)*100\n","\n","for i, model in enumerate(svm_grids):\n","    print('{} Test R_Square: {}'.format(svm_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          results.best_params_))\n","    \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","rfr_grid_dict = {0: 'Random Forest Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(rfr_grids):\n","    print('{} Train R_Square: {}'.format(rfr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","rf_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,rf_y_pred)*100\n","\n","for i, model in enumerate(rfr_grids):\n","    print('{} Test R_Square: {}'.format(rfr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","dtr_grid_dict = {0: 'Decision Tree Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(dtr_grids):\n","    print('{} Train R_Square: {}'.format(dtr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","dtr_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,dtr_y_pred)*100\n","\n","for i, model in enumerate(dtr_grids):\n","    print('{} Test R_Square: {}'.format(dtr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","gbr_grid_dict = {0: 'Gradient Boosting Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(gbr_grids):\n","    print('{} Train R_Square: {}'.format(gbr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","gbr_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,gbr_y_pred)*100\n","\n","for i, model in enumerate(gbr_grids):\n","    print('{} Test R_Square: {}'.format(gbr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          results.best_params_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":592},"executionInfo":{"status":"error","timestamp":1659726446747,"user_tz":240,"elapsed":329,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"ce5abbb0-34da-4c3e-c4d7-0a55fe99180e","id":"tPsTuLqF0lkg"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n","Feature names unseen at fit time:\n","- Abdominal distension\n","- Abdominal hernia\n","- Abdominal pain\n","- Abortion spontaneous\n","- Accepts_Healthy_volunteers\n","- ...\n","Feature names must be in the same order as they were in fit.\n","\n","  warnings.warn(message, FutureWarning)\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-93-d716c58a4f93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#then create a for loop to train them all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_grids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Train R_Square: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_grid_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Best Params: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_grid_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;31m# callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimetric_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         )\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \"\"\"\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod_caller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return self._sign * self._score_func(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;34m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \"\"\"\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise ValueError(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: X has 334 features, but LinearRegression is expecting 20 features as input."]}]},{"cell_type":"code","source":["#plot predictions \n","plt.figure()\n","plt.plot(lr_y_pred, \"gd\", label=\"Linear Regression\")\n","plt.plot(svm_y_pred, \"b^\", label=\"Support Vector Regressor\")\n","plt.plot(rf_y_pred, \"ys\", label=\"Random Forest Regressor\")\n","plt.plot(dtr_y_pred, \"r*\", ms=10, label=\"Decision Tree Regressor\")\n","plt.plot(gbr_y_pred, \"bs\", label=\"Gradient Boosting Regressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"Training Samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions - Knowledge Based Feature Selection - Depression\")\n","plt.setp(plt.gca(),ylim=(0,100))"],"metadata":{"id":"EVAJ1G3s0lkg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q11wWX3xFSgE"},"source":["## Alzheimer's Disease"]},{"cell_type":"markdown","metadata":{"id":"sFJoIRa54KXm"},"source":["### Subset Alzheimer's Disease Studies / Split into test and train sets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"afubHaTM4KXn"},"outputs":[],"source":["V4_alzheimers_df = V4_master_df[V4_master_df['disease_type'] == \"Alzheimer's Disease\"]\n","V4_alzheimers_df = V4_alzheimers_df.drop(columns=['disease_type', 'intervention_model_type_Sequential Assignment'])\n","\n","#split into features and outcome dataframes\n","X_df = V4_alzheimers_df.drop(columns=['percent_attrition'])\n","y_df = V4_alzheimers_df.percent_attrition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W0yubGw74KXn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896658095,"user_tz":240,"elapsed":3,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"4e49bf8f-a2e7-4a79-ab93-53e0dd2d5a52"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((154, 2010), (39, 2010))"]},"metadata":{},"execution_count":188}],"source":["# Train/test split:\n","X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size = 0.2, random_state = 2)\n","\n","X_train.shape, X_test.shape"]},{"cell_type":"code","source":["#select all ae columns\n","ae_df = X_df.iloc[:,9:1962]\n","\n","#replace all non zero cells with 1\n","ae_df[ae_df != 0] = 1\n","\n","#add all columns and select the top ten most prevelant\n","s = ae_df.sum()\n","top_ae_table = ae_df[s.sort_values(ascending=False).index[:10]]\n","\n","#generated list of most prevelant ae\n","top_ae_table_list = list(top_ae_table.columns)"],"metadata":{"id":"T2tg8nWCoh7M"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Px_iVicHcIo1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896658235,"user_tz":240,"elapsed":141,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"06ae03b8-ae13-4ccc-b26a-fca3119e5610"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  dropout_reason_consent withdrawn  \\\n","269                           0.0                               0.0   \n","271                           0.0                               0.0   \n","316                           0.0                               0.0   \n","318                           0.0                               0.0   \n","325                           0.0                               0.0   \n","..                            ...                               ...   \n","611                           0.0                               0.0   \n","612                           0.0                               0.0   \n","613                           0.0                               0.0   \n","614                           0.0                               0.0   \n","615                           0.0                               0.0   \n","\n","     dropout_reason_death  dropout_reason_inclusion/exclusion criteria issue  \\\n","269                   0.0                                                2.0   \n","271                   0.0                                                2.0   \n","316                   0.0                                                0.0   \n","318                   0.0                                                0.0   \n","325                   1.0                                               26.0   \n","..                    ...                                                ...   \n","611                   0.0                                                0.0   \n","612                   0.0                                                0.0   \n","613                   0.0                                                0.0   \n","614                   0.0                                                0.0   \n","615                   0.0                                                3.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","269                              0.0                               0.0   \n","271                              0.0                               0.0   \n","316                              0.0                               0.0   \n","318                              0.0                               0.0   \n","325                              0.0                              24.0   \n","..                               ...                               ...   \n","611                              0.0                               0.0   \n","612                              0.0                               3.0   \n","613                              0.0                               0.0   \n","614                              0.0                               2.0   \n","615                              0.0                               0.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","269                                2.0                                0.0   \n","271                                2.0                                0.0   \n","316                                5.0                                0.0   \n","318                                5.0                                0.0   \n","325                                0.0                                0.0   \n","..                                 ...                                ...   \n","611                                0.0                                0.0   \n","612                                0.0                                0.0   \n","613                                0.0                                0.0   \n","614                                3.0                                1.0   \n","615                                0.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Influenza  ...  \\\n","269                                5.0        0.0  ...   \n","271                                5.0        0.0  ...   \n","316                                5.0        0.0  ...   \n","318                                5.0        0.0  ...   \n","325                               21.0        0.0  ...   \n","..                                 ...        ...  ...   \n","611                                2.0        0.0  ...   \n","612                                1.0        0.0  ...   \n","613                                1.0        0.0  ...   \n","614                                7.0        0.0  ...   \n","615                                2.0        0.0  ...   \n","\n","     allocation_type_Not Reported  allocation_type_Randomized  \\\n","269                             1                           0   \n","271                             1                           0   \n","316                             1                           0   \n","318                             1                           0   \n","325                             0                           1   \n","..                            ...                         ...   \n","611                             0                           0   \n","612                             0                           1   \n","613                             0                           1   \n","614                             0                           0   \n","615                             0                           0   \n","\n","     masking_type_Double  masking_type_None (Open Label)  \\\n","269                    0                               1   \n","271                    0                               1   \n","316                    0                               1   \n","318                    0                               1   \n","325                    0                               0   \n","..                   ...                             ...   \n","611                    0                               1   \n","612                    1                               0   \n","613                    0                               0   \n","614                    0                               1   \n","615                    0                               1   \n","\n","     masking_type_Not Reported  masking_type_Quadruple  masking_type_Single  \\\n","269                          0                       0                    0   \n","271                          0                       0                    0   \n","316                          0                       0                    0   \n","318                          0                       0                    0   \n","325                          0                       0                    1   \n","..                         ...                     ...                  ...   \n","611                          0                       0                    0   \n","612                          0                       0                    0   \n","613                          0                       1                    0   \n","614                          0                       0                    0   \n","615                          0                       0                    0   \n","\n","     masking_type_Triple  study_gender_eligibility_All  \\\n","269                    0                             1   \n","271                    0                             1   \n","316                    0                             1   \n","318                    0                             1   \n","325                    0                             1   \n","..                   ...                           ...   \n","611                    0                             1   \n","612                    0                             0   \n","613                    0                             1   \n","614                    0                             1   \n","615                    0                             1   \n","\n","     study_gender_eligibility_Male  \n","269                              0  \n","271                              0  \n","316                              0  \n","318                              0  \n","325                              0  \n","..                             ...  \n","611                              0  \n","612                              1  \n","613                              0  \n","614                              0  \n","615                              0  \n","\n","[193 rows x 1113 columns]"],"text/html":["\n","  <div id=\"df-ec125631-54fc-4251-bf72-01da3487bd7f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>...</th>\n","      <th>allocation_type_Not Reported</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Not Reported</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>269</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>271</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>316</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>318</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>325</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>26.0</td>\n","      <td>0.0</td>\n","      <td>24.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>21.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>611</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>612</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>613</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>614</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>615</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>193 rows × 1113 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec125631-54fc-4251-bf72-01da3487bd7f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ec125631-54fc-4251-bf72-01da3487bd7f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ec125631-54fc-4251-bf72-01da3487bd7f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":190}],"source":["X_df = X_df.loc[:, (X_df != 0).any(axis=0)]\n","X_df"]},{"cell_type":"markdown","metadata":{"id":"FIPk2M3BOrUe"},"source":["### Colinearity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"65W8Qzk8OrUe"},"outputs":[],"source":["from statsmodels.stats.outliers_influence import variance_inflation_factor    \n","\n","def calculate_vif_(X_df, thresh=4.0):\n","    variables = list(range(X_df.shape[1]))\n","    dropped = True\n","    while dropped:\n","        dropped = False\n","        vif = [variance_inflation_factor(X_df.iloc[:, variables].values, ix)\n","               for ix in range(X_df.iloc[:, variables].shape[1])]\n","\n","        maxloc = vif.index(max(vif))\n","        if max(vif) > thresh:\n","            print('dropping \\'' + X_df.iloc[:, variables].columns[maxloc] +\n","                  '\\' at index: ' + str(maxloc))\n","            del variables[maxloc]\n","            dropped = True\n","\n","    print('Remaining variables:')\n","    print(X_df.columns[variables])\n","    return X_df.iloc[:, variables]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0eh7DWUmOrUe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896658865,"user_tz":240,"elapsed":176,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"8c3e799c-19ba-48ea-da42-897158ac4fa8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  dropout_reason_consent withdrawn  \\\n","269                           0.0                               0.0   \n","271                           0.0                               0.0   \n","316                           0.0                               0.0   \n","318                           0.0                               0.0   \n","325                           0.0                               0.0   \n","..                            ...                               ...   \n","611                           0.0                               0.0   \n","612                           0.0                               0.0   \n","613                           0.0                               0.0   \n","614                           0.0                               0.0   \n","615                           0.0                               0.0   \n","\n","     dropout_reason_death  dropout_reason_inclusion/exclusion criteria issue  \\\n","269                   0.0                                                2.0   \n","271                   0.0                                                2.0   \n","316                   0.0                                                0.0   \n","318                   0.0                                                0.0   \n","325                   1.0                                               26.0   \n","..                    ...                                                ...   \n","611                   0.0                                                0.0   \n","612                   0.0                                                0.0   \n","613                   0.0                                                0.0   \n","614                   0.0                                                0.0   \n","615                   0.0                                                3.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","269                              0.0                               0.0   \n","271                              0.0                               0.0   \n","316                              0.0                               0.0   \n","318                              0.0                               0.0   \n","325                              0.0                              24.0   \n","..                               ...                               ...   \n","611                              0.0                               0.0   \n","612                              0.0                               3.0   \n","613                              0.0                               0.0   \n","614                              0.0                               2.0   \n","615                              0.0                               0.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","269                                2.0                                0.0   \n","271                                2.0                                0.0   \n","316                                5.0                                0.0   \n","318                                5.0                                0.0   \n","325                                0.0                                0.0   \n","..                                 ...                                ...   \n","611                                0.0                                0.0   \n","612                                0.0                                0.0   \n","613                                0.0                                0.0   \n","614                                3.0                                1.0   \n","615                                0.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Influenza  ...  \\\n","269                                5.0        0.0  ...   \n","271                                5.0        0.0  ...   \n","316                                5.0        0.0  ...   \n","318                                5.0        0.0  ...   \n","325                               21.0        0.0  ...   \n","..                                 ...        ...  ...   \n","611                                2.0        0.0  ...   \n","612                                1.0        0.0  ...   \n","613                                1.0        0.0  ...   \n","614                                7.0        0.0  ...   \n","615                                2.0        0.0  ...   \n","\n","     allocation_type_Not Reported  allocation_type_Randomized  \\\n","269                             1                           0   \n","271                             1                           0   \n","316                             1                           0   \n","318                             1                           0   \n","325                             0                           1   \n","..                            ...                         ...   \n","611                             0                           0   \n","612                             0                           1   \n","613                             0                           1   \n","614                             0                           0   \n","615                             0                           0   \n","\n","     masking_type_Double  masking_type_None (Open Label)  \\\n","269                    0                               1   \n","271                    0                               1   \n","316                    0                               1   \n","318                    0                               1   \n","325                    0                               0   \n","..                   ...                             ...   \n","611                    0                               1   \n","612                    1                               0   \n","613                    0                               0   \n","614                    0                               1   \n","615                    0                               1   \n","\n","     masking_type_Not Reported  masking_type_Quadruple  masking_type_Single  \\\n","269                          0                       0                    0   \n","271                          0                       0                    0   \n","316                          0                       0                    0   \n","318                          0                       0                    0   \n","325                          0                       0                    1   \n","..                         ...                     ...                  ...   \n","611                          0                       0                    0   \n","612                          0                       0                    0   \n","613                          0                       1                    0   \n","614                          0                       0                    0   \n","615                          0                       0                    0   \n","\n","     masking_type_Triple  study_gender_eligibility_All  \\\n","269                    0                             1   \n","271                    0                             1   \n","316                    0                             1   \n","318                    0                             1   \n","325                    0                             1   \n","..                   ...                           ...   \n","611                    0                             1   \n","612                    0                             0   \n","613                    0                             1   \n","614                    0                             1   \n","615                    0                             1   \n","\n","     study_gender_eligibility_Male  \n","269                              0  \n","271                              0  \n","316                              0  \n","318                              0  \n","325                              0  \n","..                             ...  \n","611                              0  \n","612                              1  \n","613                              0  \n","614                              0  \n","615                              0  \n","\n","[193 rows x 1113 columns]"],"text/html":["\n","  <div id=\"df-69c13dcb-2208-4716-8356-8ff58cec724b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>...</th>\n","      <th>allocation_type_Not Reported</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Not Reported</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>269</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>271</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>316</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>318</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>325</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>26.0</td>\n","      <td>0.0</td>\n","      <td>24.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>21.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>611</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>612</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>613</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>614</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>615</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>193 rows × 1113 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69c13dcb-2208-4716-8356-8ff58cec724b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-69c13dcb-2208-4716-8356-8ff58cec724b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-69c13dcb-2208-4716-8356-8ff58cec724b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":192}],"source":["X_df"]},{"cell_type":"markdown","metadata":{"id":"kNSrIeTic2DO"},"source":["### Corelated Feature Drop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WUho-45Sc2DO","colab":{"base_uri":"https://localhost:8080/","height":334},"executionInfo":{"status":"ok","timestamp":1659896660433,"user_tz":240,"elapsed":1141,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"b01ba392-32b6-41ca-a39e-3e260d2c9a1f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   dropout_reason_adverse event  \\\n","dropout_reason_adverse event                                           1.000000   \n","dropout_reason_consent withdrawn                                       0.237846   \n","dropout_reason_death                                                   0.298972   \n","dropout_reason_inclusion/exclusion criteria issue                      0.565721   \n","dropout_reason_lack of efficacy                                        0.197587   \n","\n","                                                   dropout_reason_consent withdrawn  \\\n","dropout_reason_adverse event                                               0.237846   \n","dropout_reason_consent withdrawn                                           1.000000   \n","dropout_reason_death                                                       0.138402   \n","dropout_reason_inclusion/exclusion criteria issue                          0.370100   \n","dropout_reason_lack of efficacy                                            0.080904   \n","\n","                                                   dropout_reason_death  \\\n","dropout_reason_adverse event                                   0.298972   \n","dropout_reason_consent withdrawn                               0.138402   \n","dropout_reason_death                                           1.000000   \n","dropout_reason_inclusion/exclusion criteria issue              0.181400   \n","dropout_reason_lack of efficacy                                0.086247   \n","\n","                                                   dropout_reason_inclusion/exclusion criteria issue  \\\n","dropout_reason_adverse event                                                                0.565721   \n","dropout_reason_consent withdrawn                                                            0.370100   \n","dropout_reason_death                                                                        0.181400   \n","dropout_reason_inclusion/exclusion criteria issue                                           1.000000   \n","dropout_reason_lack of efficacy                                                             0.163769   \n","\n","                                                   dropout_reason_lack of efficacy  \\\n","dropout_reason_adverse event                                              0.197587   \n","dropout_reason_consent withdrawn                                          0.080904   \n","dropout_reason_death                                                      0.086247   \n","dropout_reason_inclusion/exclusion criteria issue                         0.163769   \n","dropout_reason_lack of efficacy                                           1.000000   \n","\n","                                                   dropout_reason_lost to follow-up  \\\n","dropout_reason_adverse event                                               0.224658   \n","dropout_reason_consent withdrawn                                           0.055113   \n","dropout_reason_death                                                       0.162898   \n","dropout_reason_inclusion/exclusion criteria issue                          0.202686   \n","dropout_reason_lack of efficacy                                            0.046159   \n","\n","                                                   dropout_reason_physician decision  \\\n","dropout_reason_adverse event                                                0.240606   \n","dropout_reason_consent withdrawn                                           -0.012491   \n","dropout_reason_death                                                        0.227897   \n","dropout_reason_inclusion/exclusion criteria issue                           0.025720   \n","dropout_reason_lack of efficacy                                            -0.012844   \n","\n","                                                   dropout_reason_protocol violation  \\\n","dropout_reason_adverse event                                                0.589975   \n","dropout_reason_consent withdrawn                                            0.065628   \n","dropout_reason_death                                                        0.138321   \n","dropout_reason_inclusion/exclusion criteria issue                           0.089250   \n","dropout_reason_lack of efficacy                                            -0.007926   \n","\n","                                                   dropout_reason_subject withdrawal  \\\n","dropout_reason_adverse event                                                0.588069   \n","dropout_reason_consent withdrawn                                            0.000652   \n","dropout_reason_death                                                        0.464115   \n","dropout_reason_inclusion/exclusion criteria issue                           0.409613   \n","dropout_reason_lack of efficacy                                             0.128763   \n","\n","                                                   Influenza  ...  \\\n","dropout_reason_adverse event                        0.003276  ...   \n","dropout_reason_consent withdrawn                   -0.007568  ...   \n","dropout_reason_death                                0.069795  ...   \n","dropout_reason_inclusion/exclusion criteria issue   0.056653  ...   \n","dropout_reason_lack of efficacy                    -0.001321  ...   \n","\n","                                                   allocation_type_Not Reported  \\\n","dropout_reason_adverse event                                          -0.080608   \n","dropout_reason_consent withdrawn                                      -0.062143   \n","dropout_reason_death                                                  -0.012952   \n","dropout_reason_inclusion/exclusion criteria issue                     -0.054126   \n","dropout_reason_lack of efficacy                                        0.086281   \n","\n","                                                   allocation_type_Randomized  \\\n","dropout_reason_adverse event                                         0.123205   \n","dropout_reason_consent withdrawn                                     0.090372   \n","dropout_reason_death                                                 0.067144   \n","dropout_reason_inclusion/exclusion criteria issue                    0.086368   \n","dropout_reason_lack of efficacy                                     -0.060349   \n","\n","                                                   masking_type_Double  \\\n","dropout_reason_adverse event                                 -0.044521   \n","dropout_reason_consent withdrawn                              0.030074   \n","dropout_reason_death                                         -0.061548   \n","dropout_reason_inclusion/exclusion criteria issue            -0.055511   \n","dropout_reason_lack of efficacy                              -0.033337   \n","\n","                                                   masking_type_None (Open Label)  \\\n","dropout_reason_adverse event                                            -0.081317   \n","dropout_reason_consent withdrawn                                        -0.085003   \n","dropout_reason_death                                                     0.006551   \n","dropout_reason_inclusion/exclusion criteria issue                       -0.065199   \n","dropout_reason_lack of efficacy                                          0.077214   \n","\n","                                                   masking_type_Not Reported  \\\n","dropout_reason_adverse event                                       -0.014257   \n","dropout_reason_consent withdrawn                                   -0.023521   \n","dropout_reason_death                                               -0.018748   \n","dropout_reason_inclusion/exclusion criteria issue                  -0.033962   \n","dropout_reason_lack of efficacy                                    -0.009485   \n","\n","                                                   masking_type_Quadruple  \\\n","dropout_reason_adverse event                                     0.137459   \n","dropout_reason_consent withdrawn                                 0.138742   \n","dropout_reason_death                                             0.111885   \n","dropout_reason_inclusion/exclusion criteria issue                0.139876   \n","dropout_reason_lack of efficacy                                  0.030435   \n","\n","                                                   masking_type_Single  \\\n","dropout_reason_adverse event                                 -0.103984   \n","dropout_reason_consent withdrawn                             -0.033621   \n","dropout_reason_death                                         -0.035637   \n","dropout_reason_inclusion/exclusion criteria issue            -0.049354   \n","dropout_reason_lack of efficacy                              -0.042828   \n","\n","                                                   masking_type_Triple  \\\n","dropout_reason_adverse event                                  0.033563   \n","dropout_reason_consent withdrawn                             -0.075278   \n","dropout_reason_death                                         -0.050367   \n","dropout_reason_inclusion/exclusion criteria issue             0.003190   \n","dropout_reason_lack of efficacy                              -0.062107   \n","\n","                                                   study_gender_eligibility_All  \\\n","dropout_reason_adverse event                                           0.036087   \n","dropout_reason_consent withdrawn                                       0.011668   \n","dropout_reason_death                                                   0.020343   \n","dropout_reason_inclusion/exclusion criteria issue                      0.021433   \n","dropout_reason_lack of efficacy                                        0.014863   \n","\n","                                                   study_gender_eligibility_Male  \n","dropout_reason_adverse event                                           -0.036087  \n","dropout_reason_consent withdrawn                                       -0.011668  \n","dropout_reason_death                                                   -0.020343  \n","dropout_reason_inclusion/exclusion criteria issue                      -0.021433  \n","dropout_reason_lack of efficacy                                        -0.014863  \n","\n","[5 rows x 1113 columns]"],"text/html":["\n","  <div id=\"df-c5f069c0-aced-4fe5-91da-eb24d50dc2d5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>...</th>\n","      <th>allocation_type_Not Reported</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Not Reported</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>dropout_reason_adverse event</th>\n","      <td>1.000000</td>\n","      <td>0.237846</td>\n","      <td>0.298972</td>\n","      <td>0.565721</td>\n","      <td>0.197587</td>\n","      <td>0.224658</td>\n","      <td>0.240606</td>\n","      <td>0.589975</td>\n","      <td>0.588069</td>\n","      <td>0.003276</td>\n","      <td>...</td>\n","      <td>-0.080608</td>\n","      <td>0.123205</td>\n","      <td>-0.044521</td>\n","      <td>-0.081317</td>\n","      <td>-0.014257</td>\n","      <td>0.137459</td>\n","      <td>-0.103984</td>\n","      <td>0.033563</td>\n","      <td>0.036087</td>\n","      <td>-0.036087</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <td>0.237846</td>\n","      <td>1.000000</td>\n","      <td>0.138402</td>\n","      <td>0.370100</td>\n","      <td>0.080904</td>\n","      <td>0.055113</td>\n","      <td>-0.012491</td>\n","      <td>0.065628</td>\n","      <td>0.000652</td>\n","      <td>-0.007568</td>\n","      <td>...</td>\n","      <td>-0.062143</td>\n","      <td>0.090372</td>\n","      <td>0.030074</td>\n","      <td>-0.085003</td>\n","      <td>-0.023521</td>\n","      <td>0.138742</td>\n","      <td>-0.033621</td>\n","      <td>-0.075278</td>\n","      <td>0.011668</td>\n","      <td>-0.011668</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_death</th>\n","      <td>0.298972</td>\n","      <td>0.138402</td>\n","      <td>1.000000</td>\n","      <td>0.181400</td>\n","      <td>0.086247</td>\n","      <td>0.162898</td>\n","      <td>0.227897</td>\n","      <td>0.138321</td>\n","      <td>0.464115</td>\n","      <td>0.069795</td>\n","      <td>...</td>\n","      <td>-0.012952</td>\n","      <td>0.067144</td>\n","      <td>-0.061548</td>\n","      <td>0.006551</td>\n","      <td>-0.018748</td>\n","      <td>0.111885</td>\n","      <td>-0.035637</td>\n","      <td>-0.050367</td>\n","      <td>0.020343</td>\n","      <td>-0.020343</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <td>0.565721</td>\n","      <td>0.370100</td>\n","      <td>0.181400</td>\n","      <td>1.000000</td>\n","      <td>0.163769</td>\n","      <td>0.202686</td>\n","      <td>0.025720</td>\n","      <td>0.089250</td>\n","      <td>0.409613</td>\n","      <td>0.056653</td>\n","      <td>...</td>\n","      <td>-0.054126</td>\n","      <td>0.086368</td>\n","      <td>-0.055511</td>\n","      <td>-0.065199</td>\n","      <td>-0.033962</td>\n","      <td>0.139876</td>\n","      <td>-0.049354</td>\n","      <td>0.003190</td>\n","      <td>0.021433</td>\n","      <td>-0.021433</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <td>0.197587</td>\n","      <td>0.080904</td>\n","      <td>0.086247</td>\n","      <td>0.163769</td>\n","      <td>1.000000</td>\n","      <td>0.046159</td>\n","      <td>-0.012844</td>\n","      <td>-0.007926</td>\n","      <td>0.128763</td>\n","      <td>-0.001321</td>\n","      <td>...</td>\n","      <td>0.086281</td>\n","      <td>-0.060349</td>\n","      <td>-0.033337</td>\n","      <td>0.077214</td>\n","      <td>-0.009485</td>\n","      <td>0.030435</td>\n","      <td>-0.042828</td>\n","      <td>-0.062107</td>\n","      <td>0.014863</td>\n","      <td>-0.014863</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 1113 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5f069c0-aced-4fe5-91da-eb24d50dc2d5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c5f069c0-aced-4fe5-91da-eb24d50dc2d5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c5f069c0-aced-4fe5-91da-eb24d50dc2d5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":193}],"source":["df_corr = X_df.corr()\n","df_corr.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HYGzqiSwc2DP"},"outputs":[],"source":["threshold = 0.9\n","\n","\n","columns = np.full((df_corr.shape[0],), True, dtype=bool)\n","for i in range(df_corr.shape[0]):\n","    for j in range(i+1, df_corr.shape[0]):\n","        if df_corr.iloc[i,j] >= threshold:\n","            if columns[j]:\n","                columns[j] = False\n","selected_columns = X_df.columns[columns]\n","selected_columns\n","X_df = X_df[selected_columns]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h14KwSHEc2DP","colab":{"base_uri":"https://localhost:8080/","height":505},"executionInfo":{"status":"ok","timestamp":1659896707972,"user_tz":240,"elapsed":12,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"bc5975fc-84ac-4cbf-f64f-7dd03c1e90d4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  dropout_reason_consent withdrawn  \\\n","269                           0.0                               0.0   \n","271                           0.0                               0.0   \n","316                           0.0                               0.0   \n","318                           0.0                               0.0   \n","325                           0.0                               0.0   \n","..                            ...                               ...   \n","611                           0.0                               0.0   \n","612                           0.0                               0.0   \n","613                           0.0                               0.0   \n","614                           0.0                               0.0   \n","615                           0.0                               0.0   \n","\n","     dropout_reason_death  dropout_reason_inclusion/exclusion criteria issue  \\\n","269                   0.0                                                2.0   \n","271                   0.0                                                2.0   \n","316                   0.0                                                0.0   \n","318                   0.0                                                0.0   \n","325                   1.0                                               26.0   \n","..                    ...                                                ...   \n","611                   0.0                                                0.0   \n","612                   0.0                                                0.0   \n","613                   0.0                                                0.0   \n","614                   0.0                                                0.0   \n","615                   0.0                                                3.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","269                              0.0                               0.0   \n","271                              0.0                               0.0   \n","316                              0.0                               0.0   \n","318                              0.0                               0.0   \n","325                              0.0                              24.0   \n","..                               ...                               ...   \n","611                              0.0                               0.0   \n","612                              0.0                               3.0   \n","613                              0.0                               0.0   \n","614                              0.0                               2.0   \n","615                              0.0                               0.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","269                                2.0                                0.0   \n","271                                2.0                                0.0   \n","316                                5.0                                0.0   \n","318                                5.0                                0.0   \n","325                                0.0                                0.0   \n","..                                 ...                                ...   \n","611                                0.0                                0.0   \n","612                                0.0                                0.0   \n","613                                0.0                                0.0   \n","614                                3.0                                1.0   \n","615                                0.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Influenza  ...  \\\n","269                                5.0        0.0  ...   \n","271                                5.0        0.0  ...   \n","316                                5.0        0.0  ...   \n","318                                5.0        0.0  ...   \n","325                               21.0        0.0  ...   \n","..                                 ...        ...  ...   \n","611                                2.0        0.0  ...   \n","612                                1.0        0.0  ...   \n","613                                1.0        0.0  ...   \n","614                                7.0        0.0  ...   \n","615                                2.0        0.0  ...   \n","\n","     allocation_type_Non-Randomized  allocation_type_Not Reported  \\\n","269                               0                             1   \n","271                               0                             1   \n","316                               0                             1   \n","318                               0                             1   \n","325                               0                             0   \n","..                              ...                           ...   \n","611                               1                             0   \n","612                               0                             0   \n","613                               0                             0   \n","614                               1                             0   \n","615                               1                             0   \n","\n","     allocation_type_Randomized  masking_type_Double  \\\n","269                           0                    0   \n","271                           0                    0   \n","316                           0                    0   \n","318                           0                    0   \n","325                           1                    0   \n","..                          ...                  ...   \n","611                           0                    0   \n","612                           1                    1   \n","613                           1                    0   \n","614                           0                    0   \n","615                           0                    0   \n","\n","     masking_type_None (Open Label)  masking_type_Quadruple  \\\n","269                               1                       0   \n","271                               1                       0   \n","316                               1                       0   \n","318                               1                       0   \n","325                               0                       0   \n","..                              ...                     ...   \n","611                               1                       0   \n","612                               0                       0   \n","613                               0                       1   \n","614                               1                       0   \n","615                               1                       0   \n","\n","     masking_type_Single  masking_type_Triple  study_gender_eligibility_All  \\\n","269                    0                    0                             1   \n","271                    0                    0                             1   \n","316                    0                    0                             1   \n","318                    0                    0                             1   \n","325                    1                    0                             1   \n","..                   ...                  ...                           ...   \n","611                    0                    0                             1   \n","612                    0                    0                             0   \n","613                    0                    0                             1   \n","614                    0                    0                             1   \n","615                    0                    0                             1   \n","\n","     study_gender_eligibility_Male  \n","269                              0  \n","271                              0  \n","316                              0  \n","318                              0  \n","325                              0  \n","..                             ...  \n","611                              0  \n","612                              1  \n","613                              0  \n","614                              0  \n","615                              0  \n","\n","[193 rows x 555 columns]"],"text/html":["\n","  <div id=\"df-ec7e3adb-22e7-4fc8-b2eb-07dd83a14a6a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>...</th>\n","      <th>allocation_type_Non-Randomized</th>\n","      <th>allocation_type_Not Reported</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>269</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>271</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>316</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>318</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>325</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>26.0</td>\n","      <td>0.0</td>\n","      <td>24.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>21.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>611</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>612</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>613</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>614</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>615</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>193 rows × 555 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec7e3adb-22e7-4fc8-b2eb-07dd83a14a6a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ec7e3adb-22e7-4fc8-b2eb-07dd83a14a6a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ec7e3adb-22e7-4fc8-b2eb-07dd83a14a6a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":195}],"source":["X_df"]},{"cell_type":"markdown","metadata":{"id":"27Xf0hJIc2DP"},"source":["Standardize and split data "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bCN_U5uEc2DP"},"outputs":[],"source":["X_df_norm = (X_df-X_df.min())/(X_df.max()-X_df.min())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JUAGpOndijgq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896708139,"user_tz":240,"elapsed":2,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"c736f3a8-c38a-4d82-9fb9-33d630e89af8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Series([], dtype: object)"]},"metadata":{},"execution_count":197}],"source":["X_df_norm.columns.to_series()[np.isinf(X_df_norm).any()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hIYYZTNDijs8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896708440,"user_tz":240,"elapsed":302,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"639dd071-3523-4f95-a067-668fd542c331"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dropout_reason_adverse event                         0\n","dropout_reason_consent withdrawn                     0\n","dropout_reason_death                                 0\n","dropout_reason_inclusion/exclusion criteria issue    0\n","dropout_reason_lack of efficacy                      0\n","                                                    ..\n","masking_type_Quadruple                               0\n","masking_type_Single                                  0\n","masking_type_Triple                                  0\n","study_gender_eligibility_All                         0\n","study_gender_eligibility_Male                        0\n","Length: 555, dtype: int64"]},"metadata":{},"execution_count":198}],"source":["X_df_norm.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tecUquRZij5x"},"outputs":[],"source":["X_df_norm['study_gender_eligibility_All'] = X_df_norm['study_gender_eligibility_All'].fillna(0)"]},{"cell_type":"code","source":["mean(y_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5RoBdzLjQvY","executionInfo":{"status":"ok","timestamp":1659896708873,"user_tz":240,"elapsed":2,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"2cf49176-ef36-445d-c772-4de1f0e2f52f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30.890330802202524"]},"metadata":{},"execution_count":201}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s5zDQtndc2DP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896708440,"user_tz":240,"elapsed":4,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"1aa10bb4-51fd-43a3-f536-dadc848ea313"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((154, 555), (39, 555))"]},"metadata":{},"execution_count":200}],"source":["# Train/test split:\n","X_train, X_test, y_train, y_test = train_test_split(X_df_norm, y_df, test_size = 0.2, random_state = 2)\n","\n","X_train.shape, X_test.shape"]},{"cell_type":"code","source":[""],"metadata":{"id":"bKIByeFM0qM8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iCdtK4Uw0qTT"},"source":["### Feature Selection"]},{"cell_type":"markdown","metadata":{"id":"sIBBVdYw0qTT"},"source":["#### Feature Importance with Gradient Boosting"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1659890131292,"user_tz":240,"elapsed":178,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4661acf5-1779-49c7-f5d4-3335c78e0fb7","id":"8mhEDV9d0qTT"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4288759363250807"]},"metadata":{},"execution_count":28}],"source":["# GradientBoostingRegressor will be used for feature importance\n","reg_model = GradientBoostingRegressor(random_state=0)   \n","reg_model.fit(X_train, y_train)\n","y_preds = reg_model.predict(X_test)\n","r2_score(y_test, y_preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1659890131293,"user_tz":240,"elapsed":4,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"colab":{"base_uri":"https://localhost:8080/","height":676},"outputId":"a0c48973-a909-4f20-dca5-cf341bbe25e2","id":"qidKbQS90qTT"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   importance\n","dropout_reason_inclusion/exclusion criteria issue    0.318439\n","dropout_reason_lost to follow-up                     0.058545\n","event_type_other                                     0.045327\n","Headache                                             0.040401\n","study_duration_months                                0.038388\n","Abdominal pain                                       0.037683\n","intervention_model_type_Factorial Assignment         0.037326\n","Genetic                                              0.034936\n","Nausea                                               0.028028\n","dropout_reason_adverse event                         0.025854\n","Dissociation                                         0.024618\n","Overdose                                             0.022068\n","dropout_reason_subject withdrawal                    0.017419\n","Glossitis                                            0.017076\n","Major depression                                     0.013135\n","masking_type_Quadruple                               0.012135\n","Lethargy                                             0.011323\n","Tremor                                               0.010559\n","intervention_model_type_Single Group Assignment      0.010132\n","dropout_reason_lack of efficacy                      0.009232"],"text/html":["\n","  <div id=\"df-94066c3e-bb63-41de-87b5-f6560594c6e0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>importance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <td>0.318439</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <td>0.058545</td>\n","    </tr>\n","    <tr>\n","      <th>event_type_other</th>\n","      <td>0.045327</td>\n","    </tr>\n","    <tr>\n","      <th>Headache</th>\n","      <td>0.040401</td>\n","    </tr>\n","    <tr>\n","      <th>study_duration_months</th>\n","      <td>0.038388</td>\n","    </tr>\n","    <tr>\n","      <th>Abdominal pain</th>\n","      <td>0.037683</td>\n","    </tr>\n","    <tr>\n","      <th>intervention_model_type_Factorial Assignment</th>\n","      <td>0.037326</td>\n","    </tr>\n","    <tr>\n","      <th>Genetic</th>\n","      <td>0.034936</td>\n","    </tr>\n","    <tr>\n","      <th>Nausea</th>\n","      <td>0.028028</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_adverse event</th>\n","      <td>0.025854</td>\n","    </tr>\n","    <tr>\n","      <th>Dissociation</th>\n","      <td>0.024618</td>\n","    </tr>\n","    <tr>\n","      <th>Overdose</th>\n","      <td>0.022068</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <td>0.017419</td>\n","    </tr>\n","    <tr>\n","      <th>Glossitis</th>\n","      <td>0.017076</td>\n","    </tr>\n","    <tr>\n","      <th>Major depression</th>\n","      <td>0.013135</td>\n","    </tr>\n","    <tr>\n","      <th>masking_type_Quadruple</th>\n","      <td>0.012135</td>\n","    </tr>\n","    <tr>\n","      <th>Lethargy</th>\n","      <td>0.011323</td>\n","    </tr>\n","    <tr>\n","      <th>Tremor</th>\n","      <td>0.010559</td>\n","    </tr>\n","    <tr>\n","      <th>intervention_model_type_Single Group Assignment</th>\n","      <td>0.010132</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <td>0.009232</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94066c3e-bb63-41de-87b5-f6560594c6e0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-94066c3e-bb63-41de-87b5-f6560594c6e0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-94066c3e-bb63-41de-87b5-f6560594c6e0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":29}],"source":["feature_imp = pd.DataFrame(reg_model.feature_importances_,\n","                                   index = X_train.columns,\n","                                   columns=['importance']).sort_values('importance', ascending=False)\n","\n","feature_imp.head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"axSjIbJw0qTT"},"outputs":[],"source":["#create list of top 30 features\n","boost_top_10 = feature_imp.head(10).index.values\n","boost_top_10_list = list(boost_top_10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2sv1ayxA0qTT"},"outputs":[],"source":["X_boost_df = X_df[X_df.columns.intersection(boost_top_10_list)]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1659890131482,"user_tz":240,"elapsed":3,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9298c539-76d9-4551-f6a0-512d56403e0f","id":"ci0kLhTI0qTT"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((271, 10), (68, 10))"]},"metadata":{},"execution_count":32}],"source":["# Train/test split:\n","X_boost_train, X_boost_test, y_train, y_test = train_test_split(X_boost_df, y_df, test_size = 0.2, random_state = 2)\n","\n","X_boost_train.shape, X_boost_test.shape"]},{"cell_type":"markdown","source":["##### Model Set-up"],"metadata":{"id":"cflGY7kW0qTT"}},{"cell_type":"code","source":["# Continous outcome prediction:\n","\n","def train_and_test(reg_model, X_train, y_train, X_test, y_test):\n","  reg_model.fit(X_train, y_train)\n","  # Make predictions with model\n","  y_pred = reg_model.predict(X_test)\n","  #Metrics\n","  mse_score_val = mean_squared_error(y_test, y_pred)\n","  r2_score_val = r2_score(y_test, y_pred)\n","  return {\"MSE_Score\": mse_score_val, \"R2_Score\": r2_score_val}"],"metadata":{"id":"KMjik7SR0qTT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Linear Regression"],"metadata":{"id":"DCR0R38B0qTU"}},{"cell_type":"code","source":["# Linear Regression:\n","\n","lr_model = LinearRegression()\n","\n","scores = cross_val_score(lr_model, X_boost_train, y_train, scoring='r2', cv=5)\n","scores   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893244224,"user_tz":240,"elapsed":149,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"7e15afcf-dc7e-4be4-9ead-b02e6c00e426","id":"3aECvrCn0qTU"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.52372859,  0.22300902,  0.40490087,  0.28289511,  0.22152235])"]},"metadata":{},"execution_count":104}]},{"cell_type":"code","source":["# k-fold CV (using all the boost variables)\n","train_and_test(lr_model, X_boost_train, y_train, X_boost_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893245438,"user_tz":240,"elapsed":2,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"1580e64d-dfae-49fb-ad3d-97cc49d9cbbc","id":"6tNuzdHk0qTU"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'MSE_Score': 320.12078109174996, 'R2_Score': 0.27008943892479653}"]},"metadata":{},"execution_count":105}]},{"cell_type":"markdown","source":["Random Forest"],"metadata":{"id":"jG_xkler0qTU"}},{"cell_type":"code","source":["# Random Forest Regression:\n","\n","rfr_model = RandomForestRegressor()\n","\n","scores = cross_val_score(rfr_model, X_boost_train, y_train, scoring='r2', cv=5)\n","scores   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893012236,"user_tz":240,"elapsed":2255,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"3379fa3e-f132-4e1a-dfba-ae15c9339c25","id":"_YSoUy3B0qTU"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.21087431, 0.4829302 , 0.49542987, 0.26260168, 0.45673906])"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["\n","train_and_test(rfr_model, X_boost_train, y_train, X_boost_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893013554,"user_tz":240,"elapsed":607,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"44be92a3-36fd-42ca-98b1-f2321d638b9f","id":"fo9l1C6G0qTU"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'MSE_Score': 239.01657569297282, 'R2_Score': 0.455015940310575}"]},"metadata":{},"execution_count":97}]},{"cell_type":"markdown","source":["Gradient Boosting"],"metadata":{"id":"aqdCdrOJ0qTU"}},{"cell_type":"code","source":["# Gradient Boost for feature importance:\n","\n","boost_model = GradientBoostingRegressor(random_state=0)   \n","\n","scores = cross_val_score(boost_model, X_boost_train, y_train, scoring='r2', cv=5)\n","scores   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893141201,"user_tz":240,"elapsed":860,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"cd9eebc5-824a-4f51-d233-07aaff560c52","id":"VEq8foDw0qTU"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.11861583, 0.52141256, 0.46201785, 0.23063168, 0.37609487])"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":["boost_model.fit(X_boost_train, y_train)\n","y_preds = boost_model.predict(X_boost_test)\n","r2_score(y_test, y_preds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893147475,"user_tz":240,"elapsed":316,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"f4bcf021-b3e3-4597-a9f4-494dc6deff67","id":"PvYIAhpT0qTU"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4156543656927092"]},"metadata":{},"execution_count":100}]},{"cell_type":"code","source":["#chose five models to train the data with to see which performs the best : Linear Regression and Support Vector Regression\n","pipe_lr = Pipeline([('LR', LinearRegression())])\n","pipe_svm = Pipeline([('SVM', SVR())])\n","pipe_rfr = Pipeline([('RFR', RandomForestRegressor())])\n","pipe_dtr = Pipeline([('DTR', DecisionTreeRegressor())])\n","pipe_gbr = Pipeline([('DTR', GradientBoostingRegressor())])\n","\n","#create GridSearch parameters\n","\n","#creates lists to pass into the grid below\n","C = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n","epsilon = [0, 0.01, 0.1, 0.5, 1, 2, 4, 5]\n","n_estimators = [50,100,150, 200, 300, 500,1000, 1500]\n","n_jobs = np.array([1, 10, 100, 290, 500])\n","bootstrap = [True, False]\n","max_depth = [3,4,6,8,10]\n","min_samples_split = [10,20,40]\n","max_depth = [2, 6, 8]\n","min_samples_leaf = [20, 40, 100]\n","max_leaf_nodes = [5, 20, 100]\n","learning_rate = [0.01,0.02,0.03,0.04]\n","subsample = [0.9, 0.5, 0.2, 0.1]\n","\n","#these will be passed to the GridSearchCV function below -> which will take a pipeline model and test out each paramter value passed through in the following parameter list\n","lr_space = [{'fit_intercept':[True, False]}]\n","\n","svr_space = [{'kernel': ['linear'], 'C' : C, 'epsilon' : epsilon},\n","         {'kernel': ['rbf'], 'C' : C, 'gamma' : C, 'epsilon' : epsilon}]\n","\n","rfr_space = [{'max_features' : [\"auto\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"sqrt\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"log2\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","dtr_space = [{'criterion': ['squared_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes},\n","            {'criterion': ['absolute_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes}]\n","\n","gbr_space = [{'learning_rate': learning_rate, 'subsample' : subsample, 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","\n","\n","##use the GridSearchCV function and pass in both the pipeline created above and the grid parameters \n","\n","#pass in cv=5 for the gridsearch to perform cross-validation on our training set\n","#pass score = accuracy for get the accrucay score when the test is performed \n","lr_gs = GridSearchCV(LinearRegression(), param_grid = lr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","svm_gs = GridSearchCV(SVR(), param_grid = svr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","rfr_gs = GridSearchCV(RandomForestRegressor(), param_grid = rfr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","dtr_gs = GridSearchCV(DecisionTreeRegressor(), param_grid = dtr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","gbr_gs = GridSearchCV(GradientBoostingRegressor(), param_grid = gbr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","\n","lr_grids = [lr_gs]\n","\n","for lr_pipe in lr_grids:\n","    lr_pipe.fit(X_boost_train,y_train)\n","\n","svm_grids = [svm_gs]\n","\n","for svm_pipe in svm_grids:\n","    svm_pipe.fit(X_boost_train,y_train)\n","\n","rfr_grids = [rfr_gs]\n","\n","for rfr_pipe in rfr_grids:\n","    rfr_pipe.fit(X_boost_train,y_train)\n","\n","dtr_grids = [dtr_gs]\n","\n","for dtr_pipe in dtr_grids:\n","    dtr_pipe.fit(X_boost_train,y_train)\n","\n","gbr_grids = [gbr_gs]\n","\n","for gbr_pipe in gbr_grids:\n","    gbr_pipe.fit(X_boost_train,y_train)"],"metadata":{"id":"aOTbhtQG0qTU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#first create a dictionary that contains the classifier types to used int eh for loop. \n","lr_grid_dict = {0: 'Linear Regression'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(lr_grids):\n","    print('{} Train R_Square: {}'.format(lr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","lr_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,lr_y_pred)*100\n","\n","for i, model in enumerate(lr_grids):\n","    print('{} Test R_Square: {}'.format(lr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","svm_grid_dict = {0: 'Support Vector Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(svm_grids):\n","    print('{} Train R_Square: {}'.format(svm_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","svm_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,svm_y_pred)*100\n","\n","for i, model in enumerate(svm_grids):\n","    print('{} Test R_Square: {}'.format(svm_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          results.best_params_))\n","    \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","rfr_grid_dict = {0: 'Random Forest Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(rfr_grids):\n","    print('{} Train R_Square: {}'.format(rfr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","rf_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,rf_y_pred)*100\n","\n","for i, model in enumerate(rfr_grids):\n","    print('{} Test R_Square: {}'.format(rfr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","dtr_grid_dict = {0: 'Decision Tree Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(dtr_grids):\n","    print('{} Train R_Square: {}'.format(dtr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","dtr_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,dtr_y_pred)*100\n","\n","for i, model in enumerate(dtr_grids):\n","    print('{} Test R_Square: {}'.format(dtr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","gbr_grid_dict = {0: 'Gradient Boosting Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(gbr_grids):\n","    print('{} Train R_Square: {}'.format(gbr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","gbr_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,gbr_y_pred)*100\n","\n","for i, model in enumerate(gbr_grids):\n","    print('{} Test R_Square: {}'.format(gbr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          results.best_params_))"],"metadata":{"id":"GY50FiPs0qTU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YgseKMpb0qTV"},"source":["#### Mutual Information Feature Selection "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659724797561,"user_tz":240,"elapsed":2931,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"7f430427-d146-4f57-c8f0-ac55c5f102fa","id":"Ubqgc9jp0qTV"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1.93329965e-01 2.79787357e-02 0.00000000e+00 2.85353136e-01\n"," 1.12896336e-01 2.04555356e-01 6.47709408e-02 1.89068091e-02\n"," 2.36317673e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.14886389e-02 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 9.31302684e-04 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 2.32252200e-03 1.40305033e-01\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.39487101e-02\n"," 7.96625655e-03 0.00000000e+00 9.11215201e-02 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 2.24477243e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 5.80357087e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.13094503e-01 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.45845098e-03 7.19362761e-03\n"," 0.00000000e+00 0.00000000e+00 2.40973048e-03 7.97151068e-03\n"," 1.65255318e-02 2.68652715e-02 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 4.78600247e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 9.50697768e-04 2.04791150e-03 0.00000000e+00 0.00000000e+00\n"," 1.41220624e-03 0.00000000e+00 5.01277239e-03 0.00000000e+00\n"," 0.00000000e+00 7.38843507e-03 0.00000000e+00 0.00000000e+00\n"," 1.29290297e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 6.44048285e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 5.02576173e-03 0.00000000e+00 0.00000000e+00 1.99348901e-03\n"," 7.05102041e-03 8.03350383e-03 9.70502791e-04 1.17793054e-03\n"," 5.30411535e-03 0.00000000e+00 5.33382372e-03 3.65177267e-04\n"," 8.64074784e-03 0.00000000e+00 1.19599897e-02 0.00000000e+00\n"," 2.84805174e-03 1.38729789e-03 0.00000000e+00 1.02384043e-02\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 1.09570251e-02 1.19276081e-02 0.00000000e+00 2.53345761e-04\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.42389858e-02\n"," 0.00000000e+00 1.85970340e-02 1.75240411e-03 3.44523841e-03\n"," 9.75414247e-03 2.92779979e-03 0.00000000e+00 0.00000000e+00\n"," 1.77997772e-03 0.00000000e+00 8.69478688e-04 2.96583868e-03\n"," 0.00000000e+00 8.08535841e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 1.97063305e-02 3.67974827e-05 1.96065812e-05\n"," 0.00000000e+00 0.00000000e+00 3.69781965e-04 0.00000000e+00\n"," 0.00000000e+00 1.26305402e-03 0.00000000e+00 0.00000000e+00\n"," 4.49748302e-03 8.72724855e-03 4.24913952e-03 4.28808130e-03\n"," 0.00000000e+00 0.00000000e+00 1.04173726e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 2.68405974e-03 9.93819846e-04\n"," 0.00000000e+00 2.74253287e-02 5.91776086e-03 0.00000000e+00\n"," 3.12987092e-03 0.00000000e+00 0.00000000e+00 1.84500421e-02\n"," 0.00000000e+00 7.46316487e-04 0.00000000e+00 2.83490536e-03\n"," 6.22400733e-03 9.66883491e-03 1.97294403e-02 0.00000000e+00\n"," 4.05093784e-03 0.00000000e+00 4.27624185e-05 9.47262668e-06\n"," 0.00000000e+00 2.39920972e-03 0.00000000e+00 0.00000000e+00\n"," 2.83998190e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 6.63027663e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 2.69679475e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 3.30421947e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 9.72412049e-04\n"," 0.00000000e+00 0.00000000e+00 1.51862016e-03 1.57903235e-02\n"," 0.00000000e+00 0.00000000e+00 5.30980431e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 6.48832115e-04 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.46576918e-04\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.60120945e-02\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.08799955e-02 5.67464207e-03\n"," 0.00000000e+00 0.00000000e+00 2.99233670e-03 3.60552397e-03\n"," 2.10738798e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 1.36375133e-02 0.00000000e+00 0.00000000e+00\n"," 1.38784031e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 2.36206964e-03 0.00000000e+00 0.00000000e+00\n"," 4.14751754e-04 4.63904996e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 3.81096621e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 1.43343054e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 9.67265880e-04 4.12500329e-04\n"," 1.32235983e-02 7.88329410e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 3.73740846e-04 0.00000000e+00 5.22484888e-03\n"," 6.29731809e-02 0.00000000e+00 6.21929279e-02 1.49949132e-01\n"," 8.69707919e-03 1.86974960e-02 3.31688153e-03 6.98487316e-02\n"," 5.58862446e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 1.70697662e-01 1.35633449e-01 0.00000000e+00\n"," 0.00000000e+00 8.44687426e-03 0.00000000e+00 3.92890583e-04\n"," 3.05852092e-02 0.00000000e+00 1.77488514e-02 3.18491126e-02\n"," 4.92078625e-02 5.25771761e-02 3.57412169e-02 0.00000000e+00\n"," 0.00000000e+00 6.05903110e-02 2.00073829e-02 2.41637927e-02\n"," 2.98299349e-02 6.85765039e-04 0.00000000e+00 3.66658126e-02\n"," 8.50858185e-02 8.20275432e-03 0.00000000e+00 1.04039135e-02\n"," 2.37977376e-02 7.00182719e-03]\n"]}],"source":["from sklearn.feature_selection import mutual_info_regression  \n","from sklearn.feature_selection import SelectKBest\n","selector = SelectKBest(mutual_info_regression, k=10)\n","X_train_new = selector.fit_transform(X_train, y_train)  #Applying transformation to the training set\n","#to get names of the selected features\n","mask = selector.get_support()  \n","\n","print(selector.scores_)   \n","\n","new_features = X_train.columns[mask]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dyAGG_180qTV"},"outputs":[],"source":["X_MI_df = V4_master_df[new_features]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":375},"executionInfo":{"status":"error","timestamp":1659724798118,"user_tz":240,"elapsed":289,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"b261267e-2132-4ed7-fe08-e4c25bcaeb52","id":"UbEylGhR0qTV"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-82-a1d14a8e7824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train/test split:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_MI_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_MI_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_MI_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_MI_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_MI_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2417\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [800, 339]"]}],"source":["# Train/test split:\n","X_MI_train, X_MI_test, y_train, y_test = train_test_split(X_MI_df, y_df, test_size = 0.2, random_state = 2)\n","\n","X_MI_train.shape, X_MI_test.shape"]},{"cell_type":"code","source":["logreg=LogisticRegression()\n","kf=KFold(n_splits=5)\n","score=cross_val_score(logreg,X_MI_train,y_train,cv=kf)\n","print(\"Cross Validation Scores are {}\".format(score))\n","print(\"Average Cross Validation score :{}\".format(score.mean()))\n","\n","# Train classifiers\n","reg1 = GradientBoostingRegressor(random_state=1)\n","reg2 = RandomForestRegressor(random_state=1)\n","reg3 = LinearRegression()\n","\n","reg1.fit(X_MI_train, y_train)\n","reg2.fit(X_MI_train, y_train)\n","reg3.fit(X_MI_train, y_train)\n","\n","ereg = VotingRegressor([(\"gb\", reg1), (\"rf\", reg2), (\"lr\", reg3)])\n","ereg.fit(X_MI_train, y_train)\n","\n","#predict \n","pred1 = reg1.predict(X_boost_test)\n","pred2 = reg2.predict(X_boost_test)\n","pred3 = reg3.predict(X_boost_test)\n","pred4 = ereg.predict(X_boost_test)\n","\n","#plot\n","plt.figure()\n","plt.plot(pred1, \"gd\", label=\"GradientBoostingRegressor\")\n","plt.plot(pred2, \"b^\", label=\"RandomForestRegressor\")\n","plt.plot(pred3, \"ys\", label=\"LinearRegression\")\n","plt.plot(pred4, \"r*\", ms=10, label=\"VotingRegressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"training samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions and their average - Depression\")\n","plt.setp(plt.gca(),ylim=(0,100))\n","\n","plt.show()"],"metadata":{"id":"M_YlcF8A0qTV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#chose five models to train the data with to see which performs the best : Linear Regression and Support Vector Regression\n","pipe_lr = Pipeline([('LR', LinearRegression())])\n","pipe_svm = Pipeline([('SVM', SVR())])\n","pipe_rfr = Pipeline([('RFR', RandomForestRegressor())])\n","pipe_dtr = Pipeline([('DTR', DecisionTreeRegressor())])\n","pipe_gbr = Pipeline([('DTR', GradientBoostingRegressor())])\n","\n","#create GridSearch parameters\n","\n","#creates lists to pass into the grid below\n","C = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n","epsilon = [0, 0.01, 0.1, 0.5, 1, 2, 4, 5]\n","n_estimators = [50,100,150, 200, 300, 500,1000, 1500]\n","n_jobs = np.array([1, 10, 100, 290, 500])\n","bootstrap = [True, False]\n","max_depth = [3,4,6,8,10]\n","min_samples_split = [10,20,40]\n","max_depth = [2, 6, 8]\n","min_samples_leaf = [20, 40, 100]\n","max_leaf_nodes = [5, 20, 100]\n","learning_rate = [0.01,0.02,0.03,0.04]\n","subsample = [0.9, 0.5, 0.2, 0.1]\n","\n","#these will be passed to the GridSearchCV function below -> which will take a pipeline model and test out each paramter value passed through in the following parameter list\n","lr_space = [{'fit_intercept': ['svd'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['cholesky'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['lsqr'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sparse_cg'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sag'],  'n_jobs' : n_jobs},\n","         {'fit_intercept': ['saga'], 'n_jobs' : n_jobs}]\n","\n","svr_space = [{'kernel': ['linear'], 'C' : C, 'epsilon' : epsilon},\n","         {'kernel': ['rbf'], 'C' : C, 'gamma' : C, 'epsilon' : epsilon}]\n","\n","rfr_space = [{'max_features' : [\"auto\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"sqrt\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"log2\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","dtr_space = [{'criterion': ['mse'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes},\n","         {'criterion': ['absolute_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes}]\n","\n","gbr_space = [{'learning_rate': learning_rate, 'subsample' : subsample, 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","\n","\n","##use the GridSearchCV function and pass in both the pipeline created above and the frid parameters \n","\n","#pass in cv=3 for the fridsearch to perform cross-validation on our training set\n","#pass score = accuracy for get the accrucay score when the test is performed \n","lr_gs = GridSearchCV(LinearRegression(), param_grid = lr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","svm_gs = GridSearchCV(SVR(), param_grid = svr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","rfr_gs = GridSearchCV(RandomForestRegressor(), param_grid = rfr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","dtr_gs = GridSearchCV(DecisionTreeRegressor(), param_grid = dtr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","gbr_gs = GridSearchCV(GradientBoostingRegressor(), param_grid = gbr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","\n","lr_grids = [lr_gs]\n","\n","for lr_pipe in lr_grids:\n","    lr_pipe.fit(X_MI_train,y_train)\n","\n","svm_grids = [svm_gs]\n","\n","for svm_pipe in svm_grids:\n","    svm_pipe.fit(X_MI_train,y_train)\n","\n","rfr_grids = [rfr_gs]\n","\n","for rfr_pipe in rfr_grids:\n","    rfr_pipe.fit(X_MI_train,y_train)\n","\n","dtr_grids = [dtr_gs]\n","\n","for dtr_pipe in dtr_grids:\n","    dtr_pipe.fit(X_MI_train,y_train)\n","\n","gbr_grids = [gbr_gs]\n","\n","for gbr_pipe in gbr_grids:\n","    gbr_pipe.fit(X_MI_train,y_train)"],"metadata":{"id":"Lq70fWvF0qTV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#first create a dictionary that contains the classifier types to used int eh for loop. \n","lr_grid_dict = {0: 'Linear Regression'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(lr_grids):\n","    print('{} Train R_Square: {}'.format(lr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(lr_grids):\n","    print('{} Test R_Square: {}'.format(lr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","svm_grid_dict = {0: 'Support Vector Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(svm_grids):\n","    print('{} Train R_Square: {}'.format(svm_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(svm_grids):\n","    print('{} Test R_Square: {}'.format(svm_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","rfr_grid_dict = {0: 'Random Forest Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(rfr_grids):\n","    print('{} Train R_Square: {}'.format(rfr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(rfr_grids):\n","    print('{} Test R_Square: {}'.format(rfr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","dtr_grid_dict = {0: 'Decision Tree Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(dtr_grids):\n","    print('{} Train R_Square: {}'.format(dtr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(dtr_grids):\n","    print('{} Test R_Square: {}'.format(dtr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","gbr_grid_dict = {0: 'Gradient Boosting Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(gbr_grids):\n","    print('{} Train R_Square: {}'.format(gbr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(gbr_grids):\n","    print('{} Test R_Square: {}'.format(gbr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))"],"metadata":{"id":"xuah5AQn0qTV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EbRgqDYq0qTV"},"source":["#### Knowledge Feature Selection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w5OvI8_P0qTW"},"outputs":[],"source":["df_list = list(X_df[['number_of_arms', 'has_dmc', 'number_of_facilities', 'study_duration_months', 'event_type_deaths', 'event_type_other', 'event_type_serious']])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QSTfNGhQ0qTW"},"outputs":[],"source":["dropout_list = list(X_df[['dropout_reason_adverse event', 'dropout_reason_inclusion/exclusion criteria issue', 'dropout_reason_lost to follow-up']])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659724854258,"user_tz":240,"elapsed":139,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"6e474a56-8e67-44c6-ba63-94dc82d8b857","id":"8XeZGSNT0qTW"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Headache',\n"," 'Nausea',\n"," 'Fatigue',\n"," 'Vomiting',\n"," 'Decreased appetite',\n"," 'Diarrhoea',\n"," 'Sedation',\n"," 'Rash',\n"," 'Increased appetite',\n"," 'Palpitations']"]},"metadata":{},"execution_count":85}],"source":["top_ae_table_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0SFbwkPq0qTW"},"outputs":[],"source":["X_knowledge_df = X_df[X_df.columns.intersection(top_ae_table_list+dropout_list+df_list)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mLdms8pE0qTW"},"outputs":[],"source":["X_knowledge_norm = (X_knowledge_df-X_knowledge_df.min())/(X_knowledge_df.max()-X_knowledge_df.min())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659724857924,"user_tz":240,"elapsed":117,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"1f81e75a-1e24-4ea5-fc14-1c0e06343aca","id":"yvJlrt190qTW"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((271, 20), (68, 20))"]},"metadata":{},"execution_count":88}],"source":["# Train/test split:\n","X_knowledge_train, X_knowledge_test, y_train, y_test = train_test_split(X_knowledge_norm, y_df, test_size = 0.2, random_state = 2)\n","\n","X_knowledge_train.shape, X_knowledge_test.shape"]},{"cell_type":"code","source":["logreg=LogisticRegression()\n","kf=KFold(n_splits=5)\n","score=cross_val_score(logreg,X_knowledge_train,y_train,cv=kf)\n","print(\"Cross Validation Scores are {}\".format(score))\n","print(\"Average Cross Validation score :{}\".format(score.mean()))\n","\n","# Train classifiers\n","reg1 = GradientBoostingRegressor(random_state=1)\n","reg2 = RandomForestRegressor(random_state=1)\n","reg3 = LinearRegression()\n","\n","reg1.fit(X_knowledge_train, y_train)\n","reg2.fit(X_knowledge_train, y_train)\n","reg3.fit(X_knowledge_train, y_train)\n","\n","ereg = VotingRegressor([(\"gb\", reg1), (\"rf\", reg2), (\"lr\", reg3)])\n","ereg.fit(X_knowledge_train, y_train)\n","\n","#predict \n","pred1 = reg1.predict(X_knowledge_test)\n","pred2 = reg2.predict(X_knowledge_test)\n","pred3 = reg3.predict(X_knowledge_test)\n","pred4 = ereg.predict(X_knowledge_test)\n","\n","#plot\n","plt.figure()\n","plt.plot(pred1, \"gd\", label=\"GradientBoostingRegressor\")\n","plt.plot(pred2, \"b^\", label=\"RandomForestRegressor\")\n","plt.plot(pred3, \"ys\", label=\"LinearRegression\")\n","plt.plot(pred4, \"r*\", ms=10, label=\"VotingRegressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"training samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions and their average - Depression\")\n","plt.setp(plt.gca(),ylim=(0,100))\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":640},"executionInfo":{"status":"ok","timestamp":1659724939828,"user_tz":240,"elapsed":2577,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"4fa6ee0a-25ae-442b-80ff-50a084b78f97","id":"WrfFbbfo0qTW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","5 fits failed out of a total of 5.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","5 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1516, in fit\n","    check_classification_targets(y)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 197, in check_classification_targets\n","    raise ValueError(\"Unknown label type: %r\" % y_type)\n","ValueError: Unknown label type: 'continuous'\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Cross Validation Scores are [nan nan nan nan nan]\n","Average Cross Validation score :nan\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["#chose five models to train the data with to see which performs the best : Linear Regression and Support Vector Regression\n","pipe_lr = Pipeline([('LR', LinearRegression())])\n","pipe_svm = Pipeline([('SVM', SVR())])\n","pipe_rfr = Pipeline([('RFR', RandomForestRegressor())])\n","pipe_dtr = Pipeline([('DTR', DecisionTreeRegressor())])\n","pipe_gbr = Pipeline([('DTR', GradientBoostingRegressor())])\n","\n","#create GridSearch parameters\n","\n","#creates lists to pass into the grid below\n","C = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n","epsilon = [0, 0.01, 0.1, 0.5, 1, 2, 4, 5]\n","n_estimators = [50,100,150, 200, 300, 500,1000, 1500]\n","n_jobs = np.array([1, 10, 100, 290, 500])\n","bootstrap = [True, False]\n","max_depth = [3,4,6,8,10]\n","min_samples_split = [10,20,40]\n","max_depth = [2, 6, 8]\n","min_samples_leaf = [20, 40, 100]\n","max_leaf_nodes = [5, 20, 100]\n","learning_rate = [0.01,0.02,0.03,0.04]\n","subsample = [0.9, 0.5, 0.2, 0.1]\n","\n","#these will be passed to the GridSearchCV function below -> which will take a pipeline model and test out each paramter value passed through in the following parameter list\n","lr_space = [{'fit_intercept': ['svd'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['cholesky'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['lsqr'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sparse_cg'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sag'],  'n_jobs' : n_jobs},\n","         {'fit_intercept': ['saga'], 'n_jobs' : n_jobs}]\n","\n","svr_space = [{'kernel': ['linear'], 'C' : C, 'epsilon' : epsilon},\n","         {'kernel': ['rbf'], 'C' : C, 'gamma' : C, 'epsilon' : epsilon}]\n","\n","rfr_space = [{'max_features' : [\"auto\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"sqrt\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"log2\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","dtr_space = [{'criterion': ['mse'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes},\n","         {'criterion': ['absolute_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes}]\n","\n","gbr_space = [{'learning_rate': learning_rate, 'subsample' : subsample, 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","\n","\n","##use the GridSearchCV function and pass in both the pipeline created above and the frid parameters \n","\n","#pass in cv=3 for the fridsearch to perform cross-validation on our training set\n","#pass score = accuracy for get the accrucay score when the test is performed \n","lr_gs = GridSearchCV(LinearRegression(), param_grid = lr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","svm_gs = GridSearchCV(SVR(), param_grid = svr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","rfr_gs = GridSearchCV(RandomForestRegressor(), param_grid = rfr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","dtr_gs = GridSearchCV(DecisionTreeRegressor(), param_grid = dtr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","gbr_gs = GridSearchCV(GradientBoostingRegressor(), param_grid = gbr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","\n","lr_grids = [lr_gs]\n","\n","for lr_pipe in lr_grids:\n","    lr_pipe.fit(X_knowledge_train,y_train)\n","\n","svm_grids = [svm_gs]\n","\n","for svm_pipe in svm_grids:\n","    svm_pipe.fit(X_knowledge_train,y_train)\n","\n","rfr_grids = [rfr_gs]\n","\n","for rfr_pipe in rfr_grids:\n","    rfr_pipe.fit(X_knowledge_train,y_train)\n","\n","dtr_grids = [dtr_gs]\n","\n","for dtr_pipe in dtr_grids:\n","    dtr_pipe.fit(X_knowledge_train,y_train)\n","\n","gbr_grids = [gbr_gs]\n","\n","for gbr_pipe in gbr_grids:\n","    gbr_pipe.fit(X_knowledge_train,y_train)"],"metadata":{"id":"j-ieP7o70qTW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#first create a dictionary that contains the classifier types to used int eh for loop. \n","lr_grid_dict = {0: 'Linear Regression'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(lr_grids):\n","    print('{} Train R_Square: {}'.format(lr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","lr_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,lr_y_pred)*100\n","\n","for i, model in enumerate(lr_grids):\n","    print('{} Test R_Square: {}'.format(lr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","svm_grid_dict = {0: 'Support Vector Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(svm_grids):\n","    print('{} Train R_Square: {}'.format(svm_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","svm_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,svm_y_pred)*100\n","\n","for i, model in enumerate(svm_grids):\n","    print('{} Test R_Square: {}'.format(svm_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          results.best_params_))\n","    \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","rfr_grid_dict = {0: 'Random Forest Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(rfr_grids):\n","    print('{} Train R_Square: {}'.format(rfr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","rf_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,rf_y_pred)*100\n","\n","for i, model in enumerate(rfr_grids):\n","    print('{} Test R_Square: {}'.format(rfr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","dtr_grid_dict = {0: 'Decision Tree Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(dtr_grids):\n","    print('{} Train R_Square: {}'.format(dtr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","dtr_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,dtr_y_pred)*100\n","\n","for i, model in enumerate(dtr_grids):\n","    print('{} Test R_Square: {}'.format(dtr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","gbr_grid_dict = {0: 'Gradient Boosting Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(gbr_grids):\n","    print('{} Train R_Square: {}'.format(gbr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","gbr_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,gbr_y_pred)*100\n","\n","for i, model in enumerate(gbr_grids):\n","    print('{} Test R_Square: {}'.format(gbr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          results.best_params_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":592},"executionInfo":{"status":"error","timestamp":1659726446747,"user_tz":240,"elapsed":329,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"ce5abbb0-34da-4c3e-c4d7-0a55fe99180e","id":"6dSRdH110qTW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n","Feature names unseen at fit time:\n","- Abdominal distension\n","- Abdominal hernia\n","- Abdominal pain\n","- Abortion spontaneous\n","- Accepts_Healthy_volunteers\n","- ...\n","Feature names must be in the same order as they were in fit.\n","\n","  warnings.warn(message, FutureWarning)\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-93-d716c58a4f93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#then create a for loop to train them all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_grids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Train R_Square: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_grid_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Best Params: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_grid_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;31m# callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimetric_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         )\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \"\"\"\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod_caller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return self._sign * self._score_func(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;34m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \"\"\"\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise ValueError(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: X has 334 features, but LinearRegression is expecting 20 features as input."]}]},{"cell_type":"code","source":["#plot predictions \n","plt.figure()\n","plt.plot(lr_y_pred, \"gd\", label=\"Linear Regression\")\n","plt.plot(svm_y_pred, \"b^\", label=\"Support Vector Regressor\")\n","plt.plot(rf_y_pred, \"ys\", label=\"Random Forest Regressor\")\n","plt.plot(dtr_y_pred, \"r*\", ms=10, label=\"Decision Tree Regressor\")\n","plt.plot(gbr_y_pred, \"bs\", label=\"Gradient Boosting Regressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"Training Samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions - Knowledge Based Feature Selection - Depression\")\n","plt.setp(plt.gca(),ylim=(0,100))"],"metadata":{"id":"_J0Rk1JS0qTW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"93FL8LTbFSgH"},"source":["## Parkinson's Disease"]},{"cell_type":"markdown","metadata":{"id":"5Sep1dY74dan"},"source":["### Subset Parkinson's Disease Studies / Split into test and train sets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LMhZ6KII4dan"},"outputs":[],"source":["V4_parkinsons_df = V4_master_df[V4_master_df['disease_type'] == \"Parkinson's Disease\"]\n","V4_parkinsons_df = V4_parkinsons_df.drop(columns=['disease_type', 'intervention_model_type_Sequential Assignment'])\n","\n","#split into features and outcome dataframes\n","X_df = V4_parkinsons_df.drop(columns=['percent_attrition'])\n","y_df = V4_parkinsons_df.percent_attrition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"adLkL1ix4dan","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896790504,"user_tz":240,"elapsed":200,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"679bcfd1-4b33-4ef6-bc0c-76dd515992fa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((153, 2010), (39, 2010))"]},"metadata":{},"execution_count":203}],"source":["# Train/test split:\n","X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size = 0.2, random_state = 2)\n","\n","X_train.shape, X_test.shape"]},{"cell_type":"code","source":["#select all ae columns\n","ae_df = X_df.iloc[:,9:1962]\n","\n","#replace all non zero cells with 1\n","ae_df[ae_df != 0] = 1\n","\n","#add all columns and select the top ten most prevelant\n","s = ae_df.sum()\n","top_ae_table = ae_df[s.sort_values(ascending=False).index[:10]]\n","\n","#generated list of most prevelant ae\n","top_ae_table_list = list(top_ae_table.columns)"],"metadata":{"id":"Oludrxqloj72"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PbcNGBJKcKr9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896790659,"user_tz":240,"elapsed":158,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"bc155686-f1e2-421d-c7c3-370fd353b8ee"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  dropout_reason_consent withdrawn  \\\n","1                            22.0                               0.0   \n","3                            22.0                               0.0   \n","6                            10.0                               0.0   \n","8                            10.0                               0.0   \n","23                           26.0                               0.0   \n","..                            ...                               ...   \n","795                           0.0                               0.0   \n","796                           3.0                               0.0   \n","797                           1.0                               0.0   \n","798                           1.0                               1.0   \n","799                           0.0                               0.0   \n","\n","     dropout_reason_death  dropout_reason_inclusion/exclusion criteria issue  \\\n","1                     0.0                                                0.0   \n","3                     0.0                                                0.0   \n","6                     0.0                                                3.0   \n","8                     0.0                                                3.0   \n","23                    0.0                                                4.0   \n","..                    ...                                                ...   \n","795                   0.0                                                3.0   \n","796                   0.0                                                0.0   \n","797                   0.0                                                0.0   \n","798                   0.0                                                0.0   \n","799                   0.0                                                0.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","1                                0.0                               0.0   \n","3                                0.0                               0.0   \n","6                                0.0                               0.0   \n","8                                0.0                               0.0   \n","23                               3.0                               0.0   \n","..                               ...                               ...   \n","795                              0.0                               0.0   \n","796                              5.0                               0.0   \n","797                              1.0                               0.0   \n","798                              0.0                               0.0   \n","799                              0.0                               0.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","1                                  0.0                                0.0   \n","3                                  0.0                                0.0   \n","6                                  0.0                                1.0   \n","8                                  0.0                                1.0   \n","23                                 0.0                                0.0   \n","..                                 ...                                ...   \n","795                                0.0                                0.0   \n","796                                0.0                                0.0   \n","797                                0.0                                0.0   \n","798                                0.0                                0.0   \n","799                                1.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Pain  ...  \\\n","1                                  0.0   4.0  ...   \n","3                                  0.0   4.0  ...   \n","6                                  4.0   0.0  ...   \n","8                                  4.0   0.0  ...   \n","23                                 6.0   0.0  ...   \n","..                                 ...   ...  ...   \n","795                                0.0   0.0  ...   \n","796                                1.0   0.0  ...   \n","797                                1.0   0.0  ...   \n","798                                0.0   0.0  ...   \n","799                                0.0   0.0  ...   \n","\n","     allocation_type_Not Reported  allocation_type_Randomized  \\\n","1                               0                           1   \n","3                               0                           1   \n","6                               0                           1   \n","8                               0                           1   \n","23                              0                           1   \n","..                            ...                         ...   \n","795                             1                           0   \n","796                             0                           1   \n","797                             1                           0   \n","798                             0                           1   \n","799                             0                           1   \n","\n","     masking_type_Double  masking_type_None (Open Label)  \\\n","1                      0                               0   \n","3                      0                               0   \n","6                      0                               0   \n","8                      0                               0   \n","23                     0                               0   \n","..                   ...                             ...   \n","795                    0                               1   \n","796                    0                               0   \n","797                    0                               1   \n","798                    0                               0   \n","799                    0                               0   \n","\n","     masking_type_Not Reported  masking_type_Quadruple  masking_type_Single  \\\n","1                            0                       0                    0   \n","3                            0                       0                    0   \n","6                            0                       1                    0   \n","8                            0                       1                    0   \n","23                           0                       1                    0   \n","..                         ...                     ...                  ...   \n","795                          0                       0                    0   \n","796                          0                       1                    0   \n","797                          0                       0                    0   \n","798                          0                       1                    0   \n","799                          0                       0                    0   \n","\n","     masking_type_Triple  study_gender_eligibility_All  \\\n","1                      1                             1   \n","3                      1                             1   \n","6                      0                             1   \n","8                      0                             1   \n","23                     0                             1   \n","..                   ...                           ...   \n","795                    0                             1   \n","796                    0                             1   \n","797                    0                             1   \n","798                    0                             1   \n","799                    1                             1   \n","\n","     study_gender_eligibility_Male  \n","1                                0  \n","3                                0  \n","6                                0  \n","8                                0  \n","23                               0  \n","..                             ...  \n","795                              0  \n","796                              0  \n","797                              0  \n","798                              0  \n","799                              0  \n","\n","[192 rows x 675 columns]"],"text/html":["\n","  <div id=\"df-735641ae-efbb-4fd2-bf0b-77618c6287d5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Pain</th>\n","      <th>...</th>\n","      <th>allocation_type_Not Reported</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Not Reported</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>26.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>795</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>796</th>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>797</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>798</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>799</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>192 rows × 675 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-735641ae-efbb-4fd2-bf0b-77618c6287d5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-735641ae-efbb-4fd2-bf0b-77618c6287d5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-735641ae-efbb-4fd2-bf0b-77618c6287d5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":205}],"source":["X_df = X_df.loc[:, (X_df != 0).any(axis=0)]\n","X_df"]},{"cell_type":"markdown","metadata":{"id":"w6R1seiiOza0"},"source":["### Colinearity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E_CmzL56Oza0"},"outputs":[],"source":["from statsmodels.stats.outliers_influence import variance_inflation_factor    \n","\n","def calculate_vif_(X_df, thresh=4.0):\n","    variables = list(range(X_df.shape[1]))\n","    dropped = True\n","    while dropped:\n","        dropped = False\n","        vif = [variance_inflation_factor(X_df.iloc[:, variables].values, ix)\n","               for ix in range(X_df.iloc[:, variables].shape[1])]\n","\n","        maxloc = vif.index(max(vif))\n","        if max(vif) > thresh:\n","            print('dropping \\'' + X_df.iloc[:, variables].columns[maxloc] +\n","                  '\\' at index: ' + str(maxloc))\n","            del variables[maxloc]\n","            dropped = True\n","\n","    print('Remaining variables:')\n","    print(X_df.columns[variables])\n","    return X_df.iloc[:, variables]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lJbQsNwOOza0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896790991,"user_tz":240,"elapsed":3,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"f8dd8fc3-f79a-499c-d175-e7516a16160f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  dropout_reason_consent withdrawn  \\\n","1                            22.0                               0.0   \n","3                            22.0                               0.0   \n","6                            10.0                               0.0   \n","8                            10.0                               0.0   \n","23                           26.0                               0.0   \n","..                            ...                               ...   \n","795                           0.0                               0.0   \n","796                           3.0                               0.0   \n","797                           1.0                               0.0   \n","798                           1.0                               1.0   \n","799                           0.0                               0.0   \n","\n","     dropout_reason_death  dropout_reason_inclusion/exclusion criteria issue  \\\n","1                     0.0                                                0.0   \n","3                     0.0                                                0.0   \n","6                     0.0                                                3.0   \n","8                     0.0                                                3.0   \n","23                    0.0                                                4.0   \n","..                    ...                                                ...   \n","795                   0.0                                                3.0   \n","796                   0.0                                                0.0   \n","797                   0.0                                                0.0   \n","798                   0.0                                                0.0   \n","799                   0.0                                                0.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","1                                0.0                               0.0   \n","3                                0.0                               0.0   \n","6                                0.0                               0.0   \n","8                                0.0                               0.0   \n","23                               3.0                               0.0   \n","..                               ...                               ...   \n","795                              0.0                               0.0   \n","796                              5.0                               0.0   \n","797                              1.0                               0.0   \n","798                              0.0                               0.0   \n","799                              0.0                               0.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","1                                  0.0                                0.0   \n","3                                  0.0                                0.0   \n","6                                  0.0                                1.0   \n","8                                  0.0                                1.0   \n","23                                 0.0                                0.0   \n","..                                 ...                                ...   \n","795                                0.0                                0.0   \n","796                                0.0                                0.0   \n","797                                0.0                                0.0   \n","798                                0.0                                0.0   \n","799                                1.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Pain  ...  \\\n","1                                  0.0   4.0  ...   \n","3                                  0.0   4.0  ...   \n","6                                  4.0   0.0  ...   \n","8                                  4.0   0.0  ...   \n","23                                 6.0   0.0  ...   \n","..                                 ...   ...  ...   \n","795                                0.0   0.0  ...   \n","796                                1.0   0.0  ...   \n","797                                1.0   0.0  ...   \n","798                                0.0   0.0  ...   \n","799                                0.0   0.0  ...   \n","\n","     allocation_type_Not Reported  allocation_type_Randomized  \\\n","1                               0                           1   \n","3                               0                           1   \n","6                               0                           1   \n","8                               0                           1   \n","23                              0                           1   \n","..                            ...                         ...   \n","795                             1                           0   \n","796                             0                           1   \n","797                             1                           0   \n","798                             0                           1   \n","799                             0                           1   \n","\n","     masking_type_Double  masking_type_None (Open Label)  \\\n","1                      0                               0   \n","3                      0                               0   \n","6                      0                               0   \n","8                      0                               0   \n","23                     0                               0   \n","..                   ...                             ...   \n","795                    0                               1   \n","796                    0                               0   \n","797                    0                               1   \n","798                    0                               0   \n","799                    0                               0   \n","\n","     masking_type_Not Reported  masking_type_Quadruple  masking_type_Single  \\\n","1                            0                       0                    0   \n","3                            0                       0                    0   \n","6                            0                       1                    0   \n","8                            0                       1                    0   \n","23                           0                       1                    0   \n","..                         ...                     ...                  ...   \n","795                          0                       0                    0   \n","796                          0                       1                    0   \n","797                          0                       0                    0   \n","798                          0                       1                    0   \n","799                          0                       0                    0   \n","\n","     masking_type_Triple  study_gender_eligibility_All  \\\n","1                      1                             1   \n","3                      1                             1   \n","6                      0                             1   \n","8                      0                             1   \n","23                     0                             1   \n","..                   ...                           ...   \n","795                    0                             1   \n","796                    0                             1   \n","797                    0                             1   \n","798                    0                             1   \n","799                    1                             1   \n","\n","     study_gender_eligibility_Male  \n","1                                0  \n","3                                0  \n","6                                0  \n","8                                0  \n","23                               0  \n","..                             ...  \n","795                              0  \n","796                              0  \n","797                              0  \n","798                              0  \n","799                              0  \n","\n","[192 rows x 675 columns]"],"text/html":["\n","  <div id=\"df-82419b1e-3fd4-48fb-bcbb-e0f823676063\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Pain</th>\n","      <th>...</th>\n","      <th>allocation_type_Not Reported</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Not Reported</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>26.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>795</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>796</th>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>797</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>798</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>799</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>192 rows × 675 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82419b1e-3fd4-48fb-bcbb-e0f823676063')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-82419b1e-3fd4-48fb-bcbb-e0f823676063 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-82419b1e-3fd4-48fb-bcbb-e0f823676063');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":207}],"source":["X_df"]},{"cell_type":"markdown","metadata":{"id":"d6I9gyzVc4rn"},"source":["### Corelated Feature Drop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gMd44Juwc4ro","colab":{"base_uri":"https://localhost:8080/","height":334},"executionInfo":{"status":"ok","timestamp":1659896791860,"user_tz":240,"elapsed":393,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"90d9ff16-db71-4fe1-8822-533bba6539d5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   dropout_reason_adverse event  \\\n","dropout_reason_adverse event                                           1.000000   \n","dropout_reason_consent withdrawn                                       0.247704   \n","dropout_reason_death                                                   0.172140   \n","dropout_reason_inclusion/exclusion criteria issue                      0.292774   \n","dropout_reason_lack of efficacy                                        0.565511   \n","\n","                                                   dropout_reason_consent withdrawn  \\\n","dropout_reason_adverse event                                               0.247704   \n","dropout_reason_consent withdrawn                                           1.000000   \n","dropout_reason_death                                                      -0.019762   \n","dropout_reason_inclusion/exclusion criteria issue                          0.658540   \n","dropout_reason_lack of efficacy                                            0.374822   \n","\n","                                                   dropout_reason_death  \\\n","dropout_reason_adverse event                                   0.172140   \n","dropout_reason_consent withdrawn                              -0.019762   \n","dropout_reason_death                                           1.000000   \n","dropout_reason_inclusion/exclusion criteria issue              0.450501   \n","dropout_reason_lack of efficacy                                0.082455   \n","\n","                                                   dropout_reason_inclusion/exclusion criteria issue  \\\n","dropout_reason_adverse event                                                                0.292774   \n","dropout_reason_consent withdrawn                                                            0.658540   \n","dropout_reason_death                                                                        0.450501   \n","dropout_reason_inclusion/exclusion criteria issue                                           1.000000   \n","dropout_reason_lack of efficacy                                                             0.407113   \n","\n","                                                   dropout_reason_lack of efficacy  \\\n","dropout_reason_adverse event                                              0.565511   \n","dropout_reason_consent withdrawn                                          0.374822   \n","dropout_reason_death                                                      0.082455   \n","dropout_reason_inclusion/exclusion criteria issue                         0.407113   \n","dropout_reason_lack of efficacy                                           1.000000   \n","\n","                                                   dropout_reason_lost to follow-up  \\\n","dropout_reason_adverse event                                               0.519460   \n","dropout_reason_consent withdrawn                                           0.024945   \n","dropout_reason_death                                                       0.367129   \n","dropout_reason_inclusion/exclusion criteria issue                          0.290651   \n","dropout_reason_lack of efficacy                                            0.265932   \n","\n","                                                   dropout_reason_physician decision  \\\n","dropout_reason_adverse event                                                0.116031   \n","dropout_reason_consent withdrawn                                            0.055017   \n","dropout_reason_death                                                        0.752763   \n","dropout_reason_inclusion/exclusion criteria issue                           0.479400   \n","dropout_reason_lack of efficacy                                             0.172564   \n","\n","                                                   dropout_reason_protocol violation  \\\n","dropout_reason_adverse event                                                0.444213   \n","dropout_reason_consent withdrawn                                            0.019019   \n","dropout_reason_death                                                        0.214624   \n","dropout_reason_inclusion/exclusion criteria issue                           0.167418   \n","dropout_reason_lack of efficacy                                             0.277914   \n","\n","                                                   dropout_reason_subject withdrawal  \\\n","dropout_reason_adverse event                                                0.406372   \n","dropout_reason_consent withdrawn                                           -0.063114   \n","dropout_reason_death                                                        0.568245   \n","dropout_reason_inclusion/exclusion criteria issue                           0.396212   \n","dropout_reason_lack of efficacy                                             0.058297   \n","\n","                                                       Pain  ...  \\\n","dropout_reason_adverse event                      -0.045369  ...   \n","dropout_reason_consent withdrawn                  -0.013167  ...   \n","dropout_reason_death                               0.896399  ...   \n","dropout_reason_inclusion/exclusion criteria issue  0.490699  ...   \n","dropout_reason_lack of efficacy                   -0.026600  ...   \n","\n","                                                   allocation_type_Not Reported  \\\n","dropout_reason_adverse event                                           0.025324   \n","dropout_reason_consent withdrawn                                      -0.029783   \n","dropout_reason_death                                                   0.025685   \n","dropout_reason_inclusion/exclusion criteria issue                     -0.032734   \n","dropout_reason_lack of efficacy                                        0.051942   \n","\n","                                                   allocation_type_Randomized  \\\n","dropout_reason_adverse event                                        -0.110175   \n","dropout_reason_consent withdrawn                                    -0.021405   \n","dropout_reason_death                                                -0.006003   \n","dropout_reason_inclusion/exclusion criteria issue                   -0.029209   \n","dropout_reason_lack of efficacy                                     -0.164624   \n","\n","                                                   masking_type_Double  \\\n","dropout_reason_adverse event                                 -0.028622   \n","dropout_reason_consent withdrawn                             -0.061577   \n","dropout_reason_death                                         -0.042504   \n","dropout_reason_inclusion/exclusion criteria issue            -0.048934   \n","dropout_reason_lack of efficacy                              -0.098778   \n","\n","                                                   masking_type_None (Open Label)  \\\n","dropout_reason_adverse event                                             0.010587   \n","dropout_reason_consent withdrawn                                         0.032233   \n","dropout_reason_death                                                    -0.031719   \n","dropout_reason_inclusion/exclusion criteria issue                       -0.019920   \n","dropout_reason_lack of efficacy                                          0.056347   \n","\n","                                                   masking_type_Not Reported  \\\n","dropout_reason_adverse event                                        0.217556   \n","dropout_reason_consent withdrawn                                   -0.042035   \n","dropout_reason_death                                                0.112206   \n","dropout_reason_inclusion/exclusion criteria issue                   0.049246   \n","dropout_reason_lack of efficacy                                     0.163361   \n","\n","                                                   masking_type_Quadruple  \\\n","dropout_reason_adverse event                                    -0.036255   \n","dropout_reason_consent withdrawn                                 0.056451   \n","dropout_reason_death                                             0.049206   \n","dropout_reason_inclusion/exclusion criteria issue                0.074917   \n","dropout_reason_lack of efficacy                                  0.000593   \n","\n","                                                   masking_type_Single  \\\n","dropout_reason_adverse event                                 -0.114037   \n","dropout_reason_consent withdrawn                             -0.030266   \n","dropout_reason_death                                         -0.018054   \n","dropout_reason_inclusion/exclusion criteria issue            -0.049471   \n","dropout_reason_lack of efficacy                              -0.058774   \n","\n","                                                   masking_type_Triple  \\\n","dropout_reason_adverse event                                 -0.042283   \n","dropout_reason_consent withdrawn                             -0.011564   \n","dropout_reason_death                                         -0.060669   \n","dropout_reason_inclusion/exclusion criteria issue            -0.038785   \n","dropout_reason_lack of efficacy                              -0.076235   \n","\n","                                                   study_gender_eligibility_All  \\\n","dropout_reason_adverse event                                          -0.177064   \n","dropout_reason_consent withdrawn                                      -0.445330   \n","dropout_reason_death                                                   0.012203   \n","dropout_reason_inclusion/exclusion criteria issue                     -0.522889   \n","dropout_reason_lack of efficacy                                       -0.755633   \n","\n","                                                   study_gender_eligibility_Male  \n","dropout_reason_adverse event                                            0.177064  \n","dropout_reason_consent withdrawn                                        0.445330  \n","dropout_reason_death                                                   -0.012203  \n","dropout_reason_inclusion/exclusion criteria issue                       0.522889  \n","dropout_reason_lack of efficacy                                         0.755633  \n","\n","[5 rows x 675 columns]"],"text/html":["\n","  <div id=\"df-3595f32d-95db-4db3-986e-e3e5aaf24a04\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Pain</th>\n","      <th>...</th>\n","      <th>allocation_type_Not Reported</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Not Reported</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>dropout_reason_adverse event</th>\n","      <td>1.000000</td>\n","      <td>0.247704</td>\n","      <td>0.172140</td>\n","      <td>0.292774</td>\n","      <td>0.565511</td>\n","      <td>0.519460</td>\n","      <td>0.116031</td>\n","      <td>0.444213</td>\n","      <td>0.406372</td>\n","      <td>-0.045369</td>\n","      <td>...</td>\n","      <td>0.025324</td>\n","      <td>-0.110175</td>\n","      <td>-0.028622</td>\n","      <td>0.010587</td>\n","      <td>0.217556</td>\n","      <td>-0.036255</td>\n","      <td>-0.114037</td>\n","      <td>-0.042283</td>\n","      <td>-0.177064</td>\n","      <td>0.177064</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <td>0.247704</td>\n","      <td>1.000000</td>\n","      <td>-0.019762</td>\n","      <td>0.658540</td>\n","      <td>0.374822</td>\n","      <td>0.024945</td>\n","      <td>0.055017</td>\n","      <td>0.019019</td>\n","      <td>-0.063114</td>\n","      <td>-0.013167</td>\n","      <td>...</td>\n","      <td>-0.029783</td>\n","      <td>-0.021405</td>\n","      <td>-0.061577</td>\n","      <td>0.032233</td>\n","      <td>-0.042035</td>\n","      <td>0.056451</td>\n","      <td>-0.030266</td>\n","      <td>-0.011564</td>\n","      <td>-0.445330</td>\n","      <td>0.445330</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_death</th>\n","      <td>0.172140</td>\n","      <td>-0.019762</td>\n","      <td>1.000000</td>\n","      <td>0.450501</td>\n","      <td>0.082455</td>\n","      <td>0.367129</td>\n","      <td>0.752763</td>\n","      <td>0.214624</td>\n","      <td>0.568245</td>\n","      <td>0.896399</td>\n","      <td>...</td>\n","      <td>0.025685</td>\n","      <td>-0.006003</td>\n","      <td>-0.042504</td>\n","      <td>-0.031719</td>\n","      <td>0.112206</td>\n","      <td>0.049206</td>\n","      <td>-0.018054</td>\n","      <td>-0.060669</td>\n","      <td>0.012203</td>\n","      <td>-0.012203</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <td>0.292774</td>\n","      <td>0.658540</td>\n","      <td>0.450501</td>\n","      <td>1.000000</td>\n","      <td>0.407113</td>\n","      <td>0.290651</td>\n","      <td>0.479400</td>\n","      <td>0.167418</td>\n","      <td>0.396212</td>\n","      <td>0.490699</td>\n","      <td>...</td>\n","      <td>-0.032734</td>\n","      <td>-0.029209</td>\n","      <td>-0.048934</td>\n","      <td>-0.019920</td>\n","      <td>0.049246</td>\n","      <td>0.074917</td>\n","      <td>-0.049471</td>\n","      <td>-0.038785</td>\n","      <td>-0.522889</td>\n","      <td>0.522889</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <td>0.565511</td>\n","      <td>0.374822</td>\n","      <td>0.082455</td>\n","      <td>0.407113</td>\n","      <td>1.000000</td>\n","      <td>0.265932</td>\n","      <td>0.172564</td>\n","      <td>0.277914</td>\n","      <td>0.058297</td>\n","      <td>-0.026600</td>\n","      <td>...</td>\n","      <td>0.051942</td>\n","      <td>-0.164624</td>\n","      <td>-0.098778</td>\n","      <td>0.056347</td>\n","      <td>0.163361</td>\n","      <td>0.000593</td>\n","      <td>-0.058774</td>\n","      <td>-0.076235</td>\n","      <td>-0.755633</td>\n","      <td>0.755633</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 675 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3595f32d-95db-4db3-986e-e3e5aaf24a04')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3595f32d-95db-4db3-986e-e3e5aaf24a04 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3595f32d-95db-4db3-986e-e3e5aaf24a04');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":208}],"source":["df_corr = X_df.corr()\n","df_corr.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z7x8YN0dc4ro"},"outputs":[],"source":["threshold = 0.9\n","\n","\n","columns = np.full((df_corr.shape[0],), True, dtype=bool)\n","for i in range(df_corr.shape[0]):\n","    for j in range(i+1, df_corr.shape[0]):\n","        if df_corr.iloc[i,j] >= threshold:\n","            if columns[j]:\n","                columns[j] = False\n","selected_columns = X_df.columns[columns]\n","selected_columns\n","X_df = X_df[selected_columns]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XyVgTpGLc4ro","colab":{"base_uri":"https://localhost:8080/","height":505},"executionInfo":{"status":"ok","timestamp":1659896818535,"user_tz":240,"elapsed":12,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"db589048-a36c-4af4-8004-5f0869d8e104"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  dropout_reason_consent withdrawn  \\\n","1                            22.0                               0.0   \n","3                            22.0                               0.0   \n","6                            10.0                               0.0   \n","8                            10.0                               0.0   \n","23                           26.0                               0.0   \n","..                            ...                               ...   \n","795                           0.0                               0.0   \n","796                           3.0                               0.0   \n","797                           1.0                               0.0   \n","798                           1.0                               1.0   \n","799                           0.0                               0.0   \n","\n","     dropout_reason_death  dropout_reason_inclusion/exclusion criteria issue  \\\n","1                     0.0                                                0.0   \n","3                     0.0                                                0.0   \n","6                     0.0                                                3.0   \n","8                     0.0                                                3.0   \n","23                    0.0                                                4.0   \n","..                    ...                                                ...   \n","795                   0.0                                                3.0   \n","796                   0.0                                                0.0   \n","797                   0.0                                                0.0   \n","798                   0.0                                                0.0   \n","799                   0.0                                                0.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","1                                0.0                               0.0   \n","3                                0.0                               0.0   \n","6                                0.0                               0.0   \n","8                                0.0                               0.0   \n","23                               3.0                               0.0   \n","..                               ...                               ...   \n","795                              0.0                               0.0   \n","796                              5.0                               0.0   \n","797                              1.0                               0.0   \n","798                              0.0                               0.0   \n","799                              0.0                               0.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","1                                  0.0                                0.0   \n","3                                  0.0                                0.0   \n","6                                  0.0                                1.0   \n","8                                  0.0                                1.0   \n","23                                 0.0                                0.0   \n","..                                 ...                                ...   \n","795                                0.0                                0.0   \n","796                                0.0                                0.0   \n","797                                0.0                                0.0   \n","798                                0.0                                0.0   \n","799                                1.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Pain  ...  \\\n","1                                  0.0   4.0  ...   \n","3                                  0.0   4.0  ...   \n","6                                  4.0   0.0  ...   \n","8                                  4.0   0.0  ...   \n","23                                 6.0   0.0  ...   \n","..                                 ...   ...  ...   \n","795                                0.0   0.0  ...   \n","796                                1.0   0.0  ...   \n","797                                1.0   0.0  ...   \n","798                                0.0   0.0  ...   \n","799                                0.0   0.0  ...   \n","\n","     intervention_model_type_Single Group Assignment  \\\n","1                                                  0   \n","3                                                  0   \n","6                                                  0   \n","8                                                  0   \n","23                                                 0   \n","..                                               ...   \n","795                                                1   \n","796                                                0   \n","797                                                1   \n","798                                                0   \n","799                                                0   \n","\n","     allocation_type_Non-Randomized  allocation_type_Not Reported  \\\n","1                                 0                             0   \n","3                                 0                             0   \n","6                                 0                             0   \n","8                                 0                             0   \n","23                                0                             0   \n","..                              ...                           ...   \n","795                               0                             1   \n","796                               0                             0   \n","797                               0                             1   \n","798                               0                             0   \n","799                               0                             0   \n","\n","     allocation_type_Randomized  masking_type_Double  \\\n","1                             1                    0   \n","3                             1                    0   \n","6                             1                    0   \n","8                             1                    0   \n","23                            1                    0   \n","..                          ...                  ...   \n","795                           0                    0   \n","796                           1                    0   \n","797                           0                    0   \n","798                           1                    0   \n","799                           1                    0   \n","\n","     masking_type_None (Open Label)  masking_type_Quadruple  \\\n","1                                 0                       0   \n","3                                 0                       0   \n","6                                 0                       1   \n","8                                 0                       1   \n","23                                0                       1   \n","..                              ...                     ...   \n","795                               1                       0   \n","796                               0                       1   \n","797                               1                       0   \n","798                               0                       1   \n","799                               0                       0   \n","\n","     masking_type_Single  masking_type_Triple  study_gender_eligibility_All  \n","1                      0                    1                             1  \n","3                      0                    1                             1  \n","6                      0                    0                             1  \n","8                      0                    0                             1  \n","23                     0                    0                             1  \n","..                   ...                  ...                           ...  \n","795                    0                    0                             1  \n","796                    0                    0                             1  \n","797                    0                    0                             1  \n","798                    0                    0                             1  \n","799                    0                    1                             1  \n","\n","[192 rows x 352 columns]"],"text/html":["\n","  <div id=\"df-45b278fb-b7ae-48f1-99b9-d380d2429942\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Pain</th>\n","      <th>...</th>\n","      <th>intervention_model_type_Single Group Assignment</th>\n","      <th>allocation_type_Non-Randomized</th>\n","      <th>allocation_type_Not Reported</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>26.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>795</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>796</th>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>797</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>798</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>799</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>192 rows × 352 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45b278fb-b7ae-48f1-99b9-d380d2429942')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-45b278fb-b7ae-48f1-99b9-d380d2429942 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-45b278fb-b7ae-48f1-99b9-d380d2429942');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":210}],"source":["X_df"]},{"cell_type":"markdown","metadata":{"id":"llUNpvEHc4ro"},"source":["Standardize and split data "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3uwqrcK_c4ro"},"outputs":[],"source":["X_df_norm = (X_df-X_df.min())/(X_df.max()-X_df.min())"]},{"cell_type":"code","source":["mean(y_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ag-T2oyIjxb7","executionInfo":{"status":"ok","timestamp":1659896819380,"user_tz":240,"elapsed":189,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"b236d1fe-08fe-4302-8a57-4cae6061b53f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["22.654745503505154"]},"metadata":{},"execution_count":213}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EraQkpdWc4ro","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896818716,"user_tz":240,"elapsed":2,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"5d56cca7-582b-403b-e1a1-fa83335908a1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((153, 352), (39, 352))"]},"metadata":{},"execution_count":212}],"source":["# Train/test split:\n","X_train, X_test, y_train, y_test = train_test_split(X_df_norm, y_df, test_size = 0.2, random_state = 2)\n","\n","X_train.shape, X_test.shape"]},{"cell_type":"code","source":[""],"metadata":{"id":"xVFZ9mPq0tdF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"guMMm-al0tk0"},"source":["### Feature Selection"]},{"cell_type":"markdown","metadata":{"id":"b9rnXWui0tk0"},"source":["#### Feature Importance with Gradient Boosting"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1659890131292,"user_tz":240,"elapsed":178,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4661acf5-1779-49c7-f5d4-3335c78e0fb7","id":"JxmuFLKH0tk1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4288759363250807"]},"metadata":{},"execution_count":28}],"source":["# GradientBoostingRegressor will be used for feature importance\n","reg_model = GradientBoostingRegressor(random_state=0)   \n","reg_model.fit(X_train, y_train)\n","y_preds = reg_model.predict(X_test)\n","r2_score(y_test, y_preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1659890131293,"user_tz":240,"elapsed":4,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"colab":{"base_uri":"https://localhost:8080/","height":676},"outputId":"a0c48973-a909-4f20-dca5-cf341bbe25e2","id":"iDMvJvBC0tk1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   importance\n","dropout_reason_inclusion/exclusion criteria issue    0.318439\n","dropout_reason_lost to follow-up                     0.058545\n","event_type_other                                     0.045327\n","Headache                                             0.040401\n","study_duration_months                                0.038388\n","Abdominal pain                                       0.037683\n","intervention_model_type_Factorial Assignment         0.037326\n","Genetic                                              0.034936\n","Nausea                                               0.028028\n","dropout_reason_adverse event                         0.025854\n","Dissociation                                         0.024618\n","Overdose                                             0.022068\n","dropout_reason_subject withdrawal                    0.017419\n","Glossitis                                            0.017076\n","Major depression                                     0.013135\n","masking_type_Quadruple                               0.012135\n","Lethargy                                             0.011323\n","Tremor                                               0.010559\n","intervention_model_type_Single Group Assignment      0.010132\n","dropout_reason_lack of efficacy                      0.009232"],"text/html":["\n","  <div id=\"df-94066c3e-bb63-41de-87b5-f6560594c6e0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>importance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <td>0.318439</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <td>0.058545</td>\n","    </tr>\n","    <tr>\n","      <th>event_type_other</th>\n","      <td>0.045327</td>\n","    </tr>\n","    <tr>\n","      <th>Headache</th>\n","      <td>0.040401</td>\n","    </tr>\n","    <tr>\n","      <th>study_duration_months</th>\n","      <td>0.038388</td>\n","    </tr>\n","    <tr>\n","      <th>Abdominal pain</th>\n","      <td>0.037683</td>\n","    </tr>\n","    <tr>\n","      <th>intervention_model_type_Factorial Assignment</th>\n","      <td>0.037326</td>\n","    </tr>\n","    <tr>\n","      <th>Genetic</th>\n","      <td>0.034936</td>\n","    </tr>\n","    <tr>\n","      <th>Nausea</th>\n","      <td>0.028028</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_adverse event</th>\n","      <td>0.025854</td>\n","    </tr>\n","    <tr>\n","      <th>Dissociation</th>\n","      <td>0.024618</td>\n","    </tr>\n","    <tr>\n","      <th>Overdose</th>\n","      <td>0.022068</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <td>0.017419</td>\n","    </tr>\n","    <tr>\n","      <th>Glossitis</th>\n","      <td>0.017076</td>\n","    </tr>\n","    <tr>\n","      <th>Major depression</th>\n","      <td>0.013135</td>\n","    </tr>\n","    <tr>\n","      <th>masking_type_Quadruple</th>\n","      <td>0.012135</td>\n","    </tr>\n","    <tr>\n","      <th>Lethargy</th>\n","      <td>0.011323</td>\n","    </tr>\n","    <tr>\n","      <th>Tremor</th>\n","      <td>0.010559</td>\n","    </tr>\n","    <tr>\n","      <th>intervention_model_type_Single Group Assignment</th>\n","      <td>0.010132</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <td>0.009232</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94066c3e-bb63-41de-87b5-f6560594c6e0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-94066c3e-bb63-41de-87b5-f6560594c6e0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-94066c3e-bb63-41de-87b5-f6560594c6e0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":29}],"source":["feature_imp = pd.DataFrame(reg_model.feature_importances_,\n","                                   index = X_train.columns,\n","                                   columns=['importance']).sort_values('importance', ascending=False)\n","\n","feature_imp.head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IzOQL5Yi0tk1"},"outputs":[],"source":["#create list of top 30 features\n","boost_top_10 = feature_imp.head(10).index.values\n","boost_top_10_list = list(boost_top_10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5vp4eXP00tk1"},"outputs":[],"source":["X_boost_df = X_df[X_df.columns.intersection(boost_top_10_list)]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1659890131482,"user_tz":240,"elapsed":3,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9298c539-76d9-4551-f6a0-512d56403e0f","id":"WFtQUn2M0tk1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((271, 10), (68, 10))"]},"metadata":{},"execution_count":32}],"source":["# Train/test split:\n","X_boost_train, X_boost_test, y_train, y_test = train_test_split(X_boost_df, y_df, test_size = 0.2, random_state = 2)\n","\n","X_boost_train.shape, X_boost_test.shape"]},{"cell_type":"markdown","source":["##### Model Set-up"],"metadata":{"id":"51sdXbQd0tk1"}},{"cell_type":"code","source":["# Continous outcome prediction:\n","\n","def train_and_test(reg_model, X_train, y_train, X_test, y_test):\n","  reg_model.fit(X_train, y_train)\n","  # Make predictions with model\n","  y_pred = reg_model.predict(X_test)\n","  #Metrics\n","  mse_score_val = mean_squared_error(y_test, y_pred)\n","  r2_score_val = r2_score(y_test, y_pred)\n","  return {\"MSE_Score\": mse_score_val, \"R2_Score\": r2_score_val}"],"metadata":{"id":"KZVz_F_o0tk1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Linear Regression"],"metadata":{"id":"92QyZF_h0tk1"}},{"cell_type":"code","source":["# Linear Regression:\n","\n","lr_model = LinearRegression()\n","\n","scores = cross_val_score(lr_model, X_boost_train, y_train, scoring='r2', cv=5)\n","scores   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893244224,"user_tz":240,"elapsed":149,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"7e15afcf-dc7e-4be4-9ead-b02e6c00e426","id":"pSuOJDba0tk1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.52372859,  0.22300902,  0.40490087,  0.28289511,  0.22152235])"]},"metadata":{},"execution_count":104}]},{"cell_type":"code","source":["# k-fold CV (using all the boost variables)\n","train_and_test(lr_model, X_boost_train, y_train, X_boost_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893245438,"user_tz":240,"elapsed":2,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"1580e64d-dfae-49fb-ad3d-97cc49d9cbbc","id":"9SPuCNi10tk1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'MSE_Score': 320.12078109174996, 'R2_Score': 0.27008943892479653}"]},"metadata":{},"execution_count":105}]},{"cell_type":"markdown","source":["Random Forest"],"metadata":{"id":"0SKhkNmk0tk1"}},{"cell_type":"code","source":["# Random Forest Regression:\n","\n","rfr_model = RandomForestRegressor()\n","\n","scores = cross_val_score(rfr_model, X_boost_train, y_train, scoring='r2', cv=5)\n","scores   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893012236,"user_tz":240,"elapsed":2255,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"3379fa3e-f132-4e1a-dfba-ae15c9339c25","id":"DdHh46330tk1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.21087431, 0.4829302 , 0.49542987, 0.26260168, 0.45673906])"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["\n","train_and_test(rfr_model, X_boost_train, y_train, X_boost_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893013554,"user_tz":240,"elapsed":607,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"44be92a3-36fd-42ca-98b1-f2321d638b9f","id":"5RR7Sw4a0tk2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'MSE_Score': 239.01657569297282, 'R2_Score': 0.455015940310575}"]},"metadata":{},"execution_count":97}]},{"cell_type":"markdown","source":["Gradient Boosting"],"metadata":{"id":"n4wUqC4L0tk2"}},{"cell_type":"code","source":["# Gradient Boost for feature importance:\n","\n","boost_model = GradientBoostingRegressor(random_state=0)   \n","\n","scores = cross_val_score(boost_model, X_boost_train, y_train, scoring='r2', cv=5)\n","scores   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893141201,"user_tz":240,"elapsed":860,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"cd9eebc5-824a-4f51-d233-07aaff560c52","id":"8MRMjGEk0tk2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.11861583, 0.52141256, 0.46201785, 0.23063168, 0.37609487])"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":["boost_model.fit(X_boost_train, y_train)\n","y_preds = boost_model.predict(X_boost_test)\n","r2_score(y_test, y_preds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893147475,"user_tz":240,"elapsed":316,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"f4bcf021-b3e3-4597-a9f4-494dc6deff67","id":"XlQAivZ_0tk2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4156543656927092"]},"metadata":{},"execution_count":100}]},{"cell_type":"code","source":["#chose five models to train the data with to see which performs the best : Linear Regression and Support Vector Regression\n","pipe_lr = Pipeline([('LR', LinearRegression())])\n","pipe_svm = Pipeline([('SVM', SVR())])\n","pipe_rfr = Pipeline([('RFR', RandomForestRegressor())])\n","pipe_dtr = Pipeline([('DTR', DecisionTreeRegressor())])\n","pipe_gbr = Pipeline([('DTR', GradientBoostingRegressor())])\n","\n","#create GridSearch parameters\n","\n","#creates lists to pass into the grid below\n","C = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n","epsilon = [0, 0.01, 0.1, 0.5, 1, 2, 4, 5]\n","n_estimators = [50,100,150, 200, 300, 500,1000, 1500]\n","n_jobs = np.array([1, 10, 100, 290, 500])\n","bootstrap = [True, False]\n","max_depth = [3,4,6,8,10]\n","min_samples_split = [10,20,40]\n","max_depth = [2, 6, 8]\n","min_samples_leaf = [20, 40, 100]\n","max_leaf_nodes = [5, 20, 100]\n","learning_rate = [0.01,0.02,0.03,0.04]\n","subsample = [0.9, 0.5, 0.2, 0.1]\n","\n","#these will be passed to the GridSearchCV function below -> which will take a pipeline model and test out each paramter value passed through in the following parameter list\n","lr_space = [{'fit_intercept':[True, False]}]\n","\n","svr_space = [{'kernel': ['linear'], 'C' : C, 'epsilon' : epsilon},\n","         {'kernel': ['rbf'], 'C' : C, 'gamma' : C, 'epsilon' : epsilon}]\n","\n","rfr_space = [{'max_features' : [\"auto\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"sqrt\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"log2\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","dtr_space = [{'criterion': ['squared_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes},\n","            {'criterion': ['absolute_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes}]\n","\n","gbr_space = [{'learning_rate': learning_rate, 'subsample' : subsample, 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","\n","\n","##use the GridSearchCV function and pass in both the pipeline created above and the grid parameters \n","\n","#pass in cv=5 for the gridsearch to perform cross-validation on our training set\n","#pass score = accuracy for get the accrucay score when the test is performed \n","lr_gs = GridSearchCV(LinearRegression(), param_grid = lr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","svm_gs = GridSearchCV(SVR(), param_grid = svr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","rfr_gs = GridSearchCV(RandomForestRegressor(), param_grid = rfr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","dtr_gs = GridSearchCV(DecisionTreeRegressor(), param_grid = dtr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","gbr_gs = GridSearchCV(GradientBoostingRegressor(), param_grid = gbr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","\n","lr_grids = [lr_gs]\n","\n","for lr_pipe in lr_grids:\n","    lr_pipe.fit(X_boost_train,y_train)\n","\n","svm_grids = [svm_gs]\n","\n","for svm_pipe in svm_grids:\n","    svm_pipe.fit(X_boost_train,y_train)\n","\n","rfr_grids = [rfr_gs]\n","\n","for rfr_pipe in rfr_grids:\n","    rfr_pipe.fit(X_boost_train,y_train)\n","\n","dtr_grids = [dtr_gs]\n","\n","for dtr_pipe in dtr_grids:\n","    dtr_pipe.fit(X_boost_train,y_train)\n","\n","gbr_grids = [gbr_gs]\n","\n","for gbr_pipe in gbr_grids:\n","    gbr_pipe.fit(X_boost_train,y_train)"],"metadata":{"id":"_PhJE0ZD0tk2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#first create a dictionary that contains the classifier types to used int eh for loop. \n","lr_grid_dict = {0: 'Linear Regression'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(lr_grids):\n","    print('{} Train R_Square: {}'.format(lr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","lr_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,lr_y_pred)*100\n","\n","for i, model in enumerate(lr_grids):\n","    print('{} Test R_Square: {}'.format(lr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","svm_grid_dict = {0: 'Support Vector Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(svm_grids):\n","    print('{} Train R_Square: {}'.format(svm_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","svm_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,svm_y_pred)*100\n","\n","for i, model in enumerate(svm_grids):\n","    print('{} Test R_Square: {}'.format(svm_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          results.best_params_))\n","    \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","rfr_grid_dict = {0: 'Random Forest Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(rfr_grids):\n","    print('{} Train R_Square: {}'.format(rfr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","rf_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,rf_y_pred)*100\n","\n","for i, model in enumerate(rfr_grids):\n","    print('{} Test R_Square: {}'.format(rfr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","dtr_grid_dict = {0: 'Decision Tree Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(dtr_grids):\n","    print('{} Train R_Square: {}'.format(dtr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","dtr_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,dtr_y_pred)*100\n","\n","for i, model in enumerate(dtr_grids):\n","    print('{} Test R_Square: {}'.format(dtr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","gbr_grid_dict = {0: 'Gradient Boosting Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(gbr_grids):\n","    print('{} Train R_Square: {}'.format(gbr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","gbr_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,gbr_y_pred)*100\n","\n","for i, model in enumerate(gbr_grids):\n","    print('{} Test R_Square: {}'.format(gbr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          results.best_params_))"],"metadata":{"id":"aZTOz2mA0tk2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PCfjAb7z0tk2"},"source":["#### Mutual Information Feature Selection "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659724797561,"user_tz":240,"elapsed":2931,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"7f430427-d146-4f57-c8f0-ac55c5f102fa","id":"qe-ycs9o0tk2"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1.93329965e-01 2.79787357e-02 0.00000000e+00 2.85353136e-01\n"," 1.12896336e-01 2.04555356e-01 6.47709408e-02 1.89068091e-02\n"," 2.36317673e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.14886389e-02 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 9.31302684e-04 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 2.32252200e-03 1.40305033e-01\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.39487101e-02\n"," 7.96625655e-03 0.00000000e+00 9.11215201e-02 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 2.24477243e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 5.80357087e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.13094503e-01 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.45845098e-03 7.19362761e-03\n"," 0.00000000e+00 0.00000000e+00 2.40973048e-03 7.97151068e-03\n"," 1.65255318e-02 2.68652715e-02 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 4.78600247e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 9.50697768e-04 2.04791150e-03 0.00000000e+00 0.00000000e+00\n"," 1.41220624e-03 0.00000000e+00 5.01277239e-03 0.00000000e+00\n"," 0.00000000e+00 7.38843507e-03 0.00000000e+00 0.00000000e+00\n"," 1.29290297e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 6.44048285e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 5.02576173e-03 0.00000000e+00 0.00000000e+00 1.99348901e-03\n"," 7.05102041e-03 8.03350383e-03 9.70502791e-04 1.17793054e-03\n"," 5.30411535e-03 0.00000000e+00 5.33382372e-03 3.65177267e-04\n"," 8.64074784e-03 0.00000000e+00 1.19599897e-02 0.00000000e+00\n"," 2.84805174e-03 1.38729789e-03 0.00000000e+00 1.02384043e-02\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 1.09570251e-02 1.19276081e-02 0.00000000e+00 2.53345761e-04\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.42389858e-02\n"," 0.00000000e+00 1.85970340e-02 1.75240411e-03 3.44523841e-03\n"," 9.75414247e-03 2.92779979e-03 0.00000000e+00 0.00000000e+00\n"," 1.77997772e-03 0.00000000e+00 8.69478688e-04 2.96583868e-03\n"," 0.00000000e+00 8.08535841e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 1.97063305e-02 3.67974827e-05 1.96065812e-05\n"," 0.00000000e+00 0.00000000e+00 3.69781965e-04 0.00000000e+00\n"," 0.00000000e+00 1.26305402e-03 0.00000000e+00 0.00000000e+00\n"," 4.49748302e-03 8.72724855e-03 4.24913952e-03 4.28808130e-03\n"," 0.00000000e+00 0.00000000e+00 1.04173726e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 2.68405974e-03 9.93819846e-04\n"," 0.00000000e+00 2.74253287e-02 5.91776086e-03 0.00000000e+00\n"," 3.12987092e-03 0.00000000e+00 0.00000000e+00 1.84500421e-02\n"," 0.00000000e+00 7.46316487e-04 0.00000000e+00 2.83490536e-03\n"," 6.22400733e-03 9.66883491e-03 1.97294403e-02 0.00000000e+00\n"," 4.05093784e-03 0.00000000e+00 4.27624185e-05 9.47262668e-06\n"," 0.00000000e+00 2.39920972e-03 0.00000000e+00 0.00000000e+00\n"," 2.83998190e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 6.63027663e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 2.69679475e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 3.30421947e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 9.72412049e-04\n"," 0.00000000e+00 0.00000000e+00 1.51862016e-03 1.57903235e-02\n"," 0.00000000e+00 0.00000000e+00 5.30980431e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 6.48832115e-04 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.46576918e-04\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.60120945e-02\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.08799955e-02 5.67464207e-03\n"," 0.00000000e+00 0.00000000e+00 2.99233670e-03 3.60552397e-03\n"," 2.10738798e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 1.36375133e-02 0.00000000e+00 0.00000000e+00\n"," 1.38784031e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 2.36206964e-03 0.00000000e+00 0.00000000e+00\n"," 4.14751754e-04 4.63904996e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 3.81096621e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 1.43343054e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 9.67265880e-04 4.12500329e-04\n"," 1.32235983e-02 7.88329410e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 3.73740846e-04 0.00000000e+00 5.22484888e-03\n"," 6.29731809e-02 0.00000000e+00 6.21929279e-02 1.49949132e-01\n"," 8.69707919e-03 1.86974960e-02 3.31688153e-03 6.98487316e-02\n"," 5.58862446e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 1.70697662e-01 1.35633449e-01 0.00000000e+00\n"," 0.00000000e+00 8.44687426e-03 0.00000000e+00 3.92890583e-04\n"," 3.05852092e-02 0.00000000e+00 1.77488514e-02 3.18491126e-02\n"," 4.92078625e-02 5.25771761e-02 3.57412169e-02 0.00000000e+00\n"," 0.00000000e+00 6.05903110e-02 2.00073829e-02 2.41637927e-02\n"," 2.98299349e-02 6.85765039e-04 0.00000000e+00 3.66658126e-02\n"," 8.50858185e-02 8.20275432e-03 0.00000000e+00 1.04039135e-02\n"," 2.37977376e-02 7.00182719e-03]\n"]}],"source":["from sklearn.feature_selection import mutual_info_regression  \n","from sklearn.feature_selection import SelectKBest\n","selector = SelectKBest(mutual_info_regression, k=10)\n","X_train_new = selector.fit_transform(X_train, y_train)  #Applying transformation to the training set\n","#to get names of the selected features\n","mask = selector.get_support()  \n","\n","print(selector.scores_)   \n","\n","new_features = X_train.columns[mask]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T_TZaE1u0tk2"},"outputs":[],"source":["X_MI_df = V4_master_df[new_features]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":375},"executionInfo":{"status":"error","timestamp":1659724798118,"user_tz":240,"elapsed":289,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"b261267e-2132-4ed7-fe08-e4c25bcaeb52","id":"nvO67fxU0tk2"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-82-a1d14a8e7824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train/test split:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_MI_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_MI_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_MI_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_MI_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_MI_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2417\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [800, 339]"]}],"source":["# Train/test split:\n","X_MI_train, X_MI_test, y_train, y_test = train_test_split(X_MI_df, y_df, test_size = 0.2, random_state = 2)\n","\n","X_MI_train.shape, X_MI_test.shape"]},{"cell_type":"code","source":["logreg=LogisticRegression()\n","kf=KFold(n_splits=5)\n","score=cross_val_score(logreg,X_MI_train,y_train,cv=kf)\n","print(\"Cross Validation Scores are {}\".format(score))\n","print(\"Average Cross Validation score :{}\".format(score.mean()))\n","\n","# Train classifiers\n","reg1 = GradientBoostingRegressor(random_state=1)\n","reg2 = RandomForestRegressor(random_state=1)\n","reg3 = LinearRegression()\n","\n","reg1.fit(X_MI_train, y_train)\n","reg2.fit(X_MI_train, y_train)\n","reg3.fit(X_MI_train, y_train)\n","\n","ereg = VotingRegressor([(\"gb\", reg1), (\"rf\", reg2), (\"lr\", reg3)])\n","ereg.fit(X_MI_train, y_train)\n","\n","#predict \n","pred1 = reg1.predict(X_boost_test)\n","pred2 = reg2.predict(X_boost_test)\n","pred3 = reg3.predict(X_boost_test)\n","pred4 = ereg.predict(X_boost_test)\n","\n","#plot\n","plt.figure()\n","plt.plot(pred1, \"gd\", label=\"GradientBoostingRegressor\")\n","plt.plot(pred2, \"b^\", label=\"RandomForestRegressor\")\n","plt.plot(pred3, \"ys\", label=\"LinearRegression\")\n","plt.plot(pred4, \"r*\", ms=10, label=\"VotingRegressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"training samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions and their average - Depression\")\n","plt.setp(plt.gca(),ylim=(0,100))\n","\n","plt.show()"],"metadata":{"id":"lw3An76h0tk2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#chose five models to train the data with to see which performs the best : Linear Regression and Support Vector Regression\n","pipe_lr = Pipeline([('LR', LinearRegression())])\n","pipe_svm = Pipeline([('SVM', SVR())])\n","pipe_rfr = Pipeline([('RFR', RandomForestRegressor())])\n","pipe_dtr = Pipeline([('DTR', DecisionTreeRegressor())])\n","pipe_gbr = Pipeline([('DTR', GradientBoostingRegressor())])\n","\n","#create GridSearch parameters\n","\n","#creates lists to pass into the grid below\n","C = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n","epsilon = [0, 0.01, 0.1, 0.5, 1, 2, 4, 5]\n","n_estimators = [50,100,150, 200, 300, 500,1000, 1500]\n","n_jobs = np.array([1, 10, 100, 290, 500])\n","bootstrap = [True, False]\n","max_depth = [3,4,6,8,10]\n","min_samples_split = [10,20,40]\n","max_depth = [2, 6, 8]\n","min_samples_leaf = [20, 40, 100]\n","max_leaf_nodes = [5, 20, 100]\n","learning_rate = [0.01,0.02,0.03,0.04]\n","subsample = [0.9, 0.5, 0.2, 0.1]\n","\n","#these will be passed to the GridSearchCV function below -> which will take a pipeline model and test out each paramter value passed through in the following parameter list\n","lr_space = [{'fit_intercept': ['svd'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['cholesky'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['lsqr'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sparse_cg'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sag'],  'n_jobs' : n_jobs},\n","         {'fit_intercept': ['saga'], 'n_jobs' : n_jobs}]\n","\n","svr_space = [{'kernel': ['linear'], 'C' : C, 'epsilon' : epsilon},\n","         {'kernel': ['rbf'], 'C' : C, 'gamma' : C, 'epsilon' : epsilon}]\n","\n","rfr_space = [{'max_features' : [\"auto\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"sqrt\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"log2\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","dtr_space = [{'criterion': ['mse'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes},\n","         {'criterion': ['absolute_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes}]\n","\n","gbr_space = [{'learning_rate': learning_rate, 'subsample' : subsample, 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","\n","\n","##use the GridSearchCV function and pass in both the pipeline created above and the frid parameters \n","\n","#pass in cv=3 for the fridsearch to perform cross-validation on our training set\n","#pass score = accuracy for get the accrucay score when the test is performed \n","lr_gs = GridSearchCV(LinearRegression(), param_grid = lr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","svm_gs = GridSearchCV(SVR(), param_grid = svr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","rfr_gs = GridSearchCV(RandomForestRegressor(), param_grid = rfr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","dtr_gs = GridSearchCV(DecisionTreeRegressor(), param_grid = dtr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","gbr_gs = GridSearchCV(GradientBoostingRegressor(), param_grid = gbr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","\n","lr_grids = [lr_gs]\n","\n","for lr_pipe in lr_grids:\n","    lr_pipe.fit(X_MI_train,y_train)\n","\n","svm_grids = [svm_gs]\n","\n","for svm_pipe in svm_grids:\n","    svm_pipe.fit(X_MI_train,y_train)\n","\n","rfr_grids = [rfr_gs]\n","\n","for rfr_pipe in rfr_grids:\n","    rfr_pipe.fit(X_MI_train,y_train)\n","\n","dtr_grids = [dtr_gs]\n","\n","for dtr_pipe in dtr_grids:\n","    dtr_pipe.fit(X_MI_train,y_train)\n","\n","gbr_grids = [gbr_gs]\n","\n","for gbr_pipe in gbr_grids:\n","    gbr_pipe.fit(X_MI_train,y_train)"],"metadata":{"id":"cQkRun-q0tk3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#first create a dictionary that contains the classifier types to used int eh for loop. \n","lr_grid_dict = {0: 'Linear Regression'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(lr_grids):\n","    print('{} Train R_Square: {}'.format(lr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(lr_grids):\n","    print('{} Test R_Square: {}'.format(lr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","svm_grid_dict = {0: 'Support Vector Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(svm_grids):\n","    print('{} Train R_Square: {}'.format(svm_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(svm_grids):\n","    print('{} Test R_Square: {}'.format(svm_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","rfr_grid_dict = {0: 'Random Forest Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(rfr_grids):\n","    print('{} Train R_Square: {}'.format(rfr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(rfr_grids):\n","    print('{} Test R_Square: {}'.format(rfr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","dtr_grid_dict = {0: 'Decision Tree Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(dtr_grids):\n","    print('{} Train R_Square: {}'.format(dtr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(dtr_grids):\n","    print('{} Test R_Square: {}'.format(dtr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","gbr_grid_dict = {0: 'Gradient Boosting Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(gbr_grids):\n","    print('{} Train R_Square: {}'.format(gbr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(gbr_grids):\n","    print('{} Test R_Square: {}'.format(gbr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))"],"metadata":{"id":"5KNeGzps0tk3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CMprWPcx0tk3"},"source":["#### Knowledge Feature Selection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jZzH8EYm0tk3"},"outputs":[],"source":["df_list = list(X_df[['number_of_arms', 'has_dmc', 'number_of_facilities', 'study_duration_months', 'event_type_deaths', 'event_type_other', 'event_type_serious']])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xpvW1qye0tk3"},"outputs":[],"source":["dropout_list = list(X_df[['dropout_reason_adverse event', 'dropout_reason_inclusion/exclusion criteria issue', 'dropout_reason_lost to follow-up']])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659724854258,"user_tz":240,"elapsed":139,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"6e474a56-8e67-44c6-ba63-94dc82d8b857","id":"mnQ6NTI30tk3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Headache',\n"," 'Nausea',\n"," 'Fatigue',\n"," 'Vomiting',\n"," 'Decreased appetite',\n"," 'Diarrhoea',\n"," 'Sedation',\n"," 'Rash',\n"," 'Increased appetite',\n"," 'Palpitations']"]},"metadata":{},"execution_count":85}],"source":["top_ae_table_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-BGemPD_0tk3"},"outputs":[],"source":["X_knowledge_df = X_df[X_df.columns.intersection(top_ae_table_list+dropout_list+df_list)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dXQM_7xL0tk3"},"outputs":[],"source":["X_knowledge_norm = (X_knowledge_df-X_knowledge_df.min())/(X_knowledge_df.max()-X_knowledge_df.min())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659724857924,"user_tz":240,"elapsed":117,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"1f81e75a-1e24-4ea5-fc14-1c0e06343aca","id":"YnLk2dwL0tk3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((271, 20), (68, 20))"]},"metadata":{},"execution_count":88}],"source":["# Train/test split:\n","X_knowledge_train, X_knowledge_test, y_train, y_test = train_test_split(X_knowledge_norm, y_df, test_size = 0.2, random_state = 2)\n","\n","X_knowledge_train.shape, X_knowledge_test.shape"]},{"cell_type":"code","source":["logreg=LogisticRegression()\n","kf=KFold(n_splits=5)\n","score=cross_val_score(logreg,X_knowledge_train,y_train,cv=kf)\n","print(\"Cross Validation Scores are {}\".format(score))\n","print(\"Average Cross Validation score :{}\".format(score.mean()))\n","\n","# Train classifiers\n","reg1 = GradientBoostingRegressor(random_state=1)\n","reg2 = RandomForestRegressor(random_state=1)\n","reg3 = LinearRegression()\n","\n","reg1.fit(X_knowledge_train, y_train)\n","reg2.fit(X_knowledge_train, y_train)\n","reg3.fit(X_knowledge_train, y_train)\n","\n","ereg = VotingRegressor([(\"gb\", reg1), (\"rf\", reg2), (\"lr\", reg3)])\n","ereg.fit(X_knowledge_train, y_train)\n","\n","#predict \n","pred1 = reg1.predict(X_knowledge_test)\n","pred2 = reg2.predict(X_knowledge_test)\n","pred3 = reg3.predict(X_knowledge_test)\n","pred4 = ereg.predict(X_knowledge_test)\n","\n","#plot\n","plt.figure()\n","plt.plot(pred1, \"gd\", label=\"GradientBoostingRegressor\")\n","plt.plot(pred2, \"b^\", label=\"RandomForestRegressor\")\n","plt.plot(pred3, \"ys\", label=\"LinearRegression\")\n","plt.plot(pred4, \"r*\", ms=10, label=\"VotingRegressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"training samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions and their average - Depression\")\n","plt.setp(plt.gca(),ylim=(0,100))\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":640},"executionInfo":{"status":"ok","timestamp":1659724939828,"user_tz":240,"elapsed":2577,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"4fa6ee0a-25ae-442b-80ff-50a084b78f97","id":"5yCA75G80tk3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","5 fits failed out of a total of 5.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","5 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1516, in fit\n","    check_classification_targets(y)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 197, in check_classification_targets\n","    raise ValueError(\"Unknown label type: %r\" % y_type)\n","ValueError: Unknown label type: 'continuous'\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Cross Validation Scores are [nan nan nan nan nan]\n","Average Cross Validation score :nan\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["#chose five models to train the data with to see which performs the best : Linear Regression and Support Vector Regression\n","pipe_lr = Pipeline([('LR', LinearRegression())])\n","pipe_svm = Pipeline([('SVM', SVR())])\n","pipe_rfr = Pipeline([('RFR', RandomForestRegressor())])\n","pipe_dtr = Pipeline([('DTR', DecisionTreeRegressor())])\n","pipe_gbr = Pipeline([('DTR', GradientBoostingRegressor())])\n","\n","#create GridSearch parameters\n","\n","#creates lists to pass into the grid below\n","C = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n","epsilon = [0, 0.01, 0.1, 0.5, 1, 2, 4, 5]\n","n_estimators = [50,100,150, 200, 300, 500,1000, 1500]\n","n_jobs = np.array([1, 10, 100, 290, 500])\n","bootstrap = [True, False]\n","max_depth = [3,4,6,8,10]\n","min_samples_split = [10,20,40]\n","max_depth = [2, 6, 8]\n","min_samples_leaf = [20, 40, 100]\n","max_leaf_nodes = [5, 20, 100]\n","learning_rate = [0.01,0.02,0.03,0.04]\n","subsample = [0.9, 0.5, 0.2, 0.1]\n","\n","#these will be passed to the GridSearchCV function below -> which will take a pipeline model and test out each paramter value passed through in the following parameter list\n","lr_space = [{'fit_intercept': ['svd'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['cholesky'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['lsqr'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sparse_cg'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sag'],  'n_jobs' : n_jobs},\n","         {'fit_intercept': ['saga'], 'n_jobs' : n_jobs}]\n","\n","svr_space = [{'kernel': ['linear'], 'C' : C, 'epsilon' : epsilon},\n","         {'kernel': ['rbf'], 'C' : C, 'gamma' : C, 'epsilon' : epsilon}]\n","\n","rfr_space = [{'max_features' : [\"auto\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"sqrt\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"log2\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","dtr_space = [{'criterion': ['mse'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes},\n","         {'criterion': ['absolute_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes}]\n","\n","gbr_space = [{'learning_rate': learning_rate, 'subsample' : subsample, 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","\n","\n","##use the GridSearchCV function and pass in both the pipeline created above and the frid parameters \n","\n","#pass in cv=3 for the fridsearch to perform cross-validation on our training set\n","#pass score = accuracy for get the accrucay score when the test is performed \n","lr_gs = GridSearchCV(LinearRegression(), param_grid = lr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","svm_gs = GridSearchCV(SVR(), param_grid = svr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","rfr_gs = GridSearchCV(RandomForestRegressor(), param_grid = rfr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","dtr_gs = GridSearchCV(DecisionTreeRegressor(), param_grid = dtr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","gbr_gs = GridSearchCV(GradientBoostingRegressor(), param_grid = gbr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","\n","lr_grids = [lr_gs]\n","\n","for lr_pipe in lr_grids:\n","    lr_pipe.fit(X_knowledge_train,y_train)\n","\n","svm_grids = [svm_gs]\n","\n","for svm_pipe in svm_grids:\n","    svm_pipe.fit(X_knowledge_train,y_train)\n","\n","rfr_grids = [rfr_gs]\n","\n","for rfr_pipe in rfr_grids:\n","    rfr_pipe.fit(X_knowledge_train,y_train)\n","\n","dtr_grids = [dtr_gs]\n","\n","for dtr_pipe in dtr_grids:\n","    dtr_pipe.fit(X_knowledge_train,y_train)\n","\n","gbr_grids = [gbr_gs]\n","\n","for gbr_pipe in gbr_grids:\n","    gbr_pipe.fit(X_knowledge_train,y_train)"],"metadata":{"id":"SGFSbtiB0tk3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#first create a dictionary that contains the classifier types to used int eh for loop. \n","lr_grid_dict = {0: 'Linear Regression'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(lr_grids):\n","    print('{} Train R_Square: {}'.format(lr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","lr_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,lr_y_pred)*100\n","\n","for i, model in enumerate(lr_grids):\n","    print('{} Test R_Square: {}'.format(lr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","svm_grid_dict = {0: 'Support Vector Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(svm_grids):\n","    print('{} Train R_Square: {}'.format(svm_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","svm_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,svm_y_pred)*100\n","\n","for i, model in enumerate(svm_grids):\n","    print('{} Test R_Square: {}'.format(svm_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          results.best_params_))\n","    \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","rfr_grid_dict = {0: 'Random Forest Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(rfr_grids):\n","    print('{} Train R_Square: {}'.format(rfr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","rf_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,rf_y_pred)*100\n","\n","for i, model in enumerate(rfr_grids):\n","    print('{} Test R_Square: {}'.format(rfr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","dtr_grid_dict = {0: 'Decision Tree Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(dtr_grids):\n","    print('{} Train R_Square: {}'.format(dtr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","dtr_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,dtr_y_pred)*100\n","\n","for i, model in enumerate(dtr_grids):\n","    print('{} Test R_Square: {}'.format(dtr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","gbr_grid_dict = {0: 'Gradient Boosting Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(gbr_grids):\n","    print('{} Train R_Square: {}'.format(gbr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","gbr_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,gbr_y_pred)*100\n","\n","for i, model in enumerate(gbr_grids):\n","    print('{} Test R_Square: {}'.format(gbr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          results.best_params_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":592},"executionInfo":{"status":"error","timestamp":1659726446747,"user_tz":240,"elapsed":329,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"ce5abbb0-34da-4c3e-c4d7-0a55fe99180e","id":"TsGiCwmA0tk4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n","Feature names unseen at fit time:\n","- Abdominal distension\n","- Abdominal hernia\n","- Abdominal pain\n","- Abortion spontaneous\n","- Accepts_Healthy_volunteers\n","- ...\n","Feature names must be in the same order as they were in fit.\n","\n","  warnings.warn(message, FutureWarning)\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-93-d716c58a4f93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#then create a for loop to train them all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_grids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Train R_Square: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_grid_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Best Params: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_grid_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;31m# callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimetric_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         )\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \"\"\"\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod_caller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return self._sign * self._score_func(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;34m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \"\"\"\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise ValueError(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: X has 334 features, but LinearRegression is expecting 20 features as input."]}]},{"cell_type":"code","source":["#plot predictions \n","plt.figure()\n","plt.plot(lr_y_pred, \"gd\", label=\"Linear Regression\")\n","plt.plot(svm_y_pred, \"b^\", label=\"Support Vector Regressor\")\n","plt.plot(rf_y_pred, \"ys\", label=\"Random Forest Regressor\")\n","plt.plot(dtr_y_pred, \"r*\", ms=10, label=\"Decision Tree Regressor\")\n","plt.plot(gbr_y_pred, \"bs\", label=\"Gradient Boosting Regressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"Training Samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions - Knowledge Based Feature Selection - Depression\")\n","plt.setp(plt.gca(),ylim=(0,100))"],"metadata":{"id":"vRGytFVy0tk4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MrZ2p9UEFSgM"},"source":["## Master "]},{"cell_type":"markdown","metadata":{"id":"9MZ_NNshFSgN"},"source":["### Subset Master Studies / Split into test and train sets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"53hIAx-NFSgN"},"outputs":[],"source":["#split into features and outcome dataframes\n","X_df = V4_master_df.drop(columns=['percent_attrition', 'disease_type', 'intervention_model_type_Sequential Assignment'])\n","\n","y_df = V4_master_df.percent_attrition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hajo50hGFSgN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896834140,"user_tz":240,"elapsed":3,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"e3ffca0d-f797-4359-f2c9-f6006482beec"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((640, 2010), (160, 2010))"]},"metadata":{},"execution_count":215}],"source":["# Train/test split:\n","X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size = 0.2, random_state = 2)\n","\n","X_train.shape, X_test.shape"]},{"cell_type":"code","source":["#select all ae columns\n","ae_df = X_df.iloc[:,9:1962]\n","\n","#replace all non zero cells with 1\n","ae_df[ae_df != 0] = 1\n","\n","#add all columns and select the top ten most prevelant\n","s = ae_df.sum()\n","top_ae_table = ae_df[s.sort_values(ascending=False).index[:10]]\n","\n","#generated list of most prevelant ae\n","top_ae_table_list = list(top_ae_table.columns)"],"metadata":{"id":"agxFWzXWol4I"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LL7dZ7vVcMA2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896834496,"user_tz":240,"elapsed":210,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"8ced30ec-9cb0-4467-e0e0-3cdc75fa65bb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  dropout_reason_consent withdrawn  \\\n","0                            22.0                               0.0   \n","1                            22.0                               0.0   \n","2                            22.0                               0.0   \n","3                            22.0                               0.0   \n","4                             0.0                               0.0   \n","..                            ...                               ...   \n","795                           0.0                               0.0   \n","796                           3.0                               0.0   \n","797                           1.0                               0.0   \n","798                           1.0                               1.0   \n","799                           0.0                               0.0   \n","\n","     dropout_reason_death  dropout_reason_inclusion/exclusion criteria issue  \\\n","0                     0.0                                                0.0   \n","1                     0.0                                                0.0   \n","2                     0.0                                                0.0   \n","3                     0.0                                                0.0   \n","4                     0.0                                                0.0   \n","..                    ...                                                ...   \n","795                   0.0                                                3.0   \n","796                   0.0                                                0.0   \n","797                   0.0                                                0.0   \n","798                   0.0                                                0.0   \n","799                   0.0                                                0.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","0                                0.0                               0.0   \n","1                                0.0                               0.0   \n","2                                0.0                               0.0   \n","3                                0.0                               0.0   \n","4                                0.0                               0.0   \n","..                               ...                               ...   \n","795                              0.0                               0.0   \n","796                              5.0                               0.0   \n","797                              1.0                               0.0   \n","798                              0.0                               0.0   \n","799                              0.0                               0.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","0                                  0.0                                0.0   \n","1                                  0.0                                0.0   \n","2                                  0.0                                0.0   \n","3                                  0.0                                0.0   \n","4                                  0.0                                4.0   \n","..                                 ...                                ...   \n","795                                0.0                                0.0   \n","796                                0.0                                0.0   \n","797                                0.0                                0.0   \n","798                                0.0                                0.0   \n","799                                1.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Influenza  ...  \\\n","0                                  0.0        0.0  ...   \n","1                                  0.0        0.0  ...   \n","2                                  0.0        0.0  ...   \n","3                                  0.0        0.0  ...   \n","4                                  0.0        0.0  ...   \n","..                                 ...        ...  ...   \n","795                                0.0        0.0  ...   \n","796                                1.0        0.0  ...   \n","797                                1.0        0.0  ...   \n","798                                0.0        0.0  ...   \n","799                                0.0        0.0  ...   \n","\n","     allocation_type_Randomized  masking_type_Double  \\\n","0                             1                    0   \n","1                             1                    0   \n","2                             1                    0   \n","3                             1                    0   \n","4                             1                    0   \n","..                          ...                  ...   \n","795                           0                    0   \n","796                           1                    0   \n","797                           0                    0   \n","798                           1                    0   \n","799                           1                    0   \n","\n","     masking_type_None (Open Label)  masking_type_Not Reported  \\\n","0                                 0                          0   \n","1                                 0                          0   \n","2                                 0                          0   \n","3                                 0                          0   \n","4                                 0                          0   \n","..                              ...                        ...   \n","795                               1                          0   \n","796                               0                          0   \n","797                               1                          0   \n","798                               0                          0   \n","799                               0                          0   \n","\n","     masking_type_Quadruple  masking_type_Single  masking_type_Triple  \\\n","0                         0                    0                    1   \n","1                         0                    0                    1   \n","2                         0                    0                    1   \n","3                         0                    0                    1   \n","4                         0                    1                    0   \n","..                      ...                  ...                  ...   \n","795                       0                    0                    0   \n","796                       1                    0                    0   \n","797                       0                    0                    0   \n","798                       1                    0                    0   \n","799                       0                    0                    1   \n","\n","     study_gender_eligibility_All  study_gender_eligibility_Female  \\\n","0                               1                                0   \n","1                               1                                0   \n","2                               1                                0   \n","3                               1                                0   \n","4                               1                                0   \n","..                            ...                              ...   \n","795                             1                                0   \n","796                             1                                0   \n","797                             1                                0   \n","798                             1                                0   \n","799                             1                                0   \n","\n","     study_gender_eligibility_Male  \n","0                                0  \n","1                                0  \n","2                                0  \n","3                                0  \n","4                                0  \n","..                             ...  \n","795                              0  \n","796                              0  \n","797                              0  \n","798                              0  \n","799                              0  \n","\n","[800 rows x 1802 columns]"],"text/html":["\n","  <div id=\"df-22131c15-6303-4ee3-8157-250a31ca5530\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>...</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Not Reported</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Female</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>795</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>796</th>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>797</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>798</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>799</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>800 rows × 1802 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22131c15-6303-4ee3-8157-250a31ca5530')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-22131c15-6303-4ee3-8157-250a31ca5530 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-22131c15-6303-4ee3-8157-250a31ca5530');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":217}],"source":["X_df = X_df.loc[:, (X_df != 0).any(axis=0)]\n","X_df"]},{"cell_type":"markdown","metadata":{"id":"_wL_rpI5OxbG"},"source":["### Colinearity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MUBCJ6BNOxbG"},"outputs":[],"source":["from statsmodels.stats.outliers_influence import variance_inflation_factor    \n","\n","def calculate_vif_(X_df, thresh=4.0):\n","    variables = list(range(X_df.shape[1]))\n","    dropped = True\n","    while dropped:\n","        dropped = False\n","        vif = [variance_inflation_factor(X_df.iloc[:, variables].values, ix)\n","               for ix in range(X_df.iloc[:, variables].shape[1])]\n","\n","        maxloc = vif.index(max(vif))\n","        if max(vif) > thresh:\n","            print('dropping \\'' + X_df.iloc[:, variables].columns[maxloc] +\n","                  '\\' at index: ' + str(maxloc))\n","            del variables[maxloc]\n","            dropped = True\n","\n","    print('Remaining variables:')\n","    print(X_df.columns[variables])\n","    return X_df.iloc[:, variables]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NUApLMDQOxbG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659896834795,"user_tz":240,"elapsed":3,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"9732767e-d785-452c-fda1-8c42494333c9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  dropout_reason_consent withdrawn  \\\n","0                            22.0                               0.0   \n","1                            22.0                               0.0   \n","2                            22.0                               0.0   \n","3                            22.0                               0.0   \n","4                             0.0                               0.0   \n","..                            ...                               ...   \n","795                           0.0                               0.0   \n","796                           3.0                               0.0   \n","797                           1.0                               0.0   \n","798                           1.0                               1.0   \n","799                           0.0                               0.0   \n","\n","     dropout_reason_death  dropout_reason_inclusion/exclusion criteria issue  \\\n","0                     0.0                                                0.0   \n","1                     0.0                                                0.0   \n","2                     0.0                                                0.0   \n","3                     0.0                                                0.0   \n","4                     0.0                                                0.0   \n","..                    ...                                                ...   \n","795                   0.0                                                3.0   \n","796                   0.0                                                0.0   \n","797                   0.0                                                0.0   \n","798                   0.0                                                0.0   \n","799                   0.0                                                0.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","0                                0.0                               0.0   \n","1                                0.0                               0.0   \n","2                                0.0                               0.0   \n","3                                0.0                               0.0   \n","4                                0.0                               0.0   \n","..                               ...                               ...   \n","795                              0.0                               0.0   \n","796                              5.0                               0.0   \n","797                              1.0                               0.0   \n","798                              0.0                               0.0   \n","799                              0.0                               0.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","0                                  0.0                                0.0   \n","1                                  0.0                                0.0   \n","2                                  0.0                                0.0   \n","3                                  0.0                                0.0   \n","4                                  0.0                                4.0   \n","..                                 ...                                ...   \n","795                                0.0                                0.0   \n","796                                0.0                                0.0   \n","797                                0.0                                0.0   \n","798                                0.0                                0.0   \n","799                                1.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Influenza  ...  \\\n","0                                  0.0        0.0  ...   \n","1                                  0.0        0.0  ...   \n","2                                  0.0        0.0  ...   \n","3                                  0.0        0.0  ...   \n","4                                  0.0        0.0  ...   \n","..                                 ...        ...  ...   \n","795                                0.0        0.0  ...   \n","796                                1.0        0.0  ...   \n","797                                1.0        0.0  ...   \n","798                                0.0        0.0  ...   \n","799                                0.0        0.0  ...   \n","\n","     allocation_type_Randomized  masking_type_Double  \\\n","0                             1                    0   \n","1                             1                    0   \n","2                             1                    0   \n","3                             1                    0   \n","4                             1                    0   \n","..                          ...                  ...   \n","795                           0                    0   \n","796                           1                    0   \n","797                           0                    0   \n","798                           1                    0   \n","799                           1                    0   \n","\n","     masking_type_None (Open Label)  masking_type_Not Reported  \\\n","0                                 0                          0   \n","1                                 0                          0   \n","2                                 0                          0   \n","3                                 0                          0   \n","4                                 0                          0   \n","..                              ...                        ...   \n","795                               1                          0   \n","796                               0                          0   \n","797                               1                          0   \n","798                               0                          0   \n","799                               0                          0   \n","\n","     masking_type_Quadruple  masking_type_Single  masking_type_Triple  \\\n","0                         0                    0                    1   \n","1                         0                    0                    1   \n","2                         0                    0                    1   \n","3                         0                    0                    1   \n","4                         0                    1                    0   \n","..                      ...                  ...                  ...   \n","795                       0                    0                    0   \n","796                       1                    0                    0   \n","797                       0                    0                    0   \n","798                       1                    0                    0   \n","799                       0                    0                    1   \n","\n","     study_gender_eligibility_All  study_gender_eligibility_Female  \\\n","0                               1                                0   \n","1                               1                                0   \n","2                               1                                0   \n","3                               1                                0   \n","4                               1                                0   \n","..                            ...                              ...   \n","795                             1                                0   \n","796                             1                                0   \n","797                             1                                0   \n","798                             1                                0   \n","799                             1                                0   \n","\n","     study_gender_eligibility_Male  \n","0                                0  \n","1                                0  \n","2                                0  \n","3                                0  \n","4                                0  \n","..                             ...  \n","795                              0  \n","796                              0  \n","797                              0  \n","798                              0  \n","799                              0  \n","\n","[800 rows x 1802 columns]"],"text/html":["\n","  <div id=\"df-55758b1e-dfb8-4a6d-a219-1297224d05f6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>...</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Not Reported</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Female</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>795</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>796</th>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>797</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>798</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>799</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>800 rows × 1802 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55758b1e-dfb8-4a6d-a219-1297224d05f6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-55758b1e-dfb8-4a6d-a219-1297224d05f6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-55758b1e-dfb8-4a6d-a219-1297224d05f6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":219}],"source":["X_df"]},{"cell_type":"markdown","metadata":{"id":"zk3zSiS2c7bl"},"source":["### Corelated Feature Drop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F3d8DQKJc7bl","colab":{"base_uri":"https://localhost:8080/","height":334},"executionInfo":{"status":"ok","timestamp":1659896846461,"user_tz":240,"elapsed":10902,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"1794a295-afc5-432d-8a83-42f8b69a731a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   dropout_reason_adverse event  \\\n","dropout_reason_adverse event                                           1.000000   \n","dropout_reason_consent withdrawn                                       0.241159   \n","dropout_reason_death                                                   0.247470   \n","dropout_reason_inclusion/exclusion criteria issue                      0.506430   \n","dropout_reason_lack of efficacy                                        0.378847   \n","\n","                                                   dropout_reason_consent withdrawn  \\\n","dropout_reason_adverse event                                               0.241159   \n","dropout_reason_consent withdrawn                                           1.000000   \n","dropout_reason_death                                                       0.081087   \n","dropout_reason_inclusion/exclusion criteria issue                          0.310453   \n","dropout_reason_lack of efficacy                                            0.086490   \n","\n","                                                   dropout_reason_death  \\\n","dropout_reason_adverse event                                   0.247470   \n","dropout_reason_consent withdrawn                               0.081087   \n","dropout_reason_death                                           1.000000   \n","dropout_reason_inclusion/exclusion criteria issue              0.228369   \n","dropout_reason_lack of efficacy                                0.018147   \n","\n","                                                   dropout_reason_inclusion/exclusion criteria issue  \\\n","dropout_reason_adverse event                                                                0.506430   \n","dropout_reason_consent withdrawn                                                            0.310453   \n","dropout_reason_death                                                                        0.228369   \n","dropout_reason_inclusion/exclusion criteria issue                                           1.000000   \n","dropout_reason_lack of efficacy                                                             0.146560   \n","\n","                                                   dropout_reason_lack of efficacy  \\\n","dropout_reason_adverse event                                              0.378847   \n","dropout_reason_consent withdrawn                                          0.086490   \n","dropout_reason_death                                                      0.018147   \n","dropout_reason_inclusion/exclusion criteria issue                         0.146560   \n","dropout_reason_lack of efficacy                                           1.000000   \n","\n","                                                   dropout_reason_lost to follow-up  \\\n","dropout_reason_adverse event                                               0.426010   \n","dropout_reason_consent withdrawn                                           0.115868   \n","dropout_reason_death                                                       0.114569   \n","dropout_reason_inclusion/exclusion criteria issue                          0.179957   \n","dropout_reason_lack of efficacy                                            0.309769   \n","\n","                                                   dropout_reason_physician decision  \\\n","dropout_reason_adverse event                                                0.193515   \n","dropout_reason_consent withdrawn                                           -0.006455   \n","dropout_reason_death                                                        0.236183   \n","dropout_reason_inclusion/exclusion criteria issue                           0.053016   \n","dropout_reason_lack of efficacy                                            -0.008737   \n","\n","                                                   dropout_reason_protocol violation  \\\n","dropout_reason_adverse event                                                0.493697   \n","dropout_reason_consent withdrawn                                            0.168437   \n","dropout_reason_death                                                        0.028040   \n","dropout_reason_inclusion/exclusion criteria issue                           0.106933   \n","dropout_reason_lack of efficacy                                             0.248701   \n","\n","                                                   dropout_reason_subject withdrawal  \\\n","dropout_reason_adverse event                                                0.590873   \n","dropout_reason_consent withdrawn                                           -0.046482   \n","dropout_reason_death                                                        0.374674   \n","dropout_reason_inclusion/exclusion criteria issue                           0.365794   \n","dropout_reason_lack of efficacy                                             0.263023   \n","\n","                                                   Influenza  ...  \\\n","dropout_reason_adverse event                        0.015188  ...   \n","dropout_reason_consent withdrawn                   -0.003456  ...   \n","dropout_reason_death                                0.087721  ...   \n","dropout_reason_inclusion/exclusion criteria issue   0.074414  ...   \n","dropout_reason_lack of efficacy                    -0.012213  ...   \n","\n","                                                   allocation_type_Randomized  \\\n","dropout_reason_adverse event                                         0.006793   \n","dropout_reason_consent withdrawn                                     0.013981   \n","dropout_reason_death                                                 0.026005   \n","dropout_reason_inclusion/exclusion criteria issue                    0.017235   \n","dropout_reason_lack of efficacy                                     -0.013438   \n","\n","                                                   masking_type_Double  \\\n","dropout_reason_adverse event                                 -0.033173   \n","dropout_reason_consent withdrawn                              0.013054   \n","dropout_reason_death                                         -0.031457   \n","dropout_reason_inclusion/exclusion criteria issue            -0.024001   \n","dropout_reason_lack of efficacy                              -0.007317   \n","\n","                                                   masking_type_None (Open Label)  \\\n","dropout_reason_adverse event                                            -0.032918   \n","dropout_reason_consent withdrawn                                        -0.025358   \n","dropout_reason_death                                                    -0.007997   \n","dropout_reason_inclusion/exclusion criteria issue                       -0.030071   \n","dropout_reason_lack of efficacy                                          0.043806   \n","\n","                                                   masking_type_Not Reported  \\\n","dropout_reason_adverse event                                        0.059376   \n","dropout_reason_consent withdrawn                                   -0.029537   \n","dropout_reason_death                                                0.024060   \n","dropout_reason_inclusion/exclusion criteria issue                  -0.009944   \n","dropout_reason_lack of efficacy                                     0.012859   \n","\n","                                                   masking_type_Quadruple  \\\n","dropout_reason_adverse event                                     0.058112   \n","dropout_reason_consent withdrawn                                 0.053218   \n","dropout_reason_death                                             0.056774   \n","dropout_reason_inclusion/exclusion criteria issue                0.072187   \n","dropout_reason_lack of efficacy                                  0.014162   \n","\n","                                                   masking_type_Single  \\\n","dropout_reason_adverse event                                 -0.101457   \n","dropout_reason_consent withdrawn                             -0.037200   \n","dropout_reason_death                                         -0.014566   \n","dropout_reason_inclusion/exclusion criteria issue            -0.036975   \n","dropout_reason_lack of efficacy                              -0.048064   \n","\n","                                                   masking_type_Triple  \\\n","dropout_reason_adverse event                                  0.031059   \n","dropout_reason_consent withdrawn                             -0.015078   \n","dropout_reason_death                                         -0.031492   \n","dropout_reason_inclusion/exclusion criteria issue            -0.003614   \n","dropout_reason_lack of efficacy                              -0.044471   \n","\n","                                                   study_gender_eligibility_All  \\\n","dropout_reason_adverse event                                           0.064146   \n","dropout_reason_consent withdrawn                                      -0.003165   \n","dropout_reason_death                                                   0.033528   \n","dropout_reason_inclusion/exclusion criteria issue                      0.017644   \n","dropout_reason_lack of efficacy                                       -0.001511   \n","\n","                                                   study_gender_eligibility_Female  \\\n","dropout_reason_adverse event                                             -0.063154   \n","dropout_reason_consent withdrawn                                         -0.032211   \n","dropout_reason_death                                                     -0.028812   \n","dropout_reason_inclusion/exclusion criteria issue                        -0.033793   \n","dropout_reason_lack of efficacy                                          -0.024662   \n","\n","                                                   study_gender_eligibility_Male  \n","dropout_reason_adverse event                                           -0.017771  \n","dropout_reason_consent withdrawn                                        0.062652  \n","dropout_reason_death                                                   -0.016628  \n","dropout_reason_inclusion/exclusion criteria issue                       0.023828  \n","dropout_reason_lack of efficacy                                         0.046147  \n","\n","[5 rows x 1802 columns]"],"text/html":["\n","  <div id=\"df-d01962d9-5f8c-4e45-8e16-71540b93193b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>...</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Not Reported</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Female</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>dropout_reason_adverse event</th>\n","      <td>1.000000</td>\n","      <td>0.241159</td>\n","      <td>0.247470</td>\n","      <td>0.506430</td>\n","      <td>0.378847</td>\n","      <td>0.426010</td>\n","      <td>0.193515</td>\n","      <td>0.493697</td>\n","      <td>0.590873</td>\n","      <td>0.015188</td>\n","      <td>...</td>\n","      <td>0.006793</td>\n","      <td>-0.033173</td>\n","      <td>-0.032918</td>\n","      <td>0.059376</td>\n","      <td>0.058112</td>\n","      <td>-0.101457</td>\n","      <td>0.031059</td>\n","      <td>0.064146</td>\n","      <td>-0.063154</td>\n","      <td>-0.017771</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <td>0.241159</td>\n","      <td>1.000000</td>\n","      <td>0.081087</td>\n","      <td>0.310453</td>\n","      <td>0.086490</td>\n","      <td>0.115868</td>\n","      <td>-0.006455</td>\n","      <td>0.168437</td>\n","      <td>-0.046482</td>\n","      <td>-0.003456</td>\n","      <td>...</td>\n","      <td>0.013981</td>\n","      <td>0.013054</td>\n","      <td>-0.025358</td>\n","      <td>-0.029537</td>\n","      <td>0.053218</td>\n","      <td>-0.037200</td>\n","      <td>-0.015078</td>\n","      <td>-0.003165</td>\n","      <td>-0.032211</td>\n","      <td>0.062652</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_death</th>\n","      <td>0.247470</td>\n","      <td>0.081087</td>\n","      <td>1.000000</td>\n","      <td>0.228369</td>\n","      <td>0.018147</td>\n","      <td>0.114569</td>\n","      <td>0.236183</td>\n","      <td>0.028040</td>\n","      <td>0.374674</td>\n","      <td>0.087721</td>\n","      <td>...</td>\n","      <td>0.026005</td>\n","      <td>-0.031457</td>\n","      <td>-0.007997</td>\n","      <td>0.024060</td>\n","      <td>0.056774</td>\n","      <td>-0.014566</td>\n","      <td>-0.031492</td>\n","      <td>0.033528</td>\n","      <td>-0.028812</td>\n","      <td>-0.016628</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <td>0.506430</td>\n","      <td>0.310453</td>\n","      <td>0.228369</td>\n","      <td>1.000000</td>\n","      <td>0.146560</td>\n","      <td>0.179957</td>\n","      <td>0.053016</td>\n","      <td>0.106933</td>\n","      <td>0.365794</td>\n","      <td>0.074414</td>\n","      <td>...</td>\n","      <td>0.017235</td>\n","      <td>-0.024001</td>\n","      <td>-0.030071</td>\n","      <td>-0.009944</td>\n","      <td>0.072187</td>\n","      <td>-0.036975</td>\n","      <td>-0.003614</td>\n","      <td>0.017644</td>\n","      <td>-0.033793</td>\n","      <td>0.023828</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <td>0.378847</td>\n","      <td>0.086490</td>\n","      <td>0.018147</td>\n","      <td>0.146560</td>\n","      <td>1.000000</td>\n","      <td>0.309769</td>\n","      <td>-0.008737</td>\n","      <td>0.248701</td>\n","      <td>0.263023</td>\n","      <td>-0.012213</td>\n","      <td>...</td>\n","      <td>-0.013438</td>\n","      <td>-0.007317</td>\n","      <td>0.043806</td>\n","      <td>0.012859</td>\n","      <td>0.014162</td>\n","      <td>-0.048064</td>\n","      <td>-0.044471</td>\n","      <td>-0.001511</td>\n","      <td>-0.024662</td>\n","      <td>0.046147</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 1802 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d01962d9-5f8c-4e45-8e16-71540b93193b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d01962d9-5f8c-4e45-8e16-71540b93193b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d01962d9-5f8c-4e45-8e16-71540b93193b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":220}],"source":["df_corr = X_df.corr()\n","df_corr.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YAzl0BIzc7bl"},"outputs":[],"source":["threshold = 0.9\n","\n","\n","columns = np.full((df_corr.shape[0],), True, dtype=bool)\n","for i in range(df_corr.shape[0]):\n","    for j in range(i+1, df_corr.shape[0]):\n","        if df_corr.iloc[i,j] >= threshold:\n","            if columns[j]:\n","                columns[j] = False\n","selected_columns = X_df.columns[columns]\n","selected_columns\n","X_df = X_df[selected_columns]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxz4b2_yc7bl","colab":{"base_uri":"https://localhost:8080/","height":505},"executionInfo":{"status":"ok","timestamp":1659896979628,"user_tz":240,"elapsed":20,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"4d343f0f-9a55-447e-8035-fe28f66553ab"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     dropout_reason_adverse event  dropout_reason_consent withdrawn  \\\n","0                            22.0                               0.0   \n","1                            22.0                               0.0   \n","2                            22.0                               0.0   \n","3                            22.0                               0.0   \n","4                             0.0                               0.0   \n","..                            ...                               ...   \n","795                           0.0                               0.0   \n","796                           3.0                               0.0   \n","797                           1.0                               0.0   \n","798                           1.0                               1.0   \n","799                           0.0                               0.0   \n","\n","     dropout_reason_death  dropout_reason_inclusion/exclusion criteria issue  \\\n","0                     0.0                                                0.0   \n","1                     0.0                                                0.0   \n","2                     0.0                                                0.0   \n","3                     0.0                                                0.0   \n","4                     0.0                                                0.0   \n","..                    ...                                                ...   \n","795                   0.0                                                3.0   \n","796                   0.0                                                0.0   \n","797                   0.0                                                0.0   \n","798                   0.0                                                0.0   \n","799                   0.0                                                0.0   \n","\n","     dropout_reason_lack of efficacy  dropout_reason_lost to follow-up  \\\n","0                                0.0                               0.0   \n","1                                0.0                               0.0   \n","2                                0.0                               0.0   \n","3                                0.0                               0.0   \n","4                                0.0                               0.0   \n","..                               ...                               ...   \n","795                              0.0                               0.0   \n","796                              5.0                               0.0   \n","797                              1.0                               0.0   \n","798                              0.0                               0.0   \n","799                              0.0                               0.0   \n","\n","     dropout_reason_physician decision  dropout_reason_protocol violation  \\\n","0                                  0.0                                0.0   \n","1                                  0.0                                0.0   \n","2                                  0.0                                0.0   \n","3                                  0.0                                0.0   \n","4                                  0.0                                4.0   \n","..                                 ...                                ...   \n","795                                0.0                                0.0   \n","796                                0.0                                0.0   \n","797                                0.0                                0.0   \n","798                                0.0                                0.0   \n","799                                1.0                                0.0   \n","\n","     dropout_reason_subject withdrawal  Influenza  ...  \\\n","0                                  0.0        0.0  ...   \n","1                                  0.0        0.0  ...   \n","2                                  0.0        0.0  ...   \n","3                                  0.0        0.0  ...   \n","4                                  0.0        0.0  ...   \n","..                                 ...        ...  ...   \n","795                                0.0        0.0  ...   \n","796                                1.0        0.0  ...   \n","797                                1.0        0.0  ...   \n","798                                0.0        0.0  ...   \n","799                                0.0        0.0  ...   \n","\n","     allocation_type_Not Reported  allocation_type_Randomized  \\\n","0                               0                           1   \n","1                               0                           1   \n","2                               0                           1   \n","3                               0                           1   \n","4                               0                           1   \n","..                            ...                         ...   \n","795                             1                           0   \n","796                             0                           1   \n","797                             1                           0   \n","798                             0                           1   \n","799                             0                           1   \n","\n","     masking_type_Double  masking_type_None (Open Label)  \\\n","0                      0                               0   \n","1                      0                               0   \n","2                      0                               0   \n","3                      0                               0   \n","4                      0                               0   \n","..                   ...                             ...   \n","795                    0                               1   \n","796                    0                               0   \n","797                    0                               1   \n","798                    0                               0   \n","799                    0                               0   \n","\n","     masking_type_Quadruple  masking_type_Single  masking_type_Triple  \\\n","0                         0                    0                    1   \n","1                         0                    0                    1   \n","2                         0                    0                    1   \n","3                         0                    0                    1   \n","4                         0                    1                    0   \n","..                      ...                  ...                  ...   \n","795                       0                    0                    0   \n","796                       1                    0                    0   \n","797                       0                    0                    0   \n","798                       1                    0                    0   \n","799                       0                    0                    1   \n","\n","     study_gender_eligibility_All  study_gender_eligibility_Female  \\\n","0                               1                                0   \n","1                               1                                0   \n","2                               1                                0   \n","3                               1                                0   \n","4                               1                                0   \n","..                            ...                              ...   \n","795                             1                                0   \n","796                             1                                0   \n","797                             1                                0   \n","798                             1                                0   \n","799                             1                                0   \n","\n","     study_gender_eligibility_Male  \n","0                                0  \n","1                                0  \n","2                                0  \n","3                                0  \n","4                                0  \n","..                             ...  \n","795                              0  \n","796                              0  \n","797                              0  \n","798                              0  \n","799                              0  \n","\n","[800 rows x 1033 columns]"],"text/html":["\n","  <div id=\"df-09275c6a-a704-414d-a67e-9f2c73d11aea\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout_reason_adverse event</th>\n","      <th>dropout_reason_consent withdrawn</th>\n","      <th>dropout_reason_death</th>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <th>dropout_reason_physician decision</th>\n","      <th>dropout_reason_protocol violation</th>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <th>Influenza</th>\n","      <th>...</th>\n","      <th>allocation_type_Not Reported</th>\n","      <th>allocation_type_Randomized</th>\n","      <th>masking_type_Double</th>\n","      <th>masking_type_None (Open Label)</th>\n","      <th>masking_type_Quadruple</th>\n","      <th>masking_type_Single</th>\n","      <th>masking_type_Triple</th>\n","      <th>study_gender_eligibility_All</th>\n","      <th>study_gender_eligibility_Female</th>\n","      <th>study_gender_eligibility_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>22.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>795</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>796</th>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>797</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>798</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>799</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>800 rows × 1033 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09275c6a-a704-414d-a67e-9f2c73d11aea')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-09275c6a-a704-414d-a67e-9f2c73d11aea button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-09275c6a-a704-414d-a67e-9f2c73d11aea');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":223}],"source":["X_df"]},{"cell_type":"markdown","metadata":{"id":"O2r78_COc7bm"},"source":["Standardize and split data "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j_pKwdUKc7bm"},"outputs":[],"source":["X_df_norm = (X_df-X_df.min())/(X_df.max()-X_df.min())"]},{"cell_type":"code","source":["mean(y_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q6qdKqZsj-99","executionInfo":{"status":"ok","timestamp":1659896979999,"user_tz":240,"elapsed":14,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"c35cfabd-6bb9-4bbc-8d2a-fd37358dd0d5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["25.99101549830037"]},"metadata":{},"execution_count":225}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8OH4WLm2c7bm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659898146242,"user_tz":240,"elapsed":161,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"fed3e778-ae4b-496c-e34d-b9c6273486d4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((640, 1033), (160, 1033))"]},"metadata":{},"execution_count":239}],"source":["# Train/test split:\n","X_train, X_test, y_train, y_test = train_test_split(X_df_norm, y_df, test_size = 0.2, random_state = 2)\n","\n","X_train.shape, X_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AOu5gZg8Fd2l"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns;\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import make_pipeline\n","from sklearn.feature_selection import SelectKBest, f_regression\n","from sklearn.model_selection import train_test_split,GridSearchCV\n","from sklearn.linear_model import Ridge, Lasso"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ephanBoZFHuC"},"outputs":[],"source":["#Setting up a pipeline\n","pipe=make_pipeline(StandardScaler(),SelectKBest(f_regression),Ridge())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G-qzAQXQFfKb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659898148315,"user_tz":240,"elapsed":1,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"b0409390-4ebc-4cbe-cbbf-398f638aff2b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['memory', 'steps', 'verbose', 'standardscaler', 'selectkbest', 'ridge', 'standardscaler__copy', 'standardscaler__with_mean', 'standardscaler__with_std', 'selectkbest__k', 'selectkbest__score_func', 'ridge__alpha', 'ridge__copy_X', 'ridge__fit_intercept', 'ridge__max_iter', 'ridge__normalize', 'ridge__positive', 'ridge__random_state', 'ridge__solver', 'ridge__tol'])"]},"metadata":{},"execution_count":242}],"source":["#Looking up parameters that can be passed to the pipeline\n","pipe.get_params().keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QvELinJ9FkwH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659898184966,"user_tz":240,"elapsed":35494,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"f01cbb86-476c-41cd-8cbc-cccb6f934e40"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n","  correlation_coefficient /= X_norms\n"]},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=5,\n","             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n","                                       ('selectkbest',\n","                                        SelectKBest(score_func=<function f_regression at 0x7f6bd79b5170>)),\n","                                       ('ridge', Ridge())]),\n","             n_jobs=-1,\n","             param_grid={'ridge__alpha': [5, 10],\n","                         'ridge__fit_intercept': [True, False],\n","                         'ridge__solver': ['svd', 'cholesky', 'lsqr',\n","                                           'sparse_cg', 'sag', 'saga'],\n","                         'selectkbest__k': [1, 2, 3, 4, 5, 6]})"]},"metadata":{},"execution_count":243}],"source":["#putting together a parameter grid to search over using grid search\n","params={\n","    'selectkbest__k':[1,2,3,4,5,6],\n","    'ridge__fit_intercept':[True,False],\n","    'ridge__alpha':[5,10],\n","    'ridge__solver':[ 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag',\n","'saga']\n","}\n","#setting up the grid search\n","gs=GridSearchCV(pipe,params,n_jobs=-1,cv=5)\n","#fitting gs to training data\n","gs.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hTHDBMBcFp11","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659898184966,"user_tz":240,"elapsed":15,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"aa7e746e-9f84-4fb8-f5bf-2f0b656521ae"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'ridge__alpha': 10,\n"," 'ridge__fit_intercept': True,\n"," 'ridge__solver': 'saga',\n"," 'selectkbest__k': 5}"]},"metadata":{},"execution_count":244}],"source":["#building a dataframe from cross-validation data\n","df_cv_scores=pd.DataFrame(gs.cv_results_).sort_values(by='rank_test_score')\n","#selecting specific columns to create a view\n","df_cv_scores[['params','split0_test_score', 'split1_test_score', 'split2_test_score',\\\n","       'split3_test_score', 'split4_test_score', 'mean_test_score',\\\n","       'std_test_score', 'rank_test_score']].head()\n","\n","#checking the selected permutation of parameters\n","gs.best_params_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x7SXenj_FzMK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659898184967,"user_tz":240,"elapsed":12,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"8b78939b-71d3-4e99-ab6f-8fb2c52b3b92"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.3239840869107904"]},"metadata":{},"execution_count":245}],"source":["#checking how well the model does on the holdout-set\n","gs.score(X_test,y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MHZ2ZmWtF1XX","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1659898185321,"user_tz":240,"elapsed":364,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"c17a8168-3a1e-4c24-d7bf-e20e9fceb5a5"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["#plotting predicted body weights vs actual body weights of penguins\n","y_preds=gs.predict(X_test)\n","plt.scatter(y_test,y_preds);"]},{"cell_type":"code","source":[""],"metadata":{"id":"gq4uO3zW0wYF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A6DRl7sD0wf1"},"source":["### Feature Selection"]},{"cell_type":"markdown","metadata":{"id":"XjKFVQfZ0wf2"},"source":["#### Feature Importance with Gradient Boosting"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1659890131292,"user_tz":240,"elapsed":178,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4661acf5-1779-49c7-f5d4-3335c78e0fb7","id":"WL5Q8wCg0wf2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4288759363250807"]},"metadata":{},"execution_count":28}],"source":["# GradientBoostingRegressor will be used for feature importance\n","reg_model = GradientBoostingRegressor(random_state=0)   \n","reg_model.fit(X_train, y_train)\n","y_preds = reg_model.predict(X_test)\n","r2_score(y_test, y_preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1659890131293,"user_tz":240,"elapsed":4,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"colab":{"base_uri":"https://localhost:8080/","height":676},"outputId":"a0c48973-a909-4f20-dca5-cf341bbe25e2","id":"WjIoxF9L0wf2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   importance\n","dropout_reason_inclusion/exclusion criteria issue    0.318439\n","dropout_reason_lost to follow-up                     0.058545\n","event_type_other                                     0.045327\n","Headache                                             0.040401\n","study_duration_months                                0.038388\n","Abdominal pain                                       0.037683\n","intervention_model_type_Factorial Assignment         0.037326\n","Genetic                                              0.034936\n","Nausea                                               0.028028\n","dropout_reason_adverse event                         0.025854\n","Dissociation                                         0.024618\n","Overdose                                             0.022068\n","dropout_reason_subject withdrawal                    0.017419\n","Glossitis                                            0.017076\n","Major depression                                     0.013135\n","masking_type_Quadruple                               0.012135\n","Lethargy                                             0.011323\n","Tremor                                               0.010559\n","intervention_model_type_Single Group Assignment      0.010132\n","dropout_reason_lack of efficacy                      0.009232"],"text/html":["\n","  <div id=\"df-94066c3e-bb63-41de-87b5-f6560594c6e0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>importance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>dropout_reason_inclusion/exclusion criteria issue</th>\n","      <td>0.318439</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lost to follow-up</th>\n","      <td>0.058545</td>\n","    </tr>\n","    <tr>\n","      <th>event_type_other</th>\n","      <td>0.045327</td>\n","    </tr>\n","    <tr>\n","      <th>Headache</th>\n","      <td>0.040401</td>\n","    </tr>\n","    <tr>\n","      <th>study_duration_months</th>\n","      <td>0.038388</td>\n","    </tr>\n","    <tr>\n","      <th>Abdominal pain</th>\n","      <td>0.037683</td>\n","    </tr>\n","    <tr>\n","      <th>intervention_model_type_Factorial Assignment</th>\n","      <td>0.037326</td>\n","    </tr>\n","    <tr>\n","      <th>Genetic</th>\n","      <td>0.034936</td>\n","    </tr>\n","    <tr>\n","      <th>Nausea</th>\n","      <td>0.028028</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_adverse event</th>\n","      <td>0.025854</td>\n","    </tr>\n","    <tr>\n","      <th>Dissociation</th>\n","      <td>0.024618</td>\n","    </tr>\n","    <tr>\n","      <th>Overdose</th>\n","      <td>0.022068</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_subject withdrawal</th>\n","      <td>0.017419</td>\n","    </tr>\n","    <tr>\n","      <th>Glossitis</th>\n","      <td>0.017076</td>\n","    </tr>\n","    <tr>\n","      <th>Major depression</th>\n","      <td>0.013135</td>\n","    </tr>\n","    <tr>\n","      <th>masking_type_Quadruple</th>\n","      <td>0.012135</td>\n","    </tr>\n","    <tr>\n","      <th>Lethargy</th>\n","      <td>0.011323</td>\n","    </tr>\n","    <tr>\n","      <th>Tremor</th>\n","      <td>0.010559</td>\n","    </tr>\n","    <tr>\n","      <th>intervention_model_type_Single Group Assignment</th>\n","      <td>0.010132</td>\n","    </tr>\n","    <tr>\n","      <th>dropout_reason_lack of efficacy</th>\n","      <td>0.009232</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94066c3e-bb63-41de-87b5-f6560594c6e0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-94066c3e-bb63-41de-87b5-f6560594c6e0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-94066c3e-bb63-41de-87b5-f6560594c6e0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":29}],"source":["feature_imp = pd.DataFrame(reg_model.feature_importances_,\n","                                   index = X_train.columns,\n","                                   columns=['importance']).sort_values('importance', ascending=False)\n","\n","feature_imp.head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KQT11lGq0wf2"},"outputs":[],"source":["#create list of top 30 features\n","boost_top_10 = feature_imp.head(10).index.values\n","boost_top_10_list = list(boost_top_10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sTBYjf3l0wf2"},"outputs":[],"source":["X_boost_df = X_df[X_df.columns.intersection(boost_top_10_list)]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1659890131482,"user_tz":240,"elapsed":3,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9298c539-76d9-4551-f6a0-512d56403e0f","id":"VbvpYHCA0wf2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((271, 10), (68, 10))"]},"metadata":{},"execution_count":32}],"source":["# Train/test split:\n","X_boost_train, X_boost_test, y_train, y_test = train_test_split(X_boost_df, y_df, test_size = 0.2, random_state = 2)\n","\n","X_boost_train.shape, X_boost_test.shape"]},{"cell_type":"markdown","source":["##### Model Set-up"],"metadata":{"id":"5hj3VrR-0wf2"}},{"cell_type":"code","source":["# Continous outcome prediction:\n","\n","def train_and_test(reg_model, X_train, y_train, X_test, y_test):\n","  reg_model.fit(X_train, y_train)\n","  # Make predictions with model\n","  y_pred = reg_model.predict(X_test)\n","  #Metrics\n","  mse_score_val = mean_squared_error(y_test, y_pred)\n","  r2_score_val = r2_score(y_test, y_pred)\n","  return {\"MSE_Score\": mse_score_val, \"R2_Score\": r2_score_val}"],"metadata":{"id":"OcXqNY9G0wf2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Linear Regression"],"metadata":{"id":"W1cZv_IX0wf2"}},{"cell_type":"code","source":["# Linear Regression:\n","\n","lr_model = LinearRegression()\n","\n","scores = cross_val_score(lr_model, X_boost_train, y_train, scoring='r2', cv=5)\n","scores   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893244224,"user_tz":240,"elapsed":149,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"7e15afcf-dc7e-4be4-9ead-b02e6c00e426","id":"w35y2bwm0wf2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.52372859,  0.22300902,  0.40490087,  0.28289511,  0.22152235])"]},"metadata":{},"execution_count":104}]},{"cell_type":"code","source":["# k-fold CV (using all the boost variables)\n","train_and_test(lr_model, X_boost_train, y_train, X_boost_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893245438,"user_tz":240,"elapsed":2,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"1580e64d-dfae-49fb-ad3d-97cc49d9cbbc","id":"SlAayCC70wf3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'MSE_Score': 320.12078109174996, 'R2_Score': 0.27008943892479653}"]},"metadata":{},"execution_count":105}]},{"cell_type":"markdown","source":["Random Forest"],"metadata":{"id":"yfh5lzjD0wf3"}},{"cell_type":"code","source":["# Random Forest Regression:\n","\n","rfr_model = RandomForestRegressor()\n","\n","scores = cross_val_score(rfr_model, X_boost_train, y_train, scoring='r2', cv=5)\n","scores   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893012236,"user_tz":240,"elapsed":2255,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"3379fa3e-f132-4e1a-dfba-ae15c9339c25","id":"IQ0CEC6l0wf3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.21087431, 0.4829302 , 0.49542987, 0.26260168, 0.45673906])"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["\n","train_and_test(rfr_model, X_boost_train, y_train, X_boost_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893013554,"user_tz":240,"elapsed":607,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"44be92a3-36fd-42ca-98b1-f2321d638b9f","id":"mwUM-p1O0wf3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'MSE_Score': 239.01657569297282, 'R2_Score': 0.455015940310575}"]},"metadata":{},"execution_count":97}]},{"cell_type":"markdown","source":["Gradient Boosting"],"metadata":{"id":"iEHM7NF60wf3"}},{"cell_type":"code","source":["# Gradient Boost for feature importance:\n","\n","boost_model = GradientBoostingRegressor(random_state=0)   \n","\n","scores = cross_val_score(boost_model, X_boost_train, y_train, scoring='r2', cv=5)\n","scores   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893141201,"user_tz":240,"elapsed":860,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"cd9eebc5-824a-4f51-d233-07aaff560c52","id":"9c-b1EMu0wf3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.11861583, 0.52141256, 0.46201785, 0.23063168, 0.37609487])"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":["boost_model.fit(X_boost_train, y_train)\n","y_preds = boost_model.predict(X_boost_test)\n","r2_score(y_test, y_preds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659893147475,"user_tz":240,"elapsed":316,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"f4bcf021-b3e3-4597-a9f4-494dc6deff67","id":"GQjKuCFE0wf3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4156543656927092"]},"metadata":{},"execution_count":100}]},{"cell_type":"code","source":["#chose five models to train the data with to see which performs the best : Linear Regression and Support Vector Regression\n","pipe_lr = Pipeline([('LR', LinearRegression())])\n","pipe_svm = Pipeline([('SVM', SVR())])\n","pipe_rfr = Pipeline([('RFR', RandomForestRegressor())])\n","pipe_dtr = Pipeline([('DTR', DecisionTreeRegressor())])\n","pipe_gbr = Pipeline([('DTR', GradientBoostingRegressor())])\n","\n","#create GridSearch parameters\n","\n","#creates lists to pass into the grid below\n","C = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n","epsilon = [0, 0.01, 0.1, 0.5, 1, 2, 4, 5]\n","n_estimators = [50,100,150, 200, 300, 500,1000, 1500]\n","n_jobs = np.array([1, 10, 100, 290, 500])\n","bootstrap = [True, False]\n","max_depth = [3,4,6,8,10]\n","min_samples_split = [10,20,40]\n","max_depth = [2, 6, 8]\n","min_samples_leaf = [20, 40, 100]\n","max_leaf_nodes = [5, 20, 100]\n","learning_rate = [0.01,0.02,0.03,0.04]\n","subsample = [0.9, 0.5, 0.2, 0.1]\n","\n","#these will be passed to the GridSearchCV function below -> which will take a pipeline model and test out each paramter value passed through in the following parameter list\n","lr_space = [{'fit_intercept':[True, False]}]\n","\n","svr_space = [{'kernel': ['linear'], 'C' : C, 'epsilon' : epsilon},\n","         {'kernel': ['rbf'], 'C' : C, 'gamma' : C, 'epsilon' : epsilon}]\n","\n","rfr_space = [{'max_features' : [\"auto\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"sqrt\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"log2\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","dtr_space = [{'criterion': ['squared_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes},\n","            {'criterion': ['absolute_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes}]\n","\n","gbr_space = [{'learning_rate': learning_rate, 'subsample' : subsample, 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","\n","\n","##use the GridSearchCV function and pass in both the pipeline created above and the grid parameters \n","\n","#pass in cv=5 for the gridsearch to perform cross-validation on our training set\n","#pass score = accuracy for get the accrucay score when the test is performed \n","lr_gs = GridSearchCV(LinearRegression(), param_grid = lr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","svm_gs = GridSearchCV(SVR(), param_grid = svr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","rfr_gs = GridSearchCV(RandomForestRegressor(), param_grid = rfr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","dtr_gs = GridSearchCV(DecisionTreeRegressor(), param_grid = dtr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","gbr_gs = GridSearchCV(GradientBoostingRegressor(), param_grid = gbr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","\n","lr_grids = [lr_gs]\n","\n","for lr_pipe in lr_grids:\n","    lr_pipe.fit(X_boost_train,y_train)\n","\n","svm_grids = [svm_gs]\n","\n","for svm_pipe in svm_grids:\n","    svm_pipe.fit(X_boost_train,y_train)\n","\n","rfr_grids = [rfr_gs]\n","\n","for rfr_pipe in rfr_grids:\n","    rfr_pipe.fit(X_boost_train,y_train)\n","\n","dtr_grids = [dtr_gs]\n","\n","for dtr_pipe in dtr_grids:\n","    dtr_pipe.fit(X_boost_train,y_train)\n","\n","gbr_grids = [gbr_gs]\n","\n","for gbr_pipe in gbr_grids:\n","    gbr_pipe.fit(X_boost_train,y_train)"],"metadata":{"id":"Smwk3uXC0wf3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#first create a dictionary that contains the classifier types to used int eh for loop. \n","lr_grid_dict = {0: 'Linear Regression'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(lr_grids):\n","    print('{} Train R_Square: {}'.format(lr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","lr_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,lr_y_pred)*100\n","\n","for i, model in enumerate(lr_grids):\n","    print('{} Test R_Square: {}'.format(lr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","svm_grid_dict = {0: 'Support Vector Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(svm_grids):\n","    print('{} Train R_Square: {}'.format(svm_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","svm_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,svm_y_pred)*100\n","\n","for i, model in enumerate(svm_grids):\n","    print('{} Test R_Square: {}'.format(svm_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          results.best_params_))\n","    \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","rfr_grid_dict = {0: 'Random Forest Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(rfr_grids):\n","    print('{} Train R_Square: {}'.format(rfr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","rf_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,rf_y_pred)*100\n","\n","for i, model in enumerate(rfr_grids):\n","    print('{} Test R_Square: {}'.format(rfr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","dtr_grid_dict = {0: 'Decision Tree Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(dtr_grids):\n","    print('{} Train R_Square: {}'.format(dtr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","dtr_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,dtr_y_pred)*100\n","\n","for i, model in enumerate(dtr_grids):\n","    print('{} Test R_Square: {}'.format(dtr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","gbr_grid_dict = {0: 'Gradient Boosting Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(gbr_grids):\n","    print('{} Train R_Square: {}'.format(gbr_grid_dict[i],    model.score(X_boost_train,y_train)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_boost_train, y_train)\n","gbr_y_pred=model.predict(X_boost_test)\n","Accuracy=r2_score(y_test,gbr_y_pred)*100\n","\n","for i, model in enumerate(gbr_grids):\n","    print('{} Test R_Square: {}'.format(gbr_grid_dict[i],    results.score(X_boost_test,y_test)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          results.best_params_))"],"metadata":{"id":"3TbCeBVa0wf3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1iIsmFNH0wf3"},"source":["#### Mutual Information Feature Selection "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659724797561,"user_tz":240,"elapsed":2931,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"7f430427-d146-4f57-c8f0-ac55c5f102fa","id":"z5nPfuZb0wf3"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1.93329965e-01 2.79787357e-02 0.00000000e+00 2.85353136e-01\n"," 1.12896336e-01 2.04555356e-01 6.47709408e-02 1.89068091e-02\n"," 2.36317673e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.14886389e-02 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 9.31302684e-04 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 2.32252200e-03 1.40305033e-01\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.39487101e-02\n"," 7.96625655e-03 0.00000000e+00 9.11215201e-02 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 2.24477243e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 5.80357087e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.13094503e-01 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.45845098e-03 7.19362761e-03\n"," 0.00000000e+00 0.00000000e+00 2.40973048e-03 7.97151068e-03\n"," 1.65255318e-02 2.68652715e-02 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 4.78600247e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 9.50697768e-04 2.04791150e-03 0.00000000e+00 0.00000000e+00\n"," 1.41220624e-03 0.00000000e+00 5.01277239e-03 0.00000000e+00\n"," 0.00000000e+00 7.38843507e-03 0.00000000e+00 0.00000000e+00\n"," 1.29290297e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 6.44048285e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 5.02576173e-03 0.00000000e+00 0.00000000e+00 1.99348901e-03\n"," 7.05102041e-03 8.03350383e-03 9.70502791e-04 1.17793054e-03\n"," 5.30411535e-03 0.00000000e+00 5.33382372e-03 3.65177267e-04\n"," 8.64074784e-03 0.00000000e+00 1.19599897e-02 0.00000000e+00\n"," 2.84805174e-03 1.38729789e-03 0.00000000e+00 1.02384043e-02\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 1.09570251e-02 1.19276081e-02 0.00000000e+00 2.53345761e-04\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.42389858e-02\n"," 0.00000000e+00 1.85970340e-02 1.75240411e-03 3.44523841e-03\n"," 9.75414247e-03 2.92779979e-03 0.00000000e+00 0.00000000e+00\n"," 1.77997772e-03 0.00000000e+00 8.69478688e-04 2.96583868e-03\n"," 0.00000000e+00 8.08535841e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 1.97063305e-02 3.67974827e-05 1.96065812e-05\n"," 0.00000000e+00 0.00000000e+00 3.69781965e-04 0.00000000e+00\n"," 0.00000000e+00 1.26305402e-03 0.00000000e+00 0.00000000e+00\n"," 4.49748302e-03 8.72724855e-03 4.24913952e-03 4.28808130e-03\n"," 0.00000000e+00 0.00000000e+00 1.04173726e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 2.68405974e-03 9.93819846e-04\n"," 0.00000000e+00 2.74253287e-02 5.91776086e-03 0.00000000e+00\n"," 3.12987092e-03 0.00000000e+00 0.00000000e+00 1.84500421e-02\n"," 0.00000000e+00 7.46316487e-04 0.00000000e+00 2.83490536e-03\n"," 6.22400733e-03 9.66883491e-03 1.97294403e-02 0.00000000e+00\n"," 4.05093784e-03 0.00000000e+00 4.27624185e-05 9.47262668e-06\n"," 0.00000000e+00 2.39920972e-03 0.00000000e+00 0.00000000e+00\n"," 2.83998190e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 6.63027663e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 2.69679475e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 3.30421947e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 9.72412049e-04\n"," 0.00000000e+00 0.00000000e+00 1.51862016e-03 1.57903235e-02\n"," 0.00000000e+00 0.00000000e+00 5.30980431e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 6.48832115e-04 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.46576918e-04\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.60120945e-02\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 1.08799955e-02 5.67464207e-03\n"," 0.00000000e+00 0.00000000e+00 2.99233670e-03 3.60552397e-03\n"," 2.10738798e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 1.36375133e-02 0.00000000e+00 0.00000000e+00\n"," 1.38784031e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 2.36206964e-03 0.00000000e+00 0.00000000e+00\n"," 4.14751754e-04 4.63904996e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 3.81096621e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 1.43343054e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 9.67265880e-04 4.12500329e-04\n"," 1.32235983e-02 7.88329410e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 3.73740846e-04 0.00000000e+00 5.22484888e-03\n"," 6.29731809e-02 0.00000000e+00 6.21929279e-02 1.49949132e-01\n"," 8.69707919e-03 1.86974960e-02 3.31688153e-03 6.98487316e-02\n"," 5.58862446e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 1.70697662e-01 1.35633449e-01 0.00000000e+00\n"," 0.00000000e+00 8.44687426e-03 0.00000000e+00 3.92890583e-04\n"," 3.05852092e-02 0.00000000e+00 1.77488514e-02 3.18491126e-02\n"," 4.92078625e-02 5.25771761e-02 3.57412169e-02 0.00000000e+00\n"," 0.00000000e+00 6.05903110e-02 2.00073829e-02 2.41637927e-02\n"," 2.98299349e-02 6.85765039e-04 0.00000000e+00 3.66658126e-02\n"," 8.50858185e-02 8.20275432e-03 0.00000000e+00 1.04039135e-02\n"," 2.37977376e-02 7.00182719e-03]\n"]}],"source":["from sklearn.feature_selection import mutual_info_regression  \n","from sklearn.feature_selection import SelectKBest\n","selector = SelectKBest(mutual_info_regression, k=10)\n","X_train_new = selector.fit_transform(X_train, y_train)  #Applying transformation to the training set\n","#to get names of the selected features\n","mask = selector.get_support()  \n","\n","print(selector.scores_)   \n","\n","new_features = X_train.columns[mask]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q6dA9r_v0wf4"},"outputs":[],"source":["X_MI_df = V4_master_df[new_features]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":375},"executionInfo":{"status":"error","timestamp":1659724798118,"user_tz":240,"elapsed":289,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"b261267e-2132-4ed7-fe08-e4c25bcaeb52","id":"syuHBplw0wf4"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-82-a1d14a8e7824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train/test split:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_MI_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_MI_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_MI_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_MI_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_MI_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2417\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [800, 339]"]}],"source":["# Train/test split:\n","X_MI_train, X_MI_test, y_train, y_test = train_test_split(X_MI_df, y_df, test_size = 0.2, random_state = 2)\n","\n","X_MI_train.shape, X_MI_test.shape"]},{"cell_type":"code","source":["logreg=LogisticRegression()\n","kf=KFold(n_splits=5)\n","score=cross_val_score(logreg,X_MI_train,y_train,cv=kf)\n","print(\"Cross Validation Scores are {}\".format(score))\n","print(\"Average Cross Validation score :{}\".format(score.mean()))\n","\n","# Train classifiers\n","reg1 = GradientBoostingRegressor(random_state=1)\n","reg2 = RandomForestRegressor(random_state=1)\n","reg3 = LinearRegression()\n","\n","reg1.fit(X_MI_train, y_train)\n","reg2.fit(X_MI_train, y_train)\n","reg3.fit(X_MI_train, y_train)\n","\n","ereg = VotingRegressor([(\"gb\", reg1), (\"rf\", reg2), (\"lr\", reg3)])\n","ereg.fit(X_MI_train, y_train)\n","\n","#predict \n","pred1 = reg1.predict(X_boost_test)\n","pred2 = reg2.predict(X_boost_test)\n","pred3 = reg3.predict(X_boost_test)\n","pred4 = ereg.predict(X_boost_test)\n","\n","#plot\n","plt.figure()\n","plt.plot(pred1, \"gd\", label=\"GradientBoostingRegressor\")\n","plt.plot(pred2, \"b^\", label=\"RandomForestRegressor\")\n","plt.plot(pred3, \"ys\", label=\"LinearRegression\")\n","plt.plot(pred4, \"r*\", ms=10, label=\"VotingRegressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"training samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions and their average - Depression\")\n","plt.setp(plt.gca(),ylim=(0,100))\n","\n","plt.show()"],"metadata":{"id":"318uIHc10wf4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#chose five models to train the data with to see which performs the best : Linear Regression and Support Vector Regression\n","pipe_lr = Pipeline([('LR', LinearRegression())])\n","pipe_svm = Pipeline([('SVM', SVR())])\n","pipe_rfr = Pipeline([('RFR', RandomForestRegressor())])\n","pipe_dtr = Pipeline([('DTR', DecisionTreeRegressor())])\n","pipe_gbr = Pipeline([('DTR', GradientBoostingRegressor())])\n","\n","#create GridSearch parameters\n","\n","#creates lists to pass into the grid below\n","C = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n","epsilon = [0, 0.01, 0.1, 0.5, 1, 2, 4, 5]\n","n_estimators = [50,100,150, 200, 300, 500,1000, 1500]\n","n_jobs = np.array([1, 10, 100, 290, 500])\n","bootstrap = [True, False]\n","max_depth = [3,4,6,8,10]\n","min_samples_split = [10,20,40]\n","max_depth = [2, 6, 8]\n","min_samples_leaf = [20, 40, 100]\n","max_leaf_nodes = [5, 20, 100]\n","learning_rate = [0.01,0.02,0.03,0.04]\n","subsample = [0.9, 0.5, 0.2, 0.1]\n","\n","#these will be passed to the GridSearchCV function below -> which will take a pipeline model and test out each paramter value passed through in the following parameter list\n","lr_space = [{'fit_intercept': ['svd'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['cholesky'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['lsqr'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sparse_cg'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sag'],  'n_jobs' : n_jobs},\n","         {'fit_intercept': ['saga'], 'n_jobs' : n_jobs}]\n","\n","svr_space = [{'kernel': ['linear'], 'C' : C, 'epsilon' : epsilon},\n","         {'kernel': ['rbf'], 'C' : C, 'gamma' : C, 'epsilon' : epsilon}]\n","\n","rfr_space = [{'max_features' : [\"auto\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"sqrt\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"log2\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","dtr_space = [{'criterion': ['mse'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes},\n","         {'criterion': ['absolute_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes}]\n","\n","gbr_space = [{'learning_rate': learning_rate, 'subsample' : subsample, 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","\n","\n","##use the GridSearchCV function and pass in both the pipeline created above and the frid parameters \n","\n","#pass in cv=3 for the fridsearch to perform cross-validation on our training set\n","#pass score = accuracy for get the accrucay score when the test is performed \n","lr_gs = GridSearchCV(LinearRegression(), param_grid = lr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","svm_gs = GridSearchCV(SVR(), param_grid = svr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","rfr_gs = GridSearchCV(RandomForestRegressor(), param_grid = rfr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","dtr_gs = GridSearchCV(DecisionTreeRegressor(), param_grid = dtr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","gbr_gs = GridSearchCV(GradientBoostingRegressor(), param_grid = gbr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","\n","lr_grids = [lr_gs]\n","\n","for lr_pipe in lr_grids:\n","    lr_pipe.fit(X_MI_train,y_train)\n","\n","svm_grids = [svm_gs]\n","\n","for svm_pipe in svm_grids:\n","    svm_pipe.fit(X_MI_train,y_train)\n","\n","rfr_grids = [rfr_gs]\n","\n","for rfr_pipe in rfr_grids:\n","    rfr_pipe.fit(X_MI_train,y_train)\n","\n","dtr_grids = [dtr_gs]\n","\n","for dtr_pipe in dtr_grids:\n","    dtr_pipe.fit(X_MI_train,y_train)\n","\n","gbr_grids = [gbr_gs]\n","\n","for gbr_pipe in gbr_grids:\n","    gbr_pipe.fit(X_MI_train,y_train)"],"metadata":{"id":"Ex1ASo1p0wf4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#first create a dictionary that contains the classifier types to used int eh for loop. \n","lr_grid_dict = {0: 'Linear Regression'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(lr_grids):\n","    print('{} Train R_Square: {}'.format(lr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(lr_grids):\n","    print('{} Test R_Square: {}'.format(lr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","svm_grid_dict = {0: 'Support Vector Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(svm_grids):\n","    print('{} Train R_Square: {}'.format(svm_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(svm_grids):\n","    print('{} Test R_Square: {}'.format(svm_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","rfr_grid_dict = {0: 'Random Forest Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(rfr_grids):\n","    print('{} Train R_Square: {}'.format(rfr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(rfr_grids):\n","    print('{} Test R_Square: {}'.format(rfr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","dtr_grid_dict = {0: 'Decision Tree Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(dtr_grids):\n","    print('{} Train R_Square: {}'.format(dtr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(dtr_grids):\n","    print('{} Test R_Square: {}'.format(dtr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))\n","\n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","gbr_grid_dict = {0: 'Gradient Boosting Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(gbr_grids):\n","    print('{} Train R_Square: {}'.format(gbr_grid_dict[i],    model.score(X_MI_train,y_train)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_MI_train, y_train)\n","y_pred=model.predict(X_MI_test)\n","Accuracy=r2_score(y_test,y_pred)*100\n","\n","for i, model in enumerate(gbr_grids):\n","    print('{} Test R_Square: {}'.format(gbr_grid_dict[i],    results.score(X_MI_test,y_test)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          results.best_params_))\n","    print('{} Prediction Accuracy Plot {}'.format(plt.scatter(y_test,y_pred), plt.xlabel('Actual'), plt.ylabel('Predicted'), plt.title(Accuracy)))"],"metadata":{"id":"QnZ4hULX0wf4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZKv2Di6d0wf4"},"source":["#### Knowledge Feature Selection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kYefprVY0wf4"},"outputs":[],"source":["df_list = list(X_df[['number_of_arms', 'has_dmc', 'number_of_facilities', 'study_duration_months', 'event_type_deaths', 'event_type_other', 'event_type_serious']])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5VCCl75b0wf4"},"outputs":[],"source":["dropout_list = list(X_df[['dropout_reason_adverse event', 'dropout_reason_inclusion/exclusion criteria issue', 'dropout_reason_lost to follow-up']])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659724854258,"user_tz":240,"elapsed":139,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"6e474a56-8e67-44c6-ba63-94dc82d8b857","id":"86BJwlNw0wf4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Headache',\n"," 'Nausea',\n"," 'Fatigue',\n"," 'Vomiting',\n"," 'Decreased appetite',\n"," 'Diarrhoea',\n"," 'Sedation',\n"," 'Rash',\n"," 'Increased appetite',\n"," 'Palpitations']"]},"metadata":{},"execution_count":85}],"source":["top_ae_table_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cCtpmWoS0wf4"},"outputs":[],"source":["X_knowledge_df = X_df[X_df.columns.intersection(top_ae_table_list+dropout_list+df_list)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZdT33Z_10wf4"},"outputs":[],"source":["X_knowledge_norm = (X_knowledge_df-X_knowledge_df.min())/(X_knowledge_df.max()-X_knowledge_df.min())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659724857924,"user_tz":240,"elapsed":117,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"1f81e75a-1e24-4ea5-fc14-1c0e06343aca","id":"L9zQ-KSe0wf4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((271, 20), (68, 20))"]},"metadata":{},"execution_count":88}],"source":["# Train/test split:\n","X_knowledge_train, X_knowledge_test, y_train, y_test = train_test_split(X_knowledge_norm, y_df, test_size = 0.2, random_state = 2)\n","\n","X_knowledge_train.shape, X_knowledge_test.shape"]},{"cell_type":"code","source":["logreg=LogisticRegression()\n","kf=KFold(n_splits=5)\n","score=cross_val_score(logreg,X_knowledge_train,y_train,cv=kf)\n","print(\"Cross Validation Scores are {}\".format(score))\n","print(\"Average Cross Validation score :{}\".format(score.mean()))\n","\n","# Train classifiers\n","reg1 = GradientBoostingRegressor(random_state=1)\n","reg2 = RandomForestRegressor(random_state=1)\n","reg3 = LinearRegression()\n","\n","reg1.fit(X_knowledge_train, y_train)\n","reg2.fit(X_knowledge_train, y_train)\n","reg3.fit(X_knowledge_train, y_train)\n","\n","ereg = VotingRegressor([(\"gb\", reg1), (\"rf\", reg2), (\"lr\", reg3)])\n","ereg.fit(X_knowledge_train, y_train)\n","\n","#predict \n","pred1 = reg1.predict(X_knowledge_test)\n","pred2 = reg2.predict(X_knowledge_test)\n","pred3 = reg3.predict(X_knowledge_test)\n","pred4 = ereg.predict(X_knowledge_test)\n","\n","#plot\n","plt.figure()\n","plt.plot(pred1, \"gd\", label=\"GradientBoostingRegressor\")\n","plt.plot(pred2, \"b^\", label=\"RandomForestRegressor\")\n","plt.plot(pred3, \"ys\", label=\"LinearRegression\")\n","plt.plot(pred4, \"r*\", ms=10, label=\"VotingRegressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"training samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions and their average - Depression\")\n","plt.setp(plt.gca(),ylim=(0,100))\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":640},"executionInfo":{"status":"ok","timestamp":1659724939828,"user_tz":240,"elapsed":2577,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"4fa6ee0a-25ae-442b-80ff-50a084b78f97","id":"eps0n2Cb0wf5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","5 fits failed out of a total of 5.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","5 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1516, in fit\n","    check_classification_targets(y)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\", line 197, in check_classification_targets\n","    raise ValueError(\"Unknown label type: %r\" % y_type)\n","ValueError: Unknown label type: 'continuous'\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Cross Validation Scores are [nan nan nan nan nan]\n","Average Cross Validation score :nan\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["#chose five models to train the data with to see which performs the best : Linear Regression and Support Vector Regression\n","pipe_lr = Pipeline([('LR', LinearRegression())])\n","pipe_svm = Pipeline([('SVM', SVR())])\n","pipe_rfr = Pipeline([('RFR', RandomForestRegressor())])\n","pipe_dtr = Pipeline([('DTR', DecisionTreeRegressor())])\n","pipe_gbr = Pipeline([('DTR', GradientBoostingRegressor())])\n","\n","#create GridSearch parameters\n","\n","#creates lists to pass into the grid below\n","C = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n","epsilon = [0, 0.01, 0.1, 0.5, 1, 2, 4, 5]\n","n_estimators = [50,100,150, 200, 300, 500,1000, 1500]\n","n_jobs = np.array([1, 10, 100, 290, 500])\n","bootstrap = [True, False]\n","max_depth = [3,4,6,8,10]\n","min_samples_split = [10,20,40]\n","max_depth = [2, 6, 8]\n","min_samples_leaf = [20, 40, 100]\n","max_leaf_nodes = [5, 20, 100]\n","learning_rate = [0.01,0.02,0.03,0.04]\n","subsample = [0.9, 0.5, 0.2, 0.1]\n","\n","#these will be passed to the GridSearchCV function below -> which will take a pipeline model and test out each paramter value passed through in the following parameter list\n","lr_space = [{'fit_intercept': ['svd'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['cholesky'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['lsqr'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sparse_cg'], 'n_jobs' : n_jobs},\n","         {'fit_intercept': ['sag'],  'n_jobs' : n_jobs},\n","         {'fit_intercept': ['saga'], 'n_jobs' : n_jobs}]\n","\n","svr_space = [{'kernel': ['linear'], 'C' : C, 'epsilon' : epsilon},\n","         {'kernel': ['rbf'], 'C' : C, 'gamma' : C, 'epsilon' : epsilon}]\n","\n","rfr_space = [{'max_features' : [\"auto\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"sqrt\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth},\n","             {'max_features' : [\"log2\"], 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","dtr_space = [{'criterion': ['mse'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes},\n","         {'criterion': ['absolute_error'], 'min_samples_split' : min_samples_split, 'max_depth' : max_depth, 'min_samples_leaf' : min_samples_leaf, 'max_leaf_nodes' : max_leaf_nodes}]\n","\n","gbr_space = [{'learning_rate': learning_rate, 'subsample' : subsample, 'n_estimators' : n_estimators, 'max_depth' : max_depth}]\n","\n","\n","\n","##use the GridSearchCV function and pass in both the pipeline created above and the frid parameters \n","\n","#pass in cv=3 for the fridsearch to perform cross-validation on our training set\n","#pass score = accuracy for get the accrucay score when the test is performed \n","lr_gs = GridSearchCV(LinearRegression(), param_grid = lr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","svm_gs = GridSearchCV(SVR(), param_grid = svr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","rfr_gs = GridSearchCV(RandomForestRegressor(), param_grid = rfr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","dtr_gs = GridSearchCV(DecisionTreeRegressor(), param_grid = dtr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","gbr_gs = GridSearchCV(GradientBoostingRegressor(), param_grid = gbr_space, scoring = 'r2', cv = 5, n_jobs = -1)\n","\n","lr_grids = [lr_gs]\n","\n","for lr_pipe in lr_grids:\n","    lr_pipe.fit(X_knowledge_train,y_train)\n","\n","svm_grids = [svm_gs]\n","\n","for svm_pipe in svm_grids:\n","    svm_pipe.fit(X_knowledge_train,y_train)\n","\n","rfr_grids = [rfr_gs]\n","\n","for rfr_pipe in rfr_grids:\n","    rfr_pipe.fit(X_knowledge_train,y_train)\n","\n","dtr_grids = [dtr_gs]\n","\n","for dtr_pipe in dtr_grids:\n","    dtr_pipe.fit(X_knowledge_train,y_train)\n","\n","gbr_grids = [gbr_gs]\n","\n","for gbr_pipe in gbr_grids:\n","    gbr_pipe.fit(X_knowledge_train,y_train)"],"metadata":{"id":"8ZTbUpxV0wf5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#first create a dictionary that contains the classifier types to used int eh for loop. \n","lr_grid_dict = {0: 'Linear Regression'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(lr_grids):\n","    print('{} Train R_Square: {}'.format(lr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","lr_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,lr_y_pred)*100\n","\n","for i, model in enumerate(lr_grids):\n","    print('{} Test R_Square: {}'.format(lr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(lr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","svm_grid_dict = {0: 'Support Vector Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(svm_grids):\n","    print('{} Train R_Square: {}'.format(svm_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","svm_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,svm_y_pred)*100\n","\n","for i, model in enumerate(svm_grids):\n","    print('{} Test R_Square: {}'.format(svm_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(svm_grid_dict[i],          results.best_params_))\n","    \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","rfr_grid_dict = {0: 'Random Forest Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(rfr_grids):\n","    print('{} Train R_Square: {}'.format(rfr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","rf_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,rf_y_pred)*100\n","\n","for i, model in enumerate(rfr_grids):\n","    print('{} Test R_Square: {}'.format(rfr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(rfr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","dtr_grid_dict = {0: 'Decision Tree Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(dtr_grids):\n","    print('{} Train R_Square: {}'.format(dtr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","dtr_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,dtr_y_pred)*100\n","\n","for i, model in enumerate(dtr_grids):\n","    print('{} Test R_Square: {}'.format(dtr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(dtr_grid_dict[i],          results.best_params_))\n","   \n","#first create a dictionary that contains the classifier types to used int eh for loop. \n","gbr_grid_dict = {0: 'Gradient Boosting Regressor'}\n","\n","#then create a for loop to train them all \n","for i, model in enumerate(gbr_grids):\n","    print('{} Train R_Square: {}'.format(gbr_grid_dict[i],    model.score(X_knowledge_train,y_train)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          model.best_params_))\n","\n","results = model.fit(X_knowledge_train, y_train)\n","gbr_y_pred=model.predict(X_knowledge_test)\n","Accuracy=r2_score(y_test,gbr_y_pred)*100\n","\n","for i, model in enumerate(gbr_grids):\n","    print('{} Test R_Square: {}'.format(gbr_grid_dict[i],    results.score(X_knowledge_test,y_test)))\n","    print('{} Best Params: {}'.format(gbr_grid_dict[i],          results.best_params_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":592},"executionInfo":{"status":"error","timestamp":1659726446747,"user_tz":240,"elapsed":329,"user":{"displayName":"Natalie Cortopassi","userId":"02756562078469357207"}},"outputId":"ce5abbb0-34da-4c3e-c4d7-0a55fe99180e","id":"Ozbn_NnR0wf5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n","Feature names unseen at fit time:\n","- Abdominal distension\n","- Abdominal hernia\n","- Abdominal pain\n","- Abortion spontaneous\n","- Accepts_Healthy_volunteers\n","- ...\n","Feature names must be in the same order as they were in fit.\n","\n","  warnings.warn(message, FutureWarning)\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-93-d716c58a4f93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#then create a for loop to train them all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_grids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Train R_Square: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_grid_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Best Params: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_grid_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;31m# callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimetric_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         )\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \"\"\"\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod_caller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return self._sign * self._score_func(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;34m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \"\"\"\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise ValueError(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: X has 334 features, but LinearRegression is expecting 20 features as input."]}]},{"cell_type":"code","source":["#plot predictions \n","plt.figure()\n","plt.plot(lr_y_pred, \"gd\", label=\"Linear Regression\")\n","plt.plot(svm_y_pred, \"b^\", label=\"Support Vector Regressor\")\n","plt.plot(rf_y_pred, \"ys\", label=\"Random Forest Regressor\")\n","plt.plot(dtr_y_pred, \"r*\", ms=10, label=\"Decision Tree Regressor\")\n","plt.plot(gbr_y_pred, \"bs\", label=\"Gradient Boosting Regressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"Training Samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions - Knowledge Based Feature Selection - Depression\")\n","plt.setp(plt.gca(),ylim=(0,100))"],"metadata":{"id":"cFj_mnJM0wf5"},"execution_count":null,"outputs":[]}]}